{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "using Pkg; Pkg.activate(; temp=true)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "In this tutorial we develop a very simple probabilistic programming language.\nThe implementation is similar to [DynamicPPL](https://github.com/TuringLang/DynamicPPL.jl).\nThis is intentional as we want to demonstrate some key ideas from Turing's internal implementation.\n\nTo make things easy to understand and to implement we restrict our language to a very simple subset of the language that Turing actually supports.\nDefining an accurate syntax description is not our goal here, instead, we give a simple example and all similar programs should work.\n\n# Consider a probabilistic model defined by\n\n$$\n\\begin{aligned}\na &\\sim \\operatorname{Normal}(0.5, 1^2) \\\\\nb &\\sim \\operatorname{Normal}(a, 2^2) \\\\\nx &\\sim \\operatorname{Normal}(b, 0.5^2)\n\\end{aligned}\n$$\n\nWe assume that `x` is data, i.e., an observed variable.\nIn our small language this model will be defined as"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "#| eval: false\n@mini_model function m(x)\n    a ~ Normal(0.5, 1)\n    b ~ Normal(a, 2)\n    x ~ Normal(b, 0.5)\n    return nothing\nend"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Specifically, we demand that\n\n  - all observed variables are arguments of the program,\n  - the model definition does not contain any control flow,\n  - all variables are scalars, and\n  - the function returns `nothing`.\n\nFirst, we import some required packages:"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "using MacroTools, Distributions, Random, AbstractMCMC, MCMCChains"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Before getting to the actual \"compiler\", we first build the data structure for the program trace.\nA program trace for a probabilistic programming language needs to at least record the values of stochastic variables and their log-probabilities."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "struct VarInfo{V,L}\n    values::V\n    logps::L\nend\n\nVarInfo() = VarInfo(Dict{Symbol,Float64}(), Dict{Symbol,Float64}())\n\nfunction Base.setindex!(varinfo::VarInfo, (value, logp), var_id)\n    varinfo.values[var_id] = value\n    varinfo.logps[var_id] = logp\n    return varinfo\nend"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Internally, our probabilistic programming language works with two main functions:\n\n  - `assume` for sampling unobserved variables and computing their log-probabilities, and\n  - `observe` for computing log-probabilities of observed variables (but not sampling them).\n\nFor different inference algorithms we may have to use different sampling procedures and different log-probability computations.\nFor instance, in some cases we might want to sample all variables from their prior distributions and in other cases we might only want to compute the log-likelihood of the observations based on a given set of values for the unobserved variables.\nThus depending on the inference algorithm we want to use different `assume` and `observe` implementations.\nWe can achieve this by providing this `context` information as a function argument to `assume` and `observe`.\n\n**Note:** *Although the context system in this tutorial is inspired by DynamicPPL, it is very simplistic.\nWe expand this mini Turing example in the [contexts]({{<meta contexts>}}) tutorial with some more complexity, to illustrate how and why contexts are central to Turing's design. For the full details one still needs to go to the actual source of DynamicPPL though.*\n\nHere we can see the implementation of a sampler that draws values of unobserved variables from the prior and computes the log-probability for every variable."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "struct SamplingContext{S<:AbstractMCMC.AbstractSampler,R<:Random.AbstractRNG}\n    rng::R\n    sampler::S\nend\n\nstruct PriorSampler <: AbstractMCMC.AbstractSampler end\n\nfunction observe(context::SamplingContext, varinfo, dist, var_id, var_value)\n    logp = logpdf(dist, var_value)\n    varinfo[var_id] = (var_value, logp)\n    return nothing\nend\n\nfunction assume(context::SamplingContext{PriorSampler}, varinfo, dist, var_id)\n    sample = Random.rand(context.rng, dist)\n    logp = logpdf(dist, sample)\n    varinfo[var_id] = (sample, logp)\n    return sample\nend;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Next we define the \"compiler\" for our simple programming language.\nThe term compiler is actually a bit misleading here since its only purpose is to transform the function definition in the `@mini_model` macro by\n\n  - adding the context information (`context`) and the tracing data structure (`varinfo`) as additional arguments, and\n  - replacing tildes with calls to `assume` and `observe`.\n\nAfterwards, as usual the Julia compiler will just-in-time compile the model function when it is called.\n\nThe manipulation of Julia expressions is an advanced part of the Julia language.\nThe [Julia documentation](https://docs.julialang.org/en/v1/manual/metaprogramming/) provides an introduction to and more details about this so-called metaprogramming."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "macro mini_model(expr)\n    return esc(mini_model(expr))\nend\n\nfunction mini_model(expr)\n    # Split the function definition into a dictionary with its name, arguments, body etc.\n    def = MacroTools.splitdef(expr)\n\n    # Replace tildes in the function body with calls to `assume` or `observe`\n    def[:body] = MacroTools.postwalk(def[:body]) do sub_expr\n        if MacroTools.@capture(sub_expr, var_ ~ dist_)\n            if var in def[:args]\n                # If the variable is an argument of the model function, it is observed\n                return :($(observe)(context, varinfo, $dist, $(Meta.quot(var)), $var))\n            else\n                # Otherwise it is unobserved\n                return :($var = $(assume)(context, varinfo, $dist, $(Meta.quot(var))))\n            end\n        else\n            return sub_expr\n        end\n    end\n\n    # Add `context` and `varinfo` arguments to the model function\n    def[:args] = vcat(:varinfo, :context, def[:args])\n\n    # Reassemble the function definition from its name, arguments, body etc.\n    return MacroTools.combinedef(def)\nend;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "For inference, we make use of the [AbstractMCMC interface](https://turinglang.github.io/AbstractMCMC.jl/dev/).\nIt provides a default implementation of a `sample` function for sampling a Markov chain.\nThe default implementation already supports e.g. sampling of multiple chains in parallel, thinning of samples, or discarding initial samples.\n\nThe AbstractMCMC interface requires us to at least\n\n  - define a model that is a subtype of `AbstractMCMC.AbstractModel`,\n  - define a sampler that is a subtype of `AbstractMCMC.AbstractSampler`,\n  - implement `AbstractMCMC.step` for our model and sampler.\n\nThus here we define a `MiniModel` model.\nIn this model we store the model function and the observed data."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "struct MiniModel{F,D} <: AbstractMCMC.AbstractModel\n    f::F\n    data::D # a NamedTuple of all the data\nend"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "In the Turing compiler, the model-specific `DynamicPPL.Model` is constructed automatically when calling the model function.\nBut for the sake of simplicity here we construct the model manually.\n\nTo illustrate probabilistic inference with our mini language we implement an extremely simplistic Random-Walk Metropolis-Hastings sampler.\nWe hard-code the proposal step as part of the sampler and only allow normal distributions with zero mean and fixed standard deviation.\nThe Metropolis-Hastings sampler in Turing is more flexible."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "struct MHSampler{T<:Real} <: AbstractMCMC.AbstractSampler\n    sigma::T\nend\n\nMHSampler() = MHSampler(1)\n\nfunction assume(context::SamplingContext{<:MHSampler}, varinfo, dist, var_id)\n    sampler = context.sampler\n    old_value = varinfo.values[var_id]\n\n    # propose a random-walk step, i.e, add the current value to a random\n    # value sampled from a Normal distribution centered at 0\n    value = rand(context.rng, Normal(old_value, sampler.sigma))\n    logp = Distributions.logpdf(dist, value)\n    varinfo[var_id] = (value, logp)\n\n    return value\nend;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "We need to define two `step` functions, one for the first step and the other for the following steps.\nIn the first step we sample values from the prior distributions and in the following steps we sample with the random-walk proposal.\nThe two functions are identified by the different arguments they take."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# The fist step: Sampling from the prior distributions\nfunction AbstractMCMC.step(\n    rng::Random.AbstractRNG, model::MiniModel, sampler::MHSampler; kwargs...\n)\n    vi = VarInfo()\n    ctx = SamplingContext(rng, PriorSampler())\n    model.f(vi, ctx, values(model.data)...)\n    return vi, vi\nend\n\n# The following steps: Sampling with random-walk proposal\nfunction AbstractMCMC.step(\n    rng::Random.AbstractRNG,\n    model::MiniModel,\n    sampler::MHSampler,\n    prev_state::VarInfo; # is just the old trace\n    kwargs...,\n)\n    vi = prev_state\n    new_vi = deepcopy(vi)\n    ctx = SamplingContext(rng, sampler)\n    model.f(new_vi, ctx, values(model.data)...)\n\n    # Compute log acceptance probability\n    # Since the proposal is symmetric the computation can be simplified\n    logα = sum(values(new_vi.logps)) - sum(values(vi.logps))\n\n    # Accept proposal with computed acceptance probability\n    if -randexp(rng) < logα\n        return new_vi, new_vi\n    else\n        return prev_state, prev_state\n    end\nend;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "To make it easier to analyze the samples and compare them with results from Turing, additionally we define a version of `AbstractMCMC.bundle_samples` for our model and sampler that returns a `MCMCChains.Chains` object of samples."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "function AbstractMCMC.bundle_samples(\n    samples, model::MiniModel, ::MHSampler, ::Any, ::Type{Chains}; kwargs...\n)\n    # We get a vector of traces\n    values = [sample.values for sample in samples]\n    params = [key for key in keys(values[1]) if key ∉ keys(model.data)]\n    vals = reduce(hcat, [value[p] for value in values] for p in params)\n    # Composing the `Chains` data-structure, of which analyzing infrastructure is provided\n    chains = Chains(vals, params)\n    return chains\nend;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Let us check how our mini probabilistic programming language works.\nWe define the probabilistic model:"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "@mini_model function m(x)\n    a ~ Normal(0.5, 1)\n    b ~ Normal(a, 2)\n    x ~ Normal(b, 0.5)\n    return nothing\nend;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "The `@mini_model` macro expands this into another function, `m`, which effectively calls either `assume` or `observe` on each variable as needed:"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "@macroexpand @mini_model function m(x)\n    a ~ Normal(0.5, 1)\n    b ~ Normal(a, 2)\n    x ~ Normal(b, 0.5)\n    return nothing\nend"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "We can use this function to construct the `MiniModel`, and then perform inference with data `x = 3.0`:"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "sample(MiniModel(m, (x=3.0,)), MHSampler(), 1_000_000; chain_type=Chains, progress=false)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "We compare these results with Turing."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "using Turing\nusing PDMats\n\n@model function turing_m(x)\n    a ~ Normal(0.5, 1)\n    b ~ Normal(a, 2)\n    x ~ Normal(b, 0.5)\n    return nothing\nend\n\nsample(turing_m(3.0), MH(ScalMat(2, 1.0)), 1_000_000, progress=false)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "As you can see, with our simple probabilistic programming language and custom samplers we get similar results as Turing."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Julia",
      "language": "julia",
      "name": "julia"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}