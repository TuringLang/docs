{
  "cells": [
    {
      "outputs": [],
      "cell_type": "code",
      "source": "# Install necessary dependencies.\nusing Pkg\nPkg.activate(; temp=true)\nPkg.add([\"Distributions\", \"DynamicPPL\", \"LogDensityProblems\", \"Logging\", \"Chairmarks\"])",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Once you have defined a model using the `@model` macro, Turing.jl provides high-level interfaces for applying MCMC sampling, variational inference, optimisation, and other inference algorithms.\nSuppose, however, that you want to work more directly with the model.\nA common use case for this is if you are developing your own inference algorithm.\n\nThis page describes how you can evaluate DynamicPPL models and obtain information about variable values, log densities, and other quantities of interest.\nIn particular, this provides a high-level overview of what we call `VarInfo`: this is a data structure that holds information about the execution state while traversing a model.\n\nTo begin, let's define a simple model.",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "using DynamicPPL, Distributions\n\n@model function simple()\n    @info \" --- Executing model --- \"\n    x ~ Normal()            # Prior\n    2.0 ~ Normal(x)         # Likelihood\n    return (; xplus1 = x + 1)  # Return value\nend\n\nmodel = simple()",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## The outputs of a model\n\nA DynamicPPL model has similar characteristics to Julia functions (which should not come as a surprise, since the `@model` macro is applied to a Julia function).\nHowever, an ordinary function only has a return value, whereas DynamicPPL models can have both _return values_ as well as _latent variables_ (i.e., the random variables in the model).\n\nIn general, both of these are of interest.\nWe can obtain the return value by calling the model as if it were a function:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "retval = model()",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "and the latent variables using `rand()`:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "latents = rand(Dict, model)",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "::: {.callout-note}\n## Why `Dict`?\n\nSimply calling `rand(model)`, by default, returns a NamedTuple.\nThis is fine for simple models where all variables on the left-hand side of tilde statements are standalone variables like `x`.\nHowever, if you have indices or fields such as `x[1]` or `x.a` on the left-hand side, then the NamedTuple will not be able to represent these variables properly.\nFeeding such a NamedTuple back into the model will lead to errors.\n\nIn general, `Dict{VarName}` will always avoid such correctness issues.\n:::\n\nBefore proceeding, it is worth mentioning that both of these calls generate values for random variables by sampling from their prior distributions.\nWe will see how to use different sampling strategies later.\n\n## Passing latent values into a model\n\nHaving considered what one can obtain from a model, we now turn to how we can use it.\n\nSuppose you now want to obtain the log probability (prior, likelihood, or joint) of a model, *given* certain parameters.\nFor this purpose, DynamicPPL provides the `logprior`, `loglikelihood`, and `logjoint` functions:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "logprior(model, latents)",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "One can check this against the expected log prior:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "logpdf(Normal(), latents[@varname(x)])",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Likewise, you can evaluate the return value of the model given the latent variables:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "returned(model, latents)",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## VarInfo\n\nThe above functions are convenient, but for many 'serious' applications they might not be flexible enough.\nFor example, if you wanted to obtain the return value _and_ the log joint, you would have to execute the model twice: once with `returned` and once with `logjoint`.\n\nIf you want to avoid this duplicate work, you need to use a lower-level interface, which is `DynamicPPL.evaluate!!`.\nAt its core, `evaluate!!` takes a model and a VarInfo object, and returns a tuple of the return value and the new VarInfo.\nSo, before we even get to `evaluate!!`, we need to understand what a VarInfo is.\n\nA VarInfo is a container that tracks the state of model execution, as well as any outputs related to its latent variables, such as log probabilities.\nDynamicPPL's source code contains many different kinds of VarInfos, each with different trade-offs.\nThe details of these are somewhat arcane and unfortunately cannot be fully abstracted away, mainly due to performance considerations.\n\nFor the vast majority of users, it suffices to know that you can generate one of them for a model with the constructor `VarInfo([rng, ]model)`.\nNote that this construction executes the model once (sampling new parameter values from the prior in the process).",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "v = VarInfo(model)",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "(Don't worry about the printout of the VarInfo object: we won't need to understand its internal structure.)\nWe can index into a VarInfo:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "v[@varname(x)]",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "To access the values of log-probabilities, DynamicPPL provides the `getlogprior`, `getloglikelihood`, and `getlogjoint` functions:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "DynamicPPL.getlogprior(v)",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "What about the return value?\nWell, the VarInfo does not store this directly: recall that `evaluate!!` gives us back the return value separately from the updated VarInfo.\nSo, let's try calling it to see what happens.\nThe default behaviour of `evaluate!!` is to use the parameter values stored in the VarInfo during model execution.\nThat is, when it sees `x ~ Normal()`, it will use the value of `x` stored in `v`.\nWe will see later how to change this behaviour.",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "retval, vout = DynamicPPL.evaluate!!(model, v)",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "So here in a single call we have obtained both the return value and an updated VarInfo `vout`, from which we can again extract log probabilities and variable values.\nWe can see from this that the value of `vout[@varname(x)]` is the same as `v[@varname(x)]`:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "vout[@varname(x)] == v[@varname(x)]",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "which is in line with the statement above that by default `evaluate!!` uses the values stored in the VarInfo.\n\nAt this point, the keen reader will notice that we have not really solved the problem here.\nAlthough the call to `DynamicPPL.evaluate!!` does indeed only execute the model once, we also had to do this once more at the beginning when constructing the VarInfo.\n\nBesides, we don't know how to control the parameter values used during model execution: they were simply whatever we got in the original VarInfo.\n\n## Specifying parameter values\n\nWe will first tackle the problem of specifying our own parameter values.\nTo do this, we need to use `DynamicPPL.init!!` instead of `DynamicPPL.evaluate!!`.\n\nThe difference is that instead of using the values stored in the VarInfo (which `evaluate!!` does by default), `init!!` uses a _strategy_ for generating new values, and overwrites the values in the VarInfo accordingly.\nFor example, `InitFromPrior()` says that any time a tilde-statement `x ~ dist` is encountered, a new value for `x` should be sampled from `dist`:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "retval, v_new = DynamicPPL.init!!(model, v, InitFromPrior())",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "This updates `v_new` with the new values that were sampled, and also means that log probabilities are computed using these new values.\n\n::: {.callout-note}\n## Random number generator\nYou can also provide an `AbstractRNG` as the first argument to `init!!` to control the reproducibility of the sampling: here we have omitted it.\n:::\n\nAlternatively, to provide specific sets of values, we can use `InitFromParams(...)` to specify them.\n`InitFromParams` can wrap either a `NamedTuple` or an `AbstractDict{<:VarName}`, but `Dict` is generally much preferred as this guarantees correct behaviour even for complex variable names.",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "retval, v_new = DynamicPPL.init!!(\n    model, v, InitFromParams(Dict(@varname(x) => 3.0))\n)",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We now find that if we look into `v_new`, the value of `x` is indeed `3.0`:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "v_new[@varname(x)]",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "and we can extract the return value and log probabilities exactly as before.\n\nNote that `init!!` always ignores any values that are already present in the VarInfo, and overwrites them with new values according to the specified strategy.\n\nIf you have a loop in which you want to repeatedly evaluate a model with different parameter values, then the workflow shown here is recommended:\n\n - First generate a VarInfo using `VarInfo(model)`;\n - Then call `DynamicPPL.init!!(model, v, InitFromParams(...))` to evaluate the model using those parameters.\n\nThis requires you to pay a one-time cost at the very beginning to generate the VarInfo, but subsequent evaluations will be efficient.\nDynamicPPL uses this approach when implementing functions such as `predict(model, chain)`.\n\n::: {.callout-tip}\nIf you want to avoid even the first model evaluation, you will need to read on to the 'Advanced' section below.\nHowever, for most applications this should not necessary.\n:::\n\n## Parameters in the form of Vectors\n\nIn general, one problem with `init!!` is that it is often slower than `evaluate!!`.\nThis is primarily because it does more work: it has to not only read from the provided parameters, but also overwrite existing values in the VarInfo.",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "using Chairmarks, Logging\n# We need to silence the 'executing model' message, or else it will\n# fill up the entire screen!\nwith_logger(ConsoleLogger(stderr, Logging.Warn)) do\n    median(@be DynamicPPL.evaluate!!(model, v_new))\nend",
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "with_logger(ConsoleLogger(stderr, Logging.Warn)) do\n    median(@be DynamicPPL.init!!(model, v_new, InitFromParams(Dict(@varname(x) => 3.0))))\nend",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "When evaluating models in tight loops, as is often the case in inference algorithms, this overhead can be quite unwanted.\nDynamicPPL provides a rather dangerous, but powerful, way to get around this, which is the `DynamicPPL.unflatten` function.\n`unflatten` allows you to directly modify the internal storage of a VarInfo, without having to go through `init!!` and model evaluation.\nIts input is a vector of parameters.",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "xs = [7.0]\nv_unflattened = DynamicPPL.unflatten(v_new, xs)\nv_unflattened[@varname(x)]",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can then directly use `v_new` in `evaluate!!`, which will use the value `7.0` for `x`:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "retval, vout = DynamicPPL.evaluate!!(model, v_unflattened)",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Even the combination of `unflatten` and `evaluate!!` tends to be faster than a single call to `init!!`, especially for larger models.\n\n**However, there are several reasons why this function is dangerous.\nIf you use it, you must pay close attention to correctness:**\n\n1. For models with multiple variables, the order in which these variables occur in the vector is not obvious. The short answer is that it depends on the order in which the variables are added to the VarInfo during its initialisation. If you have models where the order of variables can vary from one execution to another, then `unflatten` can easily lead to incorrect results.\n\n2. The meaning of the values passed in will generally depend on whether the VarInfo is linked or not (see the [Variable Transformations page]({{< meta developers/transforms/dynamicppl >}}) for more information about linked VarInfos). You must make sure that the values passed in are consistent with the link status of the VarInfo. In contrast, `InitFromParams` always uses unlinked values.\n\n3. While `unflatten` modifies the parameter values stored in the VarInfo, it does not modify any other information, such as log probabilities. Thus, after calling `unflatten`, your VarInfo will be in an inconsistent state, and you should not attempt to read any other information from it until you have called `evaluate!!` again (which recomputes e.g. log probabilities).\n\nThe inverse operation of `unflatten` is `DynamicPPL.getindex_internal(v, :)`:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "DynamicPPL.getindex_internal(v_unflattened, :)",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## `LogDensityFunction`\n\nThere is one place where `unflatten` is (unfortunately) quite indispensable, namely, the implementation of the LogDensityProblems.jl interface for Turing models.\n\nThe LogDensityProblems interface defines interface functions such as\n\n```julia\nLogDensityProblems.logdensity(f, x::AbstractVector)\n```\n\nwhich evaluates the log density of a model `f` given a vector of parameters `x`.\n\nGiven what we have seen above, this can be done by wrapping a model and a VarInfo together inside a struct.\nHere is a rough sketch of how this can be implemented:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "using LogDensityProblems\n\nstruct MyModelLogDensity{M<:DynamicPPL.Model,V<:DynamicPPL.VarInfo}\n    model::M\n    varinfo::V\nend\n\nfunction LogDensityProblems.logdensity(f::MyModelLogDensity, x::AbstractVector)\n    v_new = DynamicPPL.unflatten(f.varinfo, x)\n    _, vout = DynamicPPL.evaluate!!(f.model, v_new)\n    return DynamicPPL.getlogjoint(vout)\nend\n\n# Usage\nmy_ldf = MyModelLogDensity(model, VarInfo(model))\nLogDensityProblems.logdensity(my_ldf, [2.5])",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "DynamicPPL contains a `LogDensityFunction` type that, at its core, is essentially the same as the above.",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "# the varinfo object defaults to VarInfo(model)\nldf = DynamicPPL.LogDensityFunction(model)\nLogDensityProblems.logdensity(ldf, [2.5])",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "The real implementation is a bit more complicated as it provides more options, as well as support for gradients with automatic differentiation.\n\nIn this way, any Turing model can be converted into an object that you can use with LogDensityProblems-compatible optimisers, samplers, and other algorithms.\nThis is very powerful as it allows the algorithms to completely ignore the internal structure of the model, and simply treat it as an opaque log-density function.\nFor example, Turing's external sampler interface makes heavy use of this.\n\nHowever, it should be noted that because this uses `unflatten` under the hood, it suffers from exactly the same limitations as described above.\nFor example, models that do not have a fixed number or order of latent variables can lead to incorrect results or errors.\n\n## Advanced: Typed and untyped VarInfo\n\nThe discussion above suffices for many applications of DynamicPPL, but one question remains: how to avoid the initial overhead of constructing a VarInfo object before we can do anything useful with it.\nThis is important when implementing a function such as `logjoint(model, params)`: in principle, only a single evaluation should be needed.\n\nTo tackle this, we need to understand a little bit more about two kinds of VarInfo.\nConceptually, DynamicPPL has both _typed_ and _untyped_ VarInfos.\nThis distinction is also described in section 4.2.4 of [our recent Turing.jl paper](https://dl.acm.org/doi/10.1145/3711897).\n\nEvaluating a model with an existing typed VarInfo is generally much faster, and once you have a typed VarInfo it is a good idea to stick with it.\nHowever, when instantiating a new VarInfo, it is often better to start with an untyped VarInfo, fill in the values, and then convert it to a typed VarInfo.\n\n::: {.callout-note}\n## Why is untyped initialisation better?\nInitialising a fresh VarInfo requires adding variables to it as they are encountered during model execution.\nThere are two main reasons for preferring untyped VarInfo: firstly, compilation time with typed VarInfo scales poorly with the number of variables; and secondly, typed VarInfos can error with certain kinds of models.\nSee [this issue](https://github.com/TuringLang/DynamicPPL.jl/issues/1062) for more information.\n:::\n\nTo see this in action, let's begin by constructing an empty _untyped_ VarInfo.\nThis does not execute the model, and so the resulting object has no stored variable values.\nIf we try to index into it, we will get an error:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "#| error: true\nv_empty_untyped = VarInfo()\nv_empty_untyped[@varname(x)]",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "::: {.callout-note}\n## `VarInfo(model)` returns a typed VarInfo\nAlthough `VarInfo()` with no arguments returns an untyped VarInfo, note that calling `VarInfo(model)` returns a typed VarInfo. This is a slightly awkward aspect of DynamicPPL's current API.\n:::\n\nTo generate new values for it, we will use `DynamicPPL.init!!` as before.",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "_, v_filled_untyped = DynamicPPL.init!!(model, v_empty_untyped, InitFromParams(Dict(@varname(x) => 5.0)))",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Now that we have filled in the untyped VarInfo, we can access parameter values, log probabilities, and so on:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "DynamicPPL.getlogprior(v_filled_untyped)",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "So, putting this all together, this is how an implementation of `logprior(model, params)` could look:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "function mylogprior(model, params)\n    # Create empty untyped VarInfo\n    v_empty_untyped = VarInfo()\n    # Fill in values from given params\n    _, v_filled_untyped = DynamicPPL.init!!(model, v_empty_untyped, InitFromParams(params))\n    # Extract log prior\n    return DynamicPPL.getlogprior(v_filled_untyped)\nend\n\nmylogprior(model, Dict(@varname(x) => 5.0))",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Notice that the above only required a single model evaluation.\n\nIf we later want to convert the untyped VarInfo into a typed VarInfo (for example, for later reuse), we can do so using `DynamicPPL.typed_varinfo`:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "v_filled_typed = DynamicPPL.typed_varinfo(v_filled_untyped)",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "This allows us to demonstrate how `VarInfo(model)` is implemented:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "function myvarinfo(model)\n    # Create empty untyped VarInfo\n    v_empty_untyped = VarInfo()\n    # Sample values from prior\n    _, v_filled_untyped = DynamicPPL.init!!(model, v_empty_untyped, InitFromPrior())\n    # Convert to typed VarInfo\n    return DynamicPPL.typed_varinfo(v_filled_untyped)\nend",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Notice here that `evaluate!!` runs much faster with a typed VarInfo than with untyped: this is why generally for repeated evaluation you should use a typed VarInfo.\nThe same is true of `init!!`.",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "with_logger(ConsoleLogger(stderr, Logging.Warn)) do\n    median(@be DynamicPPL.evaluate!!(model, v_filled_untyped))\nend",
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "with_logger(ConsoleLogger(stderr, Logging.Warn)) do\n    median(@be DynamicPPL.evaluate!!(model, v_filled_typed))\nend",
      "metadata": {},
      "execution_count": null
    }
  ],
  "nbformat_minor": 5,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia"
    },
    "kernelspec": {
      "name": "julia",
      "display_name": "Julia",
      "language": "julia"
    }
  },
  "nbformat": 4
}