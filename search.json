[
  {
    "objectID": "changelog.html",
    "href": "changelog.html",
    "title": "Changelog",
    "section": "",
    "text": "The following exported functions have been removed:\n\nconstrained_space\nget_parameter_bounds\noptim_objective\noptim_function\noptim_problem\n\nThe same functionality is now offered by the new exported functions\n\nmaximum_likelihood\nmaximum_a_posteriori"
  },
  {
    "objectID": "changelog.html#breaking-changes",
    "href": "changelog.html#breaking-changes",
    "title": "Changelog",
    "section": "",
    "text": "The following exported functions have been removed:\n\nconstrained_space\nget_parameter_bounds\noptim_objective\noptim_function\noptim_problem\n\nThe same functionality is now offered by the new exported functions\n\nmaximum_likelihood\nmaximum_a_posteriori"
  },
  {
    "objectID": "versions.html",
    "href": "versions.html",
    "title": "Latest Version",
    "section": "",
    "text": "Latest Version\n\n\n\nv0.34\nDocumentation\nChangelog\n\n\n\n\n\nPrevious Versions\n\n\n\nv0.33\nDocumentation\n\n\nv0.32\nDocumentation\n\n\n\n\n\nArchived Versions\nDocumentation for archived versions is available on our deprecated documentation site.\n\n\n\nv0.31\nDocumentation\n\n\nv0.30\nDocumentation\n\n\nv0.29\nDocumentation\n\n\nv0.28\nDocumentation\n\n\nv0.27\nDocumentation\n\n\nv0.26\nDocumentation\n\n\nv0.25\nDocumentation\n\n\nv0.24\nDocumentation\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tutorials/06-infinite-mixture-model/index.html",
    "href": "tutorials/06-infinite-mixture-model/index.html",
    "title": "Probabilistic Modelling using the Infinite Mixture Model",
    "section": "",
    "text": "In many applications it is desirable to allow the model to adjust its complexity to the amount of data. Consider for example the task of assigning objects into clusters or groups. This task often involves the specification of the number of groups. However, often times it is not known beforehand how many groups exist. Moreover, in some applictions, e.g. modelling topics in text documents or grouping species, the number of examples per group is heavy tailed. This makes it impossible to predefine the number of groups and requiring the model to form new groups when data points from previously unseen groups are observed.\nA natural approach for such applications is the use of non-parametric models. This tutorial will introduce how to use the Dirichlet process in a mixture of infinitely many Gaussians using Turing. For further information on Bayesian nonparametrics and the Dirichlet process we refer to the introduction by Zoubin Ghahramani and the book “Fundamentals of Nonparametric Bayesian Inference” by Subhashis Ghosal and Aad van der Vaart.\nusing Turing",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Infinite Mixture Model"
    ]
  },
  {
    "objectID": "tutorials/06-infinite-mixture-model/index.html#mixture-model",
    "href": "tutorials/06-infinite-mixture-model/index.html#mixture-model",
    "title": "Probabilistic Modelling using the Infinite Mixture Model",
    "section": "Mixture Model",
    "text": "Mixture Model\nBefore introducing infinite mixture models in Turing, we will briefly review the construction of finite mixture models. Subsequently, we will define how to use the Chinese restaurant process construction of a Dirichlet process for non-parametric clustering.\n\nTwo-Component Model\nFirst, consider the simple case of a mixture model with two Gaussian components with fixed covariance. The generative process of such a model can be written as:\n\\[\\begin{equation*}\n\\begin{aligned}\n\\pi_1 &\\sim \\mathrm{Beta}(a, b) \\\\\n\\pi_2 &= 1-\\pi_1 \\\\\n\\mu_1 &\\sim \\mathrm{Normal}(\\mu_0, \\Sigma_0) \\\\\n\\mu_2 &\\sim \\mathrm{Normal}(\\mu_0, \\Sigma_0) \\\\\nz_i &\\sim \\mathrm{Categorical}(\\pi_1, \\pi_2) \\\\\nx_i &\\sim \\mathrm{Normal}(\\mu_{z_i}, \\Sigma)\n\\end{aligned}\n\\end{equation*}\\]\nwhere \\(\\pi_1, \\pi_2\\) are the mixing weights of the mixture model, i.e. \\(\\pi_1 + \\pi_2 = 1\\), and \\(z_i\\) is a latent assignment of the observation \\(x_i\\) to a component (Gaussian).\nWe can implement this model in Turing for 1D data as follows:\n\n@model function two_model(x)\n    # Hyper-parameters\n    μ0 = 0.0\n    σ0 = 1.0\n\n    # Draw weights.\n    π1 ~ Beta(1, 1)\n    π2 = 1 - π1\n\n    # Draw locations of the components.\n    μ1 ~ Normal(μ0, σ0)\n    μ2 ~ Normal(μ0, σ0)\n\n    # Draw latent assignment.\n    z ~ Categorical([π1, π2])\n\n    # Draw observation from selected component.\n    if z == 1\n        x ~ Normal(μ1, 1.0)\n    else\n        x ~ Normal(μ2, 1.0)\n    end\nend\n\ntwo_model (generic function with 2 methods)\n\n\n\n\nFinite Mixture Model\nIf we have more than two components, this model can elegantly be extended using a Dirichlet distribution as prior for the mixing weights \\(\\pi_1, \\dots, \\pi_K\\). Note that the Dirichlet distribution is the multivariate generalization of the beta distribution. The resulting model can be written as:\n\\[\n\\begin{align}\n(\\pi_1, \\dots, \\pi_K) &\\sim Dirichlet(K, \\alpha) \\\\\n\\mu_k &\\sim \\mathrm{Normal}(\\mu_0, \\Sigma_0), \\;\\; \\forall k \\\\\nz &\\sim Categorical(\\pi_1, \\dots, \\pi_K) \\\\\nx &\\sim \\mathrm{Normal}(\\mu_z, \\Sigma)\n\\end{align}\n\\]\nwhich resembles the model in the Gaussian mixture model tutorial with a slightly different notation.",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Infinite Mixture Model"
    ]
  },
  {
    "objectID": "tutorials/06-infinite-mixture-model/index.html#infinite-mixture-model",
    "href": "tutorials/06-infinite-mixture-model/index.html#infinite-mixture-model",
    "title": "Probabilistic Modelling using the Infinite Mixture Model",
    "section": "Infinite Mixture Model",
    "text": "Infinite Mixture Model\nThe question now arises, is there a generalization of a Dirichlet distribution for which the dimensionality \\(K\\) is infinite, i.e. \\(K = \\infty\\)?\nBut first, to implement an infinite Gaussian mixture model in Turing, we first need to load the Turing.RandomMeasures module. RandomMeasures contains a variety of tools useful in nonparametrics.\n\nusing Turing.RandomMeasures\n\nWe now will utilize the fact that one can integrate out the mixing weights in a Gaussian mixture model allowing us to arrive at the Chinese restaurant process construction. See Carl E. Rasmussen: The Infinite Gaussian Mixture Model, NIPS (2000) for details.\nIn fact, if the mixing weights are integrated out, the conditional prior for the latent variable \\(z\\) is given by:\n\\[\np(z_i = k \\mid z_{\\not i}, \\alpha) = \\frac{n_k + \\alpha K}{N - 1 + \\alpha}\n\\]\nwhere \\(z_{\\not i}\\) are the latent assignments of all observations except observation \\(i\\). Note that we use \\(n_k\\) to denote the number of observations at component \\(k\\) excluding observation \\(i\\). The parameter \\(\\alpha\\) is the concentration parameter of the Dirichlet distribution used as prior over the mixing weights.\n\nChinese Restaurant Process\nTo obtain the Chinese restaurant process construction, we can now derive the conditional prior if \\(K \\rightarrow \\infty\\).\nFor \\(n_k &gt; 0\\) we obtain:\n\\[\np(z_i = k \\mid z_{\\not i}, \\alpha) = \\frac{n_k}{N - 1 + \\alpha}\n\\]\nand for all infinitely many clusters that are empty (combined) we get:\n\\[\np(z_i = k \\mid z_{\\not i}, \\alpha) = \\frac{\\alpha}{N - 1 + \\alpha}\n\\]\nThose equations show that the conditional prior for component assignments is proportional to the number of such observations, meaning that the Chinese restaurant process has a rich get richer property.\nTo get a better understanding of this property, we can plot the cluster choosen by for each new observation drawn from the conditional prior.\n\n# Concentration parameter.\nα = 10.0\n\n# Random measure, e.g. Dirichlet process.\nrpm = DirichletProcess(α)\n\n# Cluster assignments for each observation.\nz = Vector{Int}()\n\n# Maximum number of observations we observe.\nNmax = 500\n\nfor i in 1:Nmax\n    # Number of observations per cluster.\n    K = isempty(z) ? 0 : maximum(z)\n    nk = Vector{Int}(map(k -&gt; sum(z .== k), 1:K))\n\n    # Draw new assignment.\n    push!(z, rand(ChineseRestaurantProcess(rpm, nk)))\nend\n\n\nusing Plots\n\n# Plot the cluster assignments over time \n@gif for i in 1:Nmax\n    scatter(\n        collect(1:i),\n        z[1:i];\n        markersize=2,\n        xlabel=\"observation (i)\",\n        ylabel=\"cluster (k)\",\n        legend=false,\n    )\nend\n\nGKS: cannot open display - headless operation mode active\n[ Info: Saved animation to /tmp/jl_GLg3Q1uJCn.gif\n\n\n\n\n\nFurther, we can see that the number of clusters is logarithmic in the number of observations and data points. This is a side-effect of the “rich-get-richer” phenomenon, i.e. we expect large clusters and thus the number of clusters has to be smaller than the number of observations.\n\\[\n\\mathbb{E}[K \\mid N] \\approx \\alpha \\cdot log \\big(1 + \\frac{N}{\\alpha}\\big)\n\\]\nWe can see from the equation that the concentration parameter \\(\\alpha\\) allows us to control the number of clusters formed a priori.\nIn Turing we can implement an infinite Gaussian mixture model using the Chinese restaurant process construction of a Dirichlet process as follows:\n\n@model function infiniteGMM(x)\n    # Hyper-parameters, i.e. concentration parameter and parameters of H.\n    α = 1.0\n    μ0 = 0.0\n    σ0 = 1.0\n\n    # Define random measure, e.g. Dirichlet process.\n    rpm = DirichletProcess(α)\n\n    # Define the base distribution, i.e. expected value of the Dirichlet process.\n    H = Normal(μ0, σ0)\n\n    # Latent assignment.\n    z = tzeros(Int, length(x))\n\n    # Locations of the infinitely many clusters.\n    μ = tzeros(Float64, 0)\n\n    for i in 1:length(x)\n\n        # Number of clusters.\n        K = maximum(z)\n        nk = Vector{Int}(map(k -&gt; sum(z .== k), 1:K))\n\n        # Draw the latent assignment.\n        z[i] ~ ChineseRestaurantProcess(rpm, nk)\n\n        # Create a new cluster?\n        if z[i] &gt; K\n            push!(μ, 0.0)\n\n            # Draw location of new cluster.\n            μ[z[i]] ~ H\n        end\n\n        # Draw observation.\n        x[i] ~ Normal(μ[z[i]], 1.0)\n    end\nend\n\ninfiniteGMM (generic function with 2 methods)\n\n\nWe can now use Turing to infer the assignments of some data points. First, we will create some random data that comes from three clusters, with means of 0, -5, and 10.\n\nusing Plots, Random\n\n# Generate some test data.\nRandom.seed!(1)\ndata = vcat(randn(10), randn(10) .- 5, randn(10) .+ 10)\ndata .-= mean(data)\ndata /= std(data);\n\nNext, we’ll sample from our posterior using SMC.\n\nsetprogress!(false)\n\n\n# MCMC sampling\nRandom.seed!(2)\niterations = 1000\nmodel_fun = infiniteGMM(data);\nchain = sample(model_fun, SMC(), iterations);\n\nFinally, we can plot the number of clusters in each sample.\n\n# Extract the number of clusters for each sample of the Markov chain.\nk = map(\n    t -&gt; length(unique(vec(chain[t, MCMCChains.namesingroup(chain, :z), :].value))),\n    1:iterations,\n);\n\n# Visualize the number of clusters.\nplot(k; xlabel=\"Iteration\", ylabel=\"Number of clusters\", label=\"Chain 1\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf we visualize the histogram of the number of clusters sampled from our posterior, we observe that the model seems to prefer 3 clusters, which is the true number of clusters. Note that the number of clusters in a Dirichlet process mixture model is not limited a priori and will grow to infinity with probability one. However, if conditioned on data the posterior will concentrate on a finite number of clusters enforcing the resulting model to have a finite amount of clusters. It is, however, not given that the posterior of a Dirichlet process Gaussian mixture model converges to the true number of clusters, given that data comes from a finite mixture model. See Jeffrey Miller and Matthew Harrison: A simple example of Dirichlet process mixture inconsitency for the number of components for details.\n\nhistogram(k; xlabel=\"Number of clusters\", legend=false)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOne issue with the Chinese restaurant process construction is that the number of latent parameters we need to sample scales with the number of observations. It may be desirable to use alternative constructions in certain cases. Alternative methods of constructing a Dirichlet process can be employed via the following representations:\nSize-Biased Sampling Process\n\\[\nj_k \\sim \\mathrm{Beta}(1, \\alpha) \\cdot \\mathrm{surplus}\n\\]\nStick-Breaking Process \\[\nv_k \\sim \\mathrm{Beta}(1, \\alpha)\n\\]\nChinese Restaurant Process \\[\np(z_n = k | z_{1:n-1}) \\propto \\begin{cases}\n\\frac{m_k}{n-1+\\alpha}, \\text{ if } m_k &gt; 0\\\\\\\n\\frac{\\alpha}{n-1+\\alpha}\n\\end{cases}\n\\]\nFor more details see this article.",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Infinite Mixture Model"
    ]
  },
  {
    "objectID": "tutorials/docs-15-using-turing-sampler-viz/index.html",
    "href": "tutorials/docs-15-using-turing-sampler-viz/index.html",
    "title": "Sampler Visualization",
    "section": "",
    "text": "For each sampler, we will use the same code to plot sampler paths. The block below loads the relevant libraries and defines a function for plotting the sampler’s trajectory across the posterior.\nThe Turing model definition used here is not especially practical, but it is designed in such a way as to produce visually interesting posterior surfaces to show how different samplers move along the distribution.\n\nENV[\"GKS_ENCODING\"] = \"utf-8\" # Allows the use of unicode characters in Plots.jl\nusing Plots\nusing StatsPlots\nusing Turing\nusing Random\nusing Bijectors\n\n# Set a seed.\nRandom.seed!(0)\n\n# Define a strange model.\n@model function gdemo(x)\n    s² ~ InverseGamma(2, 3)\n    m ~ Normal(0, sqrt(s²))\n    bumps = sin(m) + cos(m)\n    m = m + 5 * bumps\n    for i in eachindex(x)\n        x[i] ~ Normal(m, sqrt(s²))\n    end\n    return s², m\nend\n\n# Define our data points.\nx = [1.5, 2.0, 13.0, 2.1, 0.0]\n\n# Set up the model call, sample from the prior.\nmodel = gdemo(x)\n\n# Evaluate surface at coordinates.\nevaluate(m1, m2) = logjoint(model, (m=m2, s²=invlink.(Ref(InverseGamma(2, 3)), m1)))\n\nfunction plot_sampler(chain; label=\"\")\n    # Extract values from chain.\n    val = get(chain, [:s², :m, :lp])\n    ss = link.(Ref(InverseGamma(2, 3)), val.s²)\n    ms = val.m\n    lps = val.lp\n\n    # How many surface points to sample.\n    granularity = 100\n\n    # Range start/stop points.\n    spread = 0.5\n    σ_start = minimum(ss) - spread * std(ss)\n    σ_stop = maximum(ss) + spread * std(ss)\n    μ_start = minimum(ms) - spread * std(ms)\n    μ_stop = maximum(ms) + spread * std(ms)\n    σ_rng = collect(range(σ_start; stop=σ_stop, length=granularity))\n    μ_rng = collect(range(μ_start; stop=μ_stop, length=granularity))\n\n    # Make surface plot.\n    p = surface(\n        σ_rng,\n        μ_rng,\n        evaluate;\n        camera=(30, 65),\n        #   ticks=nothing,\n        colorbar=false,\n        color=:inferno,\n        title=label,\n    )\n\n    line_range = 1:length(ms)\n\n    scatter3d!(\n        ss[line_range],\n        ms[line_range],\n        lps[line_range];\n        mc=:viridis,\n        marker_z=collect(line_range),\n        msw=0,\n        legend=false,\n        colorbar=false,\n        alpha=0.5,\n        xlabel=\"σ\",\n        ylabel=\"μ\",\n        zlabel=\"Log probability\",\n        title=label,\n    )\n\n    return p\nend;\n\n\nsetprogress!(false)",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Sampler Visualization"
    ]
  },
  {
    "objectID": "tutorials/docs-15-using-turing-sampler-viz/index.html#introduction",
    "href": "tutorials/docs-15-using-turing-sampler-viz/index.html#introduction",
    "title": "Sampler Visualization",
    "section": "",
    "text": "For each sampler, we will use the same code to plot sampler paths. The block below loads the relevant libraries and defines a function for plotting the sampler’s trajectory across the posterior.\nThe Turing model definition used here is not especially practical, but it is designed in such a way as to produce visually interesting posterior surfaces to show how different samplers move along the distribution.\n\nENV[\"GKS_ENCODING\"] = \"utf-8\" # Allows the use of unicode characters in Plots.jl\nusing Plots\nusing StatsPlots\nusing Turing\nusing Random\nusing Bijectors\n\n# Set a seed.\nRandom.seed!(0)\n\n# Define a strange model.\n@model function gdemo(x)\n    s² ~ InverseGamma(2, 3)\n    m ~ Normal(0, sqrt(s²))\n    bumps = sin(m) + cos(m)\n    m = m + 5 * bumps\n    for i in eachindex(x)\n        x[i] ~ Normal(m, sqrt(s²))\n    end\n    return s², m\nend\n\n# Define our data points.\nx = [1.5, 2.0, 13.0, 2.1, 0.0]\n\n# Set up the model call, sample from the prior.\nmodel = gdemo(x)\n\n# Evaluate surface at coordinates.\nevaluate(m1, m2) = logjoint(model, (m=m2, s²=invlink.(Ref(InverseGamma(2, 3)), m1)))\n\nfunction plot_sampler(chain; label=\"\")\n    # Extract values from chain.\n    val = get(chain, [:s², :m, :lp])\n    ss = link.(Ref(InverseGamma(2, 3)), val.s²)\n    ms = val.m\n    lps = val.lp\n\n    # How many surface points to sample.\n    granularity = 100\n\n    # Range start/stop points.\n    spread = 0.5\n    σ_start = minimum(ss) - spread * std(ss)\n    σ_stop = maximum(ss) + spread * std(ss)\n    μ_start = minimum(ms) - spread * std(ms)\n    μ_stop = maximum(ms) + spread * std(ms)\n    σ_rng = collect(range(σ_start; stop=σ_stop, length=granularity))\n    μ_rng = collect(range(μ_start; stop=μ_stop, length=granularity))\n\n    # Make surface plot.\n    p = surface(\n        σ_rng,\n        μ_rng,\n        evaluate;\n        camera=(30, 65),\n        #   ticks=nothing,\n        colorbar=false,\n        color=:inferno,\n        title=label,\n    )\n\n    line_range = 1:length(ms)\n\n    scatter3d!(\n        ss[line_range],\n        ms[line_range],\n        lps[line_range];\n        mc=:viridis,\n        marker_z=collect(line_range),\n        msw=0,\n        legend=false,\n        colorbar=false,\n        alpha=0.5,\n        xlabel=\"σ\",\n        ylabel=\"μ\",\n        zlabel=\"Log probability\",\n        title=label,\n    )\n\n    return p\nend;\n\n\nsetprogress!(false)",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Sampler Visualization"
    ]
  },
  {
    "objectID": "tutorials/docs-15-using-turing-sampler-viz/index.html#samplers",
    "href": "tutorials/docs-15-using-turing-sampler-viz/index.html#samplers",
    "title": "Sampler Visualization",
    "section": "Samplers",
    "text": "Samplers\n\nGibbs\nGibbs sampling tends to exhibit a “jittery” trajectory. The example below combines HMC and PG sampling to traverse the posterior.\n\nc = sample(model, Gibbs(HMC(0.01, 5, :s²), PG(20, :m)), 1000)\nplot_sampler(c)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHMC\nHamiltonian Monte Carlo (HMC) sampling is a typical sampler to use, as it tends to be fairly good at converging in a efficient manner. It can often be tricky to set the correct parameters for this sampler however, and the NUTS sampler is often easier to run if you don’t want to spend too much time fiddling with step size and and the number of steps to take. Note however that HMC does not explore the positive values μ very well, likely due to the leapfrog and step size parameter settings.\n\nc = sample(model, HMC(0.01, 10), 1000)\nplot_sampler(c)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHMCDA\nThe HMCDA sampler is an implementation of the Hamiltonian Monte Carlo with Dual Averaging algorithm found in the paper “The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo” by Hoffman and Gelman (2011). The paper can be found on arXiv for the interested reader.\n\nc = sample(model, HMCDA(200, 0.65, 0.3), 1000)\nplot_sampler(c)\n\n┌ Info: Found initial step size\n└   ϵ = 0.4\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMH\nMetropolis-Hastings (MH) sampling is one of the earliest Markov Chain Monte Carlo methods. MH sampling does not “move” a lot, unlike many of the other samplers implemented in Turing. Typically a much longer chain is required to converge to an appropriate parameter estimate.\nThe plot below only uses 1,000 iterations of Metropolis-Hastings.\n\nc = sample(model, MH(), 1000)\nplot_sampler(c)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs you can see, the MH sampler doesn’t move parameter estimates very often.\n\n\nNUTS\nThe No U-Turn Sampler (NUTS) is an implementation of the algorithm found in the paper “The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo” by Hoffman and Gelman (2011). The paper can be found on arXiv for the interested reader.\nNUTS tends to be very good at traversing complex posteriors quickly.\n\nc = sample(model, NUTS(0.65), 1000)\nplot_sampler(c)\n\n┌ Info: Found initial step size\n└   ϵ = 0.2\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe only parameter that needs to be set other than the number of iterations to run is the target acceptance rate. In the Hoffman and Gelman paper, they note that a target acceptance rate of 0.65 is typical.\nHere is a plot showing a very high acceptance rate. Note that it appears to “stick” to a mode and is not particularly good at exploring the posterior as compared to the 0.65 target acceptance ratio case.\n\nc = sample(model, NUTS(0.95), 1000)\nplot_sampler(c)\n\n┌ Info: Found initial step size\n└   ϵ = 0.4\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn exceptionally low acceptance rate will show very few moves on the posterior:\n\nc = sample(model, NUTS(0.2), 1000)\nplot_sampler(c)\n\n┌ Info: Found initial step size\n└   ϵ = 0.4\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPG\nThe Particle Gibbs (PG) sampler is an implementation of an algorithm from the paper “Particle Markov chain Monte Carlo methods” by Andrieu, Doucet, and Holenstein (2010). The interested reader can learn more here.\nThe two parameters are the number of particles, and the number of iterations. The plot below shows the use of 20 particles.\n\nc = sample(model, PG(20), 1000)\nplot_sampler(c)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNext, we plot using 50 particles.\n\nc = sample(model, PG(50), 1000)\nplot_sampler(c)",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Sampler Visualization"
    ]
  },
  {
    "objectID": "tutorials/usage-modifying-logprob/index.html",
    "href": "tutorials/usage-modifying-logprob/index.html",
    "title": "Modifying the Log Probability",
    "section": "",
    "text": "Turing accumulates log probabilities internally in an internal data structure that is accessible through the internal variable __varinfo__ inside of the model definition. To avoid users having to deal with internal data structures, Turing provides the Turing.@addlogprob! macro which increases the accumulated log probability. For instance, this allows you to include arbitrary terms in the likelihood\n\nusing Turing\n\nmyloglikelihood(x, μ) = loglikelihood(Normal(μ, 1), x)\n\n@model function demo(x)\n    μ ~ Normal()\n    Turing.@addlogprob! myloglikelihood(x, μ)\nend\n\ndemo (generic function with 2 methods)\n\n\nand to force a sampler to reject a sample:\n\nusing Turing\nusing LinearAlgebra\n\n@model function demo(x)\n    m ~ MvNormal(zero(x), I)\n    if dot(m, x) &lt; 0\n        Turing.@addlogprob! -Inf\n        # Exit the model evaluation early\n        return nothing\n    end\n\n    x ~ MvNormal(m, I)\n    return nothing\nend\n\ndemo (generic function with 2 methods)\n\n\nNote that @addlogprob! always increases the accumulated log probability, regardless of the provided sampling context. For instance, if you do not want to apply Turing.@addlogprob! when evaluating the prior of your model but only when computing the log likelihood and the log joint probability, then you should check the type of the internal variable __context_, as in the following example:\n\nif DynamicPPL.leafcontext(__context__) !== Turing.PriorContext()\n    Turing.@addlogprob! myloglikelihood(x, μ)\nend\n\n\n\n\n Back to top",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Modifying the Log Probability"
    ]
  },
  {
    "objectID": "tutorials/09-variational-inference/index.html",
    "href": "tutorials/09-variational-inference/index.html",
    "title": "Variational inference (VI) in Turing.jl",
    "section": "",
    "text": "In this post we’ll have a look at what’s know as variational inference (VI), a family of approximate Bayesian inference methods, and how to use it in Turing.jl as an alternative to other approaches such as MCMC. In particular, we will focus on one of the more standard VI methods called Automatic Differentation Variational Inference (ADVI).\nHere we will focus on how to use VI in Turing and not much on the theory underlying VI. If you are interested in understanding the mathematics you can checkout our write-up or any other resource online (there a lot of great ones).\nUsing VI in Turing.jl is very straight forward. If model denotes a definition of a Turing.Model, performing VI is as simple as\nm = model(data...) # instantiate model on the data\nq = vi(m, vi_alg)  # perform VI on `m` using the VI method `vi_alg`, which returns a `VariationalPosterior`\nThus it’s no more work than standard MCMC sampling in Turing.\nTo get a bit more into what we can do with vi, we’ll first have a look at a simple example and then we’ll reproduce the tutorial on Bayesian linear regression using VI instead of MCMC. Finally we’ll look at some of the different parameters of vi and how you for example can use your own custom variational family.\nWe first import the packages to be used:\nusing Random\nusing Turing\nusing Turing: Variational\nusing StatsPlots, Measures\n\nRandom.seed!(42);",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Variational Inference"
    ]
  },
  {
    "objectID": "tutorials/09-variational-inference/index.html#simple-example-normal-gamma-conjugate-model",
    "href": "tutorials/09-variational-inference/index.html#simple-example-normal-gamma-conjugate-model",
    "title": "Variational inference (VI) in Turing.jl",
    "section": "Simple example: Normal-Gamma conjugate model",
    "text": "Simple example: Normal-Gamma conjugate model\nThe Normal-(Inverse)Gamma conjugate model is defined by the following generative process\n\\[\\begin{align}\ns &\\sim \\mathrm{InverseGamma}(2, 3) \\\\\nm &\\sim \\mathcal{N}(0, s) \\\\\nx_i &\\overset{\\text{i.i.d.}}{=} \\mathcal{N}(m, s), \\quad i = 1, \\dots, n\n\\end{align}\\]\nRecall that conjugate refers to the fact that we can obtain a closed-form expression for the posterior. Of course one wouldn’t use something like variational inference for a conjugate model, but it’s useful as a simple demonstration as we can compare the result to the true posterior.\nFirst we generate some synthetic data, define the Turing.Model and instantiate the model on the data:\n\n# generate data\nx = randn(2000);\n\n\n@model function model(x)\n    s ~ InverseGamma(2, 3)\n    m ~ Normal(0.0, sqrt(s))\n    for i in 1:length(x)\n        x[i] ~ Normal(m, sqrt(s))\n    end\nend;\n\n\n# Instantiate model\nm = model(x);\n\nNow we’ll produce some samples from the posterior using a MCMC method, which in constrast to VI is guaranteed to converge to the exact posterior (as the number of samples go to infinity).\nWe’ll produce 10 000 samples with 200 steps used for adaptation and a target acceptance rate of 0.65\nIf you don’t understand what “adaptation” or “target acceptance rate” refers to, all you really need to know is that NUTS is known to be one of the most accurate and efficient samplers (when applicable) while requiring little to no hand-tuning to work well.\n\nsetprogress!(false)\n\n\nsamples_nuts = sample(m, NUTS(), 10_000);\n\n┌ Info: Found initial step size\n└   ϵ = 0.025\n\n\nNow let’s try VI. The most important function you need to now about to do VI in Turing is vi:\n\n@doc(Variational.vi)\n\nvi(model, alg::VariationalInference)\nvi(model, alg::VariationalInference, q::VariationalPosterior)\nvi(model, alg::VariationalInference, getq::Function, θ::AbstractArray)\nConstructs the variational posterior from the model and performs the optimization following the configuration of the given VariationalInference instance.\nArguments\n\nmodel: Turing.Model or Function z ↦ log p(x, z) where x denotes the observations\n\nalg: the VI algorithm used\n\nq: a VariationalPosterior for which it is assumed a specialized implementation of the variational objective used exists.\n\ngetq: function taking parameters θ as input and returns a VariationalPosterior\n\nθ: only required if getq is used, in which case it is the initial parameters for the variational posterior\n\n\n\n\n\n\n\nAdditionally, you can pass\n\nan initial variational posterior q, for which we assume there exists a implementation of update(::typeof(q), θ::AbstractVector) returning an updated posterior q with parameters θ.\na function mapping \\(\\theta \\mapsto q_{\\theta}\\) (denoted above getq) together with initial parameters θ. This provides more flexibility in the types of variational families that we can use, and can sometimes be slightly more convenient for quick and rough work.\n\nBy default, i.e. when calling vi(m, advi), Turing use a mean-field approximation with a multivariate normal as the base-distribution. Mean-field refers to the fact that we assume all the latent variables to be independent. This the “standard” ADVI approach; see Automatic Differentiation Variational Inference (2016) for more. In Turing, one can obtain such a mean-field approximation by calling Variational.meanfield(model) for which there exists an internal implementation for update:\n\n@doc(Variational.meanfield)\n\nmeanfield([rng, ]model::Model)\nCreates a mean-field approximation with multivariate normal as underlying distribution.\n\n\n\n\n\nCurrently the only implementation of VariationalInference available is ADVI, which is very convenient and applicable as long as your Model is differentiable with respect to the variational parameters, that is, the parameters of your variational distribution, e.g. mean and variance in the mean-field approximation.\n\n@doc(Variational.ADVI)\n\nstruct ADVI{AD} &lt;: AdvancedVI.VariationalInference{AD}\nAutomatic Differentiation Variational Inference (ADVI) with automatic differentiation backend AD.\nFields\n\nsamples_per_step::Int64: Number of samples used to estimate the ELBO in each optimization step.\n\nmax_iters::Int64: Maximum number of gradient steps.\n\nadtype::Any: AD backend used for automatic differentiation.\n\n\n\n\n\n\n\nTo perform VI on the model m using 10 samples for gradient estimation and taking 1000 gradient steps is then as simple as:\n\n# ADVI\nadvi = ADVI(10, 1000)\nq = vi(m, advi);\n\n┌ Info: [ADVI] Should only be seen once: optimizer created for θ\n└   objectid(θ) = 0x04c0026c28ac70b6\n\n\nUnfortunately, for such a small problem Turing’s new NUTS sampler is so efficient now that it’s not that much more efficient to use ADVI. So, so very unfortunate…\nWith that being said, this is not the case in general. For very complex models we’ll later find that ADVI produces very reasonable results in a much shorter time than NUTS.\nAnd one significant advantage of using vi is that we can sample from the resulting q with ease. In fact, the result of the vi call is a TransformedDistribution from Bijectors.jl, and it implements the Distributions.jl interface for a Distribution:\n\nq isa MultivariateDistribution\n\ntrue\n\n\nThis means that we can call rand to sample from the variational posterior q\n\nhistogram(rand(q, 1_000)[1, :])\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nand logpdf to compute the log-probability\n\nlogpdf(q, rand(q))\n\n5.286257415630635\n\n\nLet’s check the first and second moments of the data to see how our approximation compares to the point-estimates form the data:\n\nvar(x), mean(x)\n\n(0.9705994811739622, -0.001561291940268486)\n\n\n\n(mean(rand(q, 1000); dims=2)...,)\n\n(0.9786919491900463, 0.0018335888218574692)\n\n\nThat’s pretty close! But we’re Bayesian so we’re not interested in just matching the mean. Let’s instead look the actual density q.\nFor that we need samples:\n\nsamples = rand(q, 10000);\nsize(samples)\n\n(2, 10000)\n\n\n\np1 = histogram(\n    samples[1, :]; bins=100, normed=true, alpha=0.2, color=:blue, label=\"\", ylabel=\"density\"\n)\ndensity!(samples[1, :]; label=\"s (ADVI)\", color=:blue, linewidth=2)\ndensity!(samples_nuts, :s; label=\"s (NUTS)\", color=:green, linewidth=2)\nvline!([var(x)]; label=\"s (data)\", color=:black)\nvline!([mean(samples[1, :])]; color=:blue, label=\"\")\n\np2 = histogram(\n    samples[2, :]; bins=100, normed=true, alpha=0.2, color=:blue, label=\"\", ylabel=\"density\"\n)\ndensity!(samples[2, :]; label=\"m (ADVI)\", color=:blue, linewidth=2)\ndensity!(samples_nuts, :m; label=\"m (NUTS)\", color=:green, linewidth=2)\nvline!([mean(x)]; color=:black, label=\"m (data)\")\nvline!([mean(samples[2, :])]; color=:blue, label=\"\")\n\nplot(p1, p2; layout=(2, 1), size=(900, 500), legend=true)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor this particular Model, we can in fact obtain the posterior of the latent variables in closed form. This allows us to compare both NUTS and ADVI to the true posterior \\(p(s, m \\mid x_1, \\ldots, x_n)\\).\nThe code below is just work to get the marginals \\(p(s \\mid x_1, \\ldots, x_n)\\) and \\(p(m \\mid x_1, \\ldots, x_n)\\). Feel free to skip it.\n\n# closed form computation of the Normal-inverse-gamma posterior\n# based on \"Conjugate Bayesian analysis of the Gaussian distribution\" by Murphy\nfunction posterior(μ₀::Real, κ₀::Real, α₀::Real, β₀::Real, x::AbstractVector{&lt;:Real})\n    # Compute summary statistics\n    n = length(x)\n    x̄ = mean(x)\n    sum_of_squares = sum(xi -&gt; (xi - x̄)^2, x)\n\n    # Compute parameters of the posterior\n    κₙ = κ₀ + n\n    μₙ = (κ₀ * μ₀ + n * x̄) / κₙ\n    αₙ = α₀ + n / 2\n    βₙ = β₀ + (sum_of_squares + n * κ₀ / κₙ * (x̄ - μ₀)^2) / 2\n\n    return μₙ, κₙ, αₙ, βₙ\nend\nμₙ, κₙ, αₙ, βₙ = posterior(0.0, 1.0, 2.0, 3.0, x)\n\n# marginal distribution of σ²\n# cf. Eq. (90) in \"Conjugate Bayesian analysis of the Gaussian distribution\" by Murphy\np_σ² = InverseGamma(αₙ, βₙ)\np_σ²_pdf = z -&gt; pdf(p_σ², z)\n\n# marginal of μ\n# Eq. (91) in \"Conjugate Bayesian analysis of the Gaussian distribution\" by Murphy\np_μ = μₙ + sqrt(βₙ / (αₙ * κₙ)) * TDist(2 * αₙ)\np_μ_pdf = z -&gt; pdf(p_μ, z)\n\n# posterior plots\np1 = plot()\nhistogram!(samples[1, :]; bins=100, normed=true, alpha=0.2, color=:blue, label=\"\")\ndensity!(samples[1, :]; label=\"s (ADVI)\", color=:blue)\ndensity!(samples_nuts, :s; label=\"s (NUTS)\", color=:green)\nvline!([mean(samples[1, :])]; linewidth=1.5, color=:blue, label=\"\")\nplot!(range(0.75, 1.35; length=1_001), p_σ²_pdf; label=\"s (posterior)\", color=:red)\nvline!([var(x)]; label=\"s (data)\", linewidth=1.5, color=:black, alpha=0.7)\nxlims!(0.75, 1.35)\n\np2 = plot()\nhistogram!(samples[2, :]; bins=100, normed=true, alpha=0.2, color=:blue, label=\"\")\ndensity!(samples[2, :]; label=\"m (ADVI)\", color=:blue)\ndensity!(samples_nuts, :m; label=\"m (NUTS)\", color=:green)\nvline!([mean(samples[2, :])]; linewidth=1.5, color=:blue, label=\"\")\nplot!(range(-0.25, 0.25; length=1_001), p_μ_pdf; label=\"m (posterior)\", color=:red)\nvline!([mean(x)]; label=\"m (data)\", linewidth=1.5, color=:black, alpha=0.7)\nxlims!(-0.25, 0.25)\n\nplot(p1, p2; layout=(2, 1), size=(900, 500))",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Variational Inference"
    ]
  },
  {
    "objectID": "tutorials/09-variational-inference/index.html#bayesian-linear-regression-example-using-advi",
    "href": "tutorials/09-variational-inference/index.html#bayesian-linear-regression-example-using-advi",
    "title": "Variational inference (VI) in Turing.jl",
    "section": "Bayesian linear regression example using ADVI",
    "text": "Bayesian linear regression example using ADVI\nThis is simply a duplication of the tutorial on Bayesian linear regression (much of the code is directly lifted), but now with the addition of an approximate posterior obtained using ADVI.\nAs we’ll see, there is really no additional work required to apply variational inference to a more complex Model.\n\nRandom.seed!(1);\n\n\nusing FillArrays\nusing RDatasets\n\nusing LinearAlgebra\n\n\n# Import the \"Default\" dataset.\ndata = RDatasets.dataset(\"datasets\", \"mtcars\");\n\n# Show the first six rows of the dataset.\nfirst(data, 6)\n\n6×12 DataFrame\n\n\n\nRow\nModel\nMPG\nCyl\nDisp\nHP\nDRat\nWT\nQSec\nVS\nAM\nGear\nCarb\n\n\n\nString31\nFloat64\nInt64\nFloat64\nInt64\nFloat64\nFloat64\nFloat64\nInt64\nInt64\nInt64\nInt64\n\n\n\n\n1\nMazda RX4\n21.0\n6\n160.0\n110\n3.9\n2.62\n16.46\n0\n1\n4\n4\n\n\n2\nMazda RX4 Wag\n21.0\n6\n160.0\n110\n3.9\n2.875\n17.02\n0\n1\n4\n4\n\n\n3\nDatsun 710\n22.8\n4\n108.0\n93\n3.85\n2.32\n18.61\n1\n1\n4\n1\n\n\n4\nHornet 4 Drive\n21.4\n6\n258.0\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n5\nHornet Sportabout\n18.7\n8\n360.0\n175\n3.15\n3.44\n17.02\n0\n0\n3\n2\n\n\n6\nValiant\n18.1\n6\n225.0\n105\n2.76\n3.46\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\n\n# Function to split samples.\nfunction split_data(df, at=0.70)\n    r = size(df, 1)\n    index = Int(round(r * at))\n    train = df[1:index, :]\n    test = df[(index + 1):end, :]\n    return train, test\nend\n\n# A handy helper function to rescale our dataset.\nfunction standardize(x)\n    return (x .- mean(x; dims=1)) ./ std(x; dims=1)\nend\n\nfunction standardize(x, orig)\n    return (x .- mean(orig; dims=1)) ./ std(orig; dims=1)\nend\n\n# Another helper function to unstandardize our datasets.\nfunction unstandardize(x, orig)\n    return x .* std(orig; dims=1) .+ mean(orig; dims=1)\nend\n\nfunction unstandardize(x, mean_train, std_train)\n    return x .* std_train .+ mean_train\nend\n\nunstandardize (generic function with 2 methods)\n\n\n\n# Remove the model column.\nselect!(data, Not(:Model))\n\n# Split our dataset 70%/30% into training/test sets.\ntrain, test = split_data(data, 0.7)\ntrain_unstandardized = copy(train)\n\n# Standardize both datasets.\nstd_train = standardize(Matrix(train))\nstd_test = standardize(Matrix(test), Matrix(train))\n\n# Save dataframe versions of our dataset.\ntrain_cut = DataFrame(std_train, names(data))\ntest_cut = DataFrame(std_test, names(data))\n\n# Create our labels. These are the values we are trying to predict.\ntrain_label = train_cut[:, :MPG]\ntest_label = test_cut[:, :MPG]\n\n# Get the list of columns to keep.\nremove_names = filter(x -&gt; !in(x, [\"MPG\"]), names(data))\n\n# Filter the test and train sets.\ntrain = Matrix(train_cut[:, remove_names]);\ntest = Matrix(test_cut[:, remove_names]);\n\n\n# Bayesian linear regression.\n@model function linear_regression(x, y, n_obs, n_vars, ::Type{T}=Vector{Float64}) where {T}\n    # Set variance prior.\n    σ² ~ truncated(Normal(0, 100), 0, Inf)\n\n    # Set intercept prior.\n    intercept ~ Normal(0, 3)\n\n    # Set the priors on our coefficients.\n    coefficients ~ MvNormal(Zeros(n_vars), 10.0 * I)\n\n    # Calculate all the mu terms.\n    mu = intercept .+ x * coefficients\n    return y ~ MvNormal(mu, σ² * I)\nend;\n\n\nn_obs, n_vars = size(train)\nm = linear_regression(train, train_label, n_obs, n_vars);",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Variational Inference"
    ]
  },
  {
    "objectID": "tutorials/09-variational-inference/index.html#performing-vi",
    "href": "tutorials/09-variational-inference/index.html#performing-vi",
    "title": "Variational inference (VI) in Turing.jl",
    "section": "Performing VI",
    "text": "Performing VI\nFirst we define the initial variational distribution, or, equivalently, the family of distributions to consider. We’re going to use the same mean-field approximation as Turing will use by default when we call vi(m, advi), which we obtain by calling Variational.meanfield. This returns a TransformedDistribution with a TuringDiagMvNormal as the underlying distribution and the transformation mapping from the reals to the domain of the latent variables.\n\nq0 = Variational.meanfield(m)\ntypeof(q0)\n\nMultivariateTransformed{TuringDiagMvNormal{Vector{Float64}, Vector{Float64}}, Stacked{Vector{Any}, Vector{UnitRange{Int64}}}} (alias for Bijectors.TransformedDistribution{DistributionsAD.TuringDiagMvNormal{Array{Float64, 1}, Array{Float64, 1}}, Stacked{Array{Any, 1}, Array{UnitRange{Int64}, 1}}, ArrayLikeVariate{1}})\n\n\n\nadvi = ADVI(10, 10_000)\n\nADVI{AutoForwardDiff{nothing, Nothing}}(10, 10000, AutoForwardDiff{nothing, Nothing}(nothing))\n\n\nTuring also provides a couple of different optimizers:\n\nTruncatedADAGrad (default)\nDecayedADAGrad as these are well-suited for problems with high-variance stochastic objectives, which is usually what the ELBO ends up being at different times in our optimization process.\n\nWith that being said, thanks to Requires.jl, if we add a using Flux prior to using Turing we can also make use of all the optimizers in Flux, e.g. ADAM, without any additional changes to your code! For example:\n\nusing Flux, Turing\nusing Turing.Variational\n\nvi(m, advi; optimizer=Flux.ADAM())\n\njust works.\nFor this problem we’ll use the DecayedADAGrad from Turing:\n\nopt = Variational.DecayedADAGrad(1e-2, 1.1, 0.9)\n\nAdvancedVI.DecayedADAGrad(0.01, 1.1, 0.9, IdDict{Any, Any}())\n\n\n\nq = vi(m, advi, q0; optimizer=opt)\ntypeof(q)\n\nMultivariateTransformed{TuringDiagMvNormal{Vector{Float64}, Vector{Float64}}, Stacked{Vector{Any}, Vector{UnitRange{Int64}}}} (alias for Bijectors.TransformedDistribution{DistributionsAD.TuringDiagMvNormal{Array{Float64, 1}, Array{Float64, 1}}, Stacked{Array{Any, 1}, Array{UnitRange{Int64}, 1}}, ArrayLikeVariate{1}})\n\n\nNote: as mentioned before, we internally define a update(q::TransformedDistribution{&lt;:TuringDiagMvNormal}, θ::AbstractVector) method which takes in the current variational approximation q together with new parameters z and returns the new variational approximation. This is required so that we can actually update the Distribution object after each optimization step.\nAlternatively, we can instead provide the mapping \\(\\theta \\mapsto q_{\\theta}\\) directly together with initial parameters using the signature vi(m, advi, getq, θ_init) as mentioned earlier. We’ll see an explicit example of this later on!\nTo compute statistics for our approximation we need samples:\n\nz = rand(q, 10_000);\n\nNow we can for example look at the average\n\navg = vec(mean(z; dims=2))\n\n12-element Vector{Float64}:\n  0.21552003804685096\n -0.0002081503176371776\n  0.37286836459744244\n -0.10511174644443397\n -0.07311313042765602\n  0.610946269436176\n  0.01089622391060304\n  0.08171466259953368\n -0.07307258841268861\n  0.12252931457781585\n  0.18537557756434636\n -0.6189871448165513\n\n\nThe vector has the same ordering as the model, e.g. in this case σ² has index 1, intercept has index 2 and coefficients has indices 3:12. If you forget or you might want to do something programmatically with the result, you can obtain the sym → indices mapping as follows:\n\n_, sym2range = bijector(m, Val(true));\nsym2range\n\n(intercept = UnitRange{Int64}[2:2], σ² = UnitRange{Int64}[1:1], coefficients = UnitRange{Int64}[3:12])\n\n\nFor example, we can check the sample distribution and mean value of σ²:\n\nhistogram(z[1, :])\navg[union(sym2range[:σ²]...)]\n\n1-element Vector{Float64}:\n 0.21552003804685096\n\n\n\navg[union(sym2range[:intercept]...)]\n\n1-element Vector{Float64}:\n -0.0002081503176371776\n\n\n\navg[union(sym2range[:coefficients]...)]\n\n10-element Vector{Float64}:\n  0.37286836459744244\n -0.10511174644443397\n -0.07311313042765602\n  0.610946269436176\n  0.01089622391060304\n  0.08171466259953368\n -0.07307258841268861\n  0.12252931457781585\n  0.18537557756434636\n -0.6189871448165513\n\n\nNote: as you can see, this is slightly awkward to work with at the moment. We’ll soon add a better way of dealing with this.\nWith a bit of work (this will be much easier in the future), we can also visualize the approximate marginals of the different variables, similar to plot(chain):\n\nfunction plot_variational_marginals(z, sym2range)\n    ps = []\n\n    for (i, sym) in enumerate(keys(sym2range))\n        indices = union(sym2range[sym]...)  # &lt;= array of ranges\n        if sum(length.(indices)) &gt; 1\n            offset = 1\n            for r in indices\n                p = density(\n                    z[r, :];\n                    title=\"$(sym)[$offset]\",\n                    titlefontsize=10,\n                    label=\"\",\n                    ylabel=\"Density\",\n                    margin=1.5mm,\n                )\n                push!(ps, p)\n                offset += 1\n            end\n        else\n            p = density(\n                z[first(indices), :];\n                title=\"$(sym)\",\n                titlefontsize=10,\n                label=\"\",\n                ylabel=\"Density\",\n                margin=1.5mm,\n            )\n            push!(ps, p)\n        end\n    end\n\n    return plot(ps...; layout=(length(ps), 1), size=(500, 2000), margin=4.0mm)\nend\n\nplot_variational_marginals (generic function with 1 method)\n\n\n\nplot_variational_marginals(z, sym2range)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnd let’s compare this to using the NUTS sampler:\n\nchain = sample(m, NUTS(), 10_000);\n\n┌ Info: Found initial step size\n└   ϵ = 0.05\n\n\n\nplot(chain; margin=12.00mm)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvi_mean = vec(mean(z; dims=2))[[\n    union(sym2range[:coefficients]...)...,\n    union(sym2range[:intercept]...)...,\n    union(sym2range[:σ²]...)...,\n]]\n\n12-element Vector{Float64}:\n  0.37286836459744244\n -0.10511174644443397\n -0.07311313042765602\n  0.610946269436176\n  0.01089622391060304\n  0.08171466259953368\n -0.07307258841268861\n  0.12252931457781585\n  0.18537557756434636\n -0.6189871448165513\n -0.0002081503176371776\n  0.21552003804685096\n\n\n\nmcmc_mean = mean(chain, names(chain, :parameters))[:, 2]\n\n12-element Vector{Float64}:\n  0.24497437389809712\n -0.0015420571833307008\n  0.36707138360730684\n -0.10589040186838188\n -0.08500111989405507\n  0.6103726656930614\n  0.000520786680662595\n  0.07840268777151398\n -0.07745211223393232\n  0.11694526351329519\n  0.1876236062728296\n -0.6151720432994979\n\n\n\nplot(mcmc_mean; xticks=1:1:length(mcmc_mean), linestyle=:dot, label=\"NUTS\")\nplot!(vi_mean; linestyle=:dot, label=\"VI\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOne thing we can look at is simply the squared error between the means:\n\nsum(abs2, mcmc_mean .- vi_mean)\n\n2.366744508898657\n\n\nThat looks pretty good! But let’s see how the predictive distributions looks for the two.",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Variational Inference"
    ]
  },
  {
    "objectID": "tutorials/09-variational-inference/index.html#prediction",
    "href": "tutorials/09-variational-inference/index.html#prediction",
    "title": "Variational inference (VI) in Turing.jl",
    "section": "Prediction",
    "text": "Prediction\nSimilarily to the linear regression tutorial, we’re going to compare to multivariate ordinary linear regression using the GLM package:\n\n# Import the GLM package.\nusing GLM\n\n# Perform multivariate OLS.\nols = lm(\n    @formula(MPG ~ Cyl + Disp + HP + DRat + WT + QSec + VS + AM + Gear + Carb), train_cut\n)\n\n# Store our predictions in the original dataframe.\ntrain_cut.OLSPrediction = unstandardize(GLM.predict(ols), train_unstandardized.MPG)\ntest_cut.OLSPrediction = unstandardize(GLM.predict(ols, test_cut), train_unstandardized.MPG);\n\n\n# Make a prediction given an input vector, using mean parameter values from a chain.\nfunction prediction_chain(chain, x)\n    p = get_params(chain)\n    α = mean(p.intercept)\n    β = collect(mean.(p.coefficients))\n    return α .+ x * β\nend\n\nprediction_chain (generic function with 1 method)\n\n\n\n# Make a prediction using samples from the variational posterior given an input vector.\nfunction prediction(samples::AbstractVector, sym2ranges, x)\n    α = mean(samples[union(sym2ranges[:intercept]...)])\n    β = vec(mean(samples[union(sym2ranges[:coefficients]...)]; dims=2))\n    return α .+ x * β\nend\n\nfunction prediction(samples::AbstractMatrix, sym2ranges, x)\n    α = mean(samples[union(sym2ranges[:intercept]...), :])\n    β = vec(mean(samples[union(sym2ranges[:coefficients]...), :]; dims=2))\n    return α .+ x * β\nend\n\nprediction (generic function with 2 methods)\n\n\n\n# Unstandardize the dependent variable.\ntrain_cut.MPG = unstandardize(train_cut.MPG, train_unstandardized.MPG)\ntest_cut.MPG = unstandardize(test_cut.MPG, train_unstandardized.MPG);\n\n\n# Show the first side rows of the modified dataframe.\nfirst(test_cut, 6)\n\n6×12 DataFrame\n\n\n\nRow\nMPG\nCyl\nDisp\nHP\nDRat\nWT\nQSec\nVS\nAM\nGear\nCarb\nOLSPrediction\n\n\n\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n15.2\n1.04746\n0.565102\n0.258882\n-0.652405\n0.0714991\n-0.716725\n-0.977008\n-0.598293\n-0.891883\n-0.469126\n19.8583\n\n\n2\n13.3\n1.04746\n0.929057\n1.90345\n0.380435\n0.465717\n-1.90403\n-0.977008\n-0.598293\n-0.891883\n1.11869\n16.0462\n\n\n3\n19.2\n1.04746\n1.32466\n0.691663\n-0.777058\n0.470584\n-0.873777\n-0.977008\n-0.598293\n-0.891883\n-0.469126\n18.5746\n\n\n4\n27.3\n-1.25696\n-1.21511\n-1.19526\n1.0037\n-1.38857\n0.288403\n0.977008\n1.59545\n1.07026\n-1.26303\n29.3233\n\n\n5\n26.0\n-1.25696\n-0.888346\n-0.762482\n1.62697\n-1.18903\n-1.09365\n-0.977008\n1.59545\n3.0324\n-0.469126\n30.7731\n\n\n6\n30.4\n-1.25696\n-1.08773\n-0.381634\n0.451665\n-1.79933\n-0.968007\n0.977008\n1.59545\n3.0324\n-0.469126\n25.2892\n\n\n\n\n\n\n\nz = rand(q, 10_000);\n\n\n# Calculate the predictions for the training and testing sets using the samples `z` from variational posterior\ntrain_cut.VIPredictions = unstandardize(\n    prediction(z, sym2range, train), train_unstandardized.MPG\n)\ntest_cut.VIPredictions = unstandardize(\n    prediction(z, sym2range, test), train_unstandardized.MPG\n)\n\ntrain_cut.BayesPredictions = unstandardize(\n    prediction_chain(chain, train), train_unstandardized.MPG\n)\ntest_cut.BayesPredictions = unstandardize(\n    prediction_chain(chain, test), train_unstandardized.MPG\n);\n\n\nvi_loss1 = mean((train_cut.VIPredictions - train_cut.MPG) .^ 2)\nbayes_loss1 = mean((train_cut.BayesPredictions - train_cut.MPG) .^ 2)\nols_loss1 = mean((train_cut.OLSPrediction - train_cut.MPG) .^ 2)\n\nvi_loss2 = mean((test_cut.VIPredictions - test_cut.MPG) .^ 2)\nbayes_loss2 = mean((test_cut.BayesPredictions - test_cut.MPG) .^ 2)\nols_loss2 = mean((test_cut.OLSPrediction - test_cut.MPG) .^ 2)\n\nprintln(\"Training set:\n    VI loss: $vi_loss1\n    Bayes loss: $bayes_loss1\n    OLS loss: $ols_loss1\nTest set: \n    VI loss: $vi_loss2\n    Bayes loss: $bayes_loss2\n    OLS loss: $ols_loss2\")\n\nTraining set:\n    VI loss: 3.0829864603139474\n    Bayes loss: 3.0726440712978866\n    OLS loss: 3.0709261248930093\nTest set: \n    VI loss: 26.433362102251017\n    Bayes loss: 26.332747788436865\n    OLS loss: 27.09481307076057\n\n\nInterestingly the squared difference between true- and mean-prediction on the test-set is actually better for the mean-field variational posterior than for the “true” posterior obtained by MCMC sampling using NUTS. But, as Bayesians, we know that the mean doesn’t tell the entire story. One quick check is to look at the mean predictions ± standard deviation of the two different approaches:\n\nz = rand(q, 1000);\npreds = mapreduce(hcat, eachcol(z)) do zi\n    return unstandardize(prediction(zi, sym2range, test), train_unstandardized.MPG)\nend\n\nscatter(\n    1:size(test, 1),\n    mean(preds; dims=2);\n    yerr=std(preds; dims=2),\n    label=\"prediction (mean ± std)\",\n    size=(900, 500),\n    markersize=8,\n)\nscatter!(1:size(test, 1), unstandardize(test_label, train_unstandardized.MPG); label=\"true\")\nxaxis!(1:size(test, 1))\nylims!(10, 40)\ntitle!(\"Mean-field ADVI (Normal)\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npreds = mapreduce(hcat, 1:5:size(chain, 1)) do i\n    return unstandardize(prediction_chain(chain[i], test), train_unstandardized.MPG)\nend\n\nscatter(\n    1:size(test, 1),\n    mean(preds; dims=2);\n    yerr=std(preds; dims=2),\n    label=\"prediction (mean ± std)\",\n    size=(900, 500),\n    markersize=8,\n)\nscatter!(1:size(test, 1), unstandardize(test_label, train_unstandardized.MPG); label=\"true\")\nxaxis!(1:size(test, 1))\nylims!(10, 40)\ntitle!(\"MCMC (NUTS)\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndeed we see that the MCMC approach generally provides better uncertainty estimates than the mean-field ADVI approach! Good. So all the work we’ve done to make MCMC fast isn’t for nothing.",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Variational Inference"
    ]
  },
  {
    "objectID": "tutorials/09-variational-inference/index.html#alternative-provide-parameter-to-distribution-instead-of-q-with-update-implemented",
    "href": "tutorials/09-variational-inference/index.html#alternative-provide-parameter-to-distribution-instead-of-q-with-update-implemented",
    "title": "Variational inference (VI) in Turing.jl",
    "section": "Alternative: provide parameter-to-distribution instead of \\(q\\) with update implemented",
    "text": "Alternative: provide parameter-to-distribution instead of \\(q\\) with update implemented\nAs mentioned earlier, it’s also possible to just provide the mapping \\(\\theta \\mapsto q_{\\theta}\\) rather than the variational family / initial variational posterior q, i.e. use the interface vi(m, advi, getq, θ_init) where getq is the mapping \\(\\theta \\mapsto q_{\\theta}\\)\nIn this section we’re going to construct a mean-field approximation to the model by hand using a composition ofShift and Scale from Bijectors.jl togheter with a standard multivariate Gaussian as the base distribution.\n\nusing Bijectors\n\n\nusing Bijectors: Scale, Shift\n\n\nd = length(q)\nbase_dist = Turing.DistributionsAD.TuringDiagMvNormal(zeros(d), ones(d))\n\nDistributionsAD.TuringDiagMvNormal{Vector{Float64}, Vector{Float64}}(\nm: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\nσ: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n)\n\n\nbijector(model::Turing.Model) is defined by Turing, and will return a bijector which takes you from the space of the latent variables to the real space. In this particular case, this is a mapping ((0, ∞) × ℝ × ℝ¹⁰) → ℝ¹². We’re interested in using a normal distribution as a base-distribution and transform samples to the latent space, thus we need the inverse mapping from the reals to the latent space:\n\nto_constrained = inverse(bijector(m));\n\n\nfunction getq(θ)\n    d = length(θ) ÷ 2\n    A = @inbounds θ[1:d]\n    b = @inbounds θ[(d + 1):(2 * d)]\n\n    b = to_constrained ∘ Shift(b) ∘ Scale(exp.(A))\n\n    return transformed(base_dist, b)\nend\n\ngetq (generic function with 1 method)\n\n\n\nq_mf_normal = vi(m, advi, getq, randn(2 * d));\n\n┌ Info: [ADVI] Should only be seen once: optimizer created for θ\n└   objectid(θ) = 0x1ed9ff3745711b47\n\n\n\np1 = plot_variational_marginals(rand(q_mf_normal, 10_000), sym2range) # MvDiagNormal + Affine transformation + to_constrained\np2 = plot_variational_marginals(rand(q, 10_000), sym2range)  # Turing.meanfield(m)\n\nplot(p1, p2; layout=(1, 2), size=(800, 2000))\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs expected, the fits look pretty much identical.\nBut using this interface it becomes trivial to go beyond the mean-field assumption we made for the variational posterior, as we’ll see in the next section.\n\nRelaxing the mean-field assumption\nHere we’ll instead consider the variational family to be a full non-diagonal multivariate Gaussian. As in the previous section we’ll implement this by transforming a standard multivariate Gaussian using Scale and Shift, but now Scale will instead be using a lower-triangular matrix (representing the Cholesky of the covariance matrix of a multivariate normal) in contrast to the diagonal matrix we used in for the mean-field approximate posterior.\n\n# Using `ComponentArrays.jl` together with `UnPack.jl` makes our lives much easier.\nusing ComponentArrays, UnPack\n\n\nproto_arr = ComponentArray(; L=zeros(d, d), b=zeros(d))\nproto_axes = getaxes(proto_arr)\nnum_params = length(proto_arr)\n\nfunction getq(θ)\n    L, b = begin\n        @unpack L, b = ComponentArray(θ, proto_axes)\n        LowerTriangular(L), b\n    end\n    # For this to represent a covariance matrix we need to ensure that the diagonal is positive.\n    # We can enforce this by zeroing out the diagonal and then adding back the diagonal exponentiated.\n    D = Diagonal(diag(L))\n    A = L - D + exp(D) # exp for Diagonal is the same as exponentiating only the diagonal entries\n\n    b = to_constrained ∘ Shift(b) ∘ Scale(A)\n\n    return transformed(base_dist, b)\nend\n\ngetq (generic function with 1 method)\n\n\n\nadvi = ADVI(10, 20_000)\n\nADVI{AutoForwardDiff{nothing, Nothing}}(10, 20000, AutoForwardDiff{nothing, Nothing}(nothing))\n\n\n\nq_full_normal = vi(\n    m, advi, getq, randn(num_params); optimizer=Variational.DecayedADAGrad(1e-2)\n);\n\nLet’s have a look at the learned covariance matrix:\n\nA = q_full_normal.transform.inner.a\n\n12×12 LowerTriangular{Float64, Matrix{Float64}}:\n  0.32301        ⋅             ⋅         …    ⋅          ⋅          ⋅ \n  0.00159264    0.0968207      ⋅              ⋅          ⋅          ⋅ \n -0.0103866     0.0145415     0.423763        ⋅          ⋅          ⋅ \n  0.0157501    -0.000285194  -0.0510179       ⋅          ⋅          ⋅ \n -0.00630413    0.00384525   -0.0528681       ⋅          ⋅          ⋅ \n -0.0197176    -0.0105593     0.115836   …    ⋅          ⋅          ⋅ \n -0.00804167   -0.00704082    0.0156415       ⋅          ⋅          ⋅ \n  0.000353499   0.00189386    0.0972563       ⋅          ⋅          ⋅ \n -0.0104786     0.00201413    0.0828047       ⋅          ⋅          ⋅ \n -0.00559584   -0.00118795    0.0577811      0.140065    ⋅          ⋅ \n  0.000137063  -0.000269624   0.024069   …  -0.0993842  0.102173    ⋅ \n  0.00402445    0.00525839   -0.06383        0.0354554  0.0116445  0.101763\n\n\n\nheatmap(cov(A * A'))\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nzs = rand(q_full_normal, 10_000);\n\n\np1 = plot_variational_marginals(rand(q_mf_normal, 10_000), sym2range)\np2 = plot_variational_marginals(rand(q_full_normal, 10_000), sym2range)\n\nplot(p1, p2; layout=(1, 2), size=(800, 2000))\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSo it seems like the “full” ADVI approach, i.e. no mean-field assumption, obtain the same modes as the mean-field approach but with greater uncertainty for some of the coefficients. This\n\n# Unfortunately, it seems like this has quite a high variance which is likely to be due to numerical instability, \n# so we consider a larger number of samples. If we get a couple of outliers due to numerical issues, \n# these kind affect the mean prediction greatly.\nz = rand(q_full_normal, 10_000);\n\n\ntrain_cut.VIFullPredictions = unstandardize(\n    prediction(z, sym2range, train), train_unstandardized.MPG\n)\ntest_cut.VIFullPredictions = unstandardize(\n    prediction(z, sym2range, test), train_unstandardized.MPG\n);\n\n\nvi_loss1 = mean((train_cut.VIPredictions - train_cut.MPG) .^ 2)\nvifull_loss1 = mean((train_cut.VIFullPredictions - train_cut.MPG) .^ 2)\nbayes_loss1 = mean((train_cut.BayesPredictions - train_cut.MPG) .^ 2)\nols_loss1 = mean((train_cut.OLSPrediction - train_cut.MPG) .^ 2)\n\nvi_loss2 = mean((test_cut.VIPredictions - test_cut.MPG) .^ 2)\nvifull_loss2 = mean((test_cut.VIFullPredictions - test_cut.MPG) .^ 2)\nbayes_loss2 = mean((test_cut.BayesPredictions - test_cut.MPG) .^ 2)\nols_loss2 = mean((test_cut.OLSPrediction - test_cut.MPG) .^ 2)\n\nprintln(\"Training set:\n    VI loss: $vi_loss1\n    Bayes loss: $bayes_loss1\n    OLS loss: $ols_loss1\nTest set: \n    VI loss: $vi_loss2\n    Bayes loss: $bayes_loss2\n    OLS loss: $ols_loss2\")\n\nTraining set:\n    VI loss: 3.0829864603139474\n    Bayes loss: 3.0726440712978866\n    OLS loss: 3.0709261248930093\nTest set: \n    VI loss: 26.433362102251017\n    Bayes loss: 26.332747788436865\n    OLS loss: 27.09481307076057\n\n\n\nz = rand(q_mf_normal, 1000);\npreds = mapreduce(hcat, eachcol(z)) do zi\n    return unstandardize(prediction(zi, sym2range, test), train_unstandardized.MPG)\nend\n\np1 = scatter(\n    1:size(test, 1),\n    mean(preds; dims=2);\n    yerr=std(preds; dims=2),\n    label=\"prediction (mean ± std)\",\n    size=(900, 500),\n    markersize=8,\n)\nscatter!(1:size(test, 1), unstandardize(test_label, train_unstandardized.MPG); label=\"true\")\nxaxis!(1:size(test, 1))\nylims!(10, 40)\ntitle!(\"Mean-field ADVI (Normal)\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nz = rand(q_full_normal, 1000);\npreds = mapreduce(hcat, eachcol(z)) do zi\n    return unstandardize(prediction(zi, sym2range, test), train_unstandardized.MPG)\nend\n\np2 = scatter(\n    1:size(test, 1),\n    mean(preds; dims=2);\n    yerr=std(preds; dims=2),\n    label=\"prediction (mean ± std)\",\n    size=(900, 500),\n    markersize=8,\n)\nscatter!(1:size(test, 1), unstandardize(test_label, train_unstandardized.MPG); label=\"true\")\nxaxis!(1:size(test, 1))\nylims!(10, 40)\ntitle!(\"Full ADVI (Normal)\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npreds = mapreduce(hcat, 1:5:size(chain, 1)) do i\n    return unstandardize(prediction_chain(chain[i], test), train_unstandardized.MPG)\nend\n\np3 = scatter(\n    1:size(test, 1),\n    mean(preds; dims=2);\n    yerr=std(preds; dims=2),\n    label=\"prediction (mean ± std)\",\n    size=(900, 500),\n    markersize=8,\n)\nscatter!(1:size(test, 1), unstandardize(test_label, train_unstandardized.MPG); label=\"true\")\nxaxis!(1:size(test, 1))\nylims!(10, 40)\ntitle!(\"MCMC (NUTS)\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot(p1, p2, p3; layout=(1, 3), size=(900, 250), label=\"\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere we actually see that indeed both the full ADVI and the MCMC approaches does a much better job of quantifying the uncertainty of predictions for never-before-seen samples, with full ADVI seemingly underestimating the variance slightly compared to MCMC.\nSo now you know how to do perform VI on your Turing.jl model! Great isn’t it?",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Variational Inference"
    ]
  },
  {
    "objectID": "tutorials/12-gplvm/index.html",
    "href": "tutorials/12-gplvm/index.html",
    "title": "Gaussian Process Latent Variable Model",
    "section": "",
    "text": "In a previous tutorial, we have discussed latent variable models, in particular probabilistic principal component analysis (pPCA). Here, we show how we can extend the mapping provided by pPCA to non-linear mappings between input and output. For more details about the Gaussian Process Latent Variable Model (GPLVM), we refer the reader to the original publication and a further extension.\nIn short, the GPVLM is a dimensionality reduction technique that allows us to embed a high-dimensional dataset in a lower-dimensional embedding. Importantly, it provides the advantage that the linear mappings from the embedded space can be non-linearised through the use of Gaussian Processes.\n\nLet’s start by loading some dependencies.\n\nusing Turing\nusing AbstractGPs\nusing FillArrays\nusing LaTeXStrings\nusing Plots\nusing RDatasets\nusing ReverseDiff\nusing StatsBase\n\nusing LinearAlgebra\nusing Random\n\nRandom.seed!(1789);\n\nWe demonstrate the GPLVM with a very small dataset: Fisher’s Iris data set. This is mostly for reasons of run time, so the tutorial can be run quickly. As you will see, one of the major drawbacks of using GPs is their speed, although this is an active area of research. We will briefly touch on some ways to speed things up at the end of this tutorial. We transform the original data with non-linear operations in order to demonstrate the power of GPs to work on non-linear relationships, while keeping the problem reasonably small.\n\ndata = dataset(\"datasets\", \"iris\")\nspecies = data[!, \"Species\"]\nindex = shuffle(1:150)\n# we extract the four measured quantities,\n# so the dimension of the data is only d=4 for this toy example\ndat = Matrix(data[index, 1:4])\nlabels = data[index, \"Species\"]\n\n# non-linearize data to demonstrate ability of GPs to deal with non-linearity\ndat[:, 1] = 0.5 * dat[:, 1] .^ 2 + 0.1 * dat[:, 1] .^ 3\ndat[:, 2] = dat[:, 2] .^ 3 + 0.2 * dat[:, 2] .^ 4\ndat[:, 3] = 0.1 * exp.(dat[:, 3]) - 0.2 * dat[:, 3] .^ 2\ndat[:, 4] = 0.5 * log.(dat[:, 4]) .^ 2 + 0.01 * dat[:, 3] .^ 5\n\n# normalize data\ndt = fit(ZScoreTransform, dat; dims=1);\nStatsBase.transform!(dt, dat);\n\nWe will start out by demonstrating the basic similarity between pPCA (see the tutorial on this topic) and the GPLVM model. Indeed, pPCA is basically equivalent to running the GPLVM model with an automatic relevance determination (ARD) linear kernel.\nFirst, we re-introduce the pPCA model (see the tutorial on pPCA for details)\n\n@model function pPCA(x)\n    # Dimensionality of the problem.\n    N, D = size(x)\n    # latent variable z\n    z ~ filldist(Normal(), D, N)\n    # weights/loadings W\n    w ~ filldist(Normal(), D, D)\n    mu = (w * z)'\n    for d in 1:D\n        x[:, d] ~ MvNormal(mu[:, d], I)\n    end\n    return nothing\nend;\n\nWe define two different kernels, a simple linear kernel with an Automatic Relevance Determination transform and a squared exponential kernel.\n\nlinear_kernel(α) = LinearKernel() ∘ ARDTransform(α)\nsekernel(α, σ) = σ * SqExponentialKernel() ∘ ARDTransform(α);\n\nAnd here is the GPLVM model. We create separate models for the two types of kernel.\n\n@model function GPLVM_linear(Y, K)\n    # Dimensionality of the problem.\n    N, D = size(Y)\n    # K is the dimension of the latent space\n    @assert K &lt;= D\n    noise = 1e-3\n\n    # Priors\n    α ~ MvLogNormal(MvNormal(Zeros(K), I))\n    Z ~ filldist(Normal(), K, N)\n    mu ~ filldist(Normal(), N)\n\n    gp = GP(linear_kernel(α))\n    gpz = gp(ColVecs(Z), noise)\n    Y ~ filldist(MvNormal(mu, cov(gpz)), D)\n\n    return nothing\nend;\n\n@model function GPLVM(Y, K)\n    # Dimensionality of the problem.\n    N, D = size(Y)\n    # K is the dimension of the latent space\n    @assert K &lt;= D\n    noise = 1e-3\n\n    # Priors\n    α ~ MvLogNormal(MvNormal(Zeros(K), I))\n    σ ~ LogNormal(0.0, 1.0)\n    Z ~ filldist(Normal(), K, N)\n    mu ~ filldist(Normal(), N)\n\n    gp = GP(sekernel(α, σ))\n    gpz = gp(ColVecs(Z), noise)\n    Y ~ filldist(MvNormal(mu, cov(gpz)), D)\n\n    return nothing\nend;\n\n\n# Standard GPs don't scale very well in n, so we use a small subsample for the purpose of this tutorial\nn_data = 40\n# number of features to use from dataset\nn_features = 4\n# latent dimension for GP case\nndim = 4;\n\n\nppca = pPCA(dat[1:n_data, 1:n_features])\nchain_ppca = sample(ppca, NUTS{Turing.ReverseDiffAD{true}}(), 1000);\n\n\n# we extract the posterior mean estimates of the parameters from the chain\nz_mean = reshape(mean(group(chain_ppca, :z))[:, 2], (n_features, n_data))\nscatter(z_mean[1, :], z_mean[2, :]; group=labels[1:n_data], xlabel=L\"z_1\", ylabel=L\"z_2\")\n\nWe can see that the pPCA fails to distinguish the groups. In particular, the setosa species is not clearly separated from versicolor and virginica. This is due to the non-linearities that we introduced, as without them the two groups can be clearly distinguished using pPCA (see the pPCA tutorial).\nLet’s try the same with our linear kernel GPLVM model.\n\ngplvm_linear = GPLVM_linear(dat[1:n_data, 1:n_features], ndim)\nchain_linear = sample(gplvm_linear, NUTS{Turing.ReverseDiffAD{true}}(), 500);\n\n\n# we extract the posterior mean estimates of the parameters from the chain\nz_mean = reshape(mean(group(chain_linear, :Z))[:, 2], (n_features, n_data))\nalpha_mean = mean(group(chain_linear, :α))[:, 2]\n\nalpha1, alpha2 = partialsortperm(alpha_mean, 1:2; rev=true)\nscatter(\n    z_mean[alpha1, :],\n    z_mean[alpha2, :];\n    group=labels[1:n_data],\n    xlabel=L\"z_{\\mathrm{ard}_1}\",\n    ylabel=L\"z_{\\mathrm{ard}_2}\",\n)\n\nWe can see that similar to the pPCA case, the linear kernel GPLVM fails to distinguish between the two groups (setosa on the one hand, and virginica and verticolor on the other).\nFinally, we demonstrate that by changing the kernel to a non-linear function, we are able to separate the data again.\n\ngplvm = GPLVM(dat[1:n_data, 1:n_features], ndim)\nchain_gplvm = sample(gplvm, NUTS{Turing.ReverseDiffAD{true}}(), 500);\n\n\n# we extract the posterior mean estimates of the parameters from the chain\nz_mean = reshape(mean(group(chain_gplvm, :Z))[:, 2], (ndim, n_data))\nalpha_mean = mean(group(chain_gplvm, :α))[:, 2]\n\nalpha1, alpha2 = partialsortperm(alpha_mean, 1:2; rev=true)\nscatter(\n    z_mean[alpha1, :],\n    z_mean[alpha2, :];\n    group=labels[1:n_data],\n    xlabel=L\"z_{\\mathrm{ard}_1}\",\n    ylabel=L\"z_{\\mathrm{ard}_2}\",\n)\n\n\nlet\n    @assert abs(\n        mean(z_mean[alpha1, labels[1:n_data] .== \"setosa\"]) -\n        mean(z_mean[alpha1, labels[1:n_data] .!= \"setosa\"]),\n    ) &gt; 1\nend\n\nNow, the split between the two groups is visible again.\n\n\n\n\n Back to top",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Gaussian Process Latent Variable Models"
    ]
  },
  {
    "objectID": "tutorials/16-contexts/index.html",
    "href": "tutorials/16-contexts/index.html",
    "title": "A Mini Turing Implementation II: Contexts",
    "section": "",
    "text": "In the Mini Turing tutorial we developed a miniature version of the Turing language, to illustrate its core design. A passing mention was made of contexts. In this tutorial we develop that aspect of our mini Turing language further to demonstrate how and why contexts are an important part of Turing’s design.",
    "crumbs": [
      "Get Started",
      "Developers",
      "DynamicPPL in Depth",
      "A Mini Turing Implementation II: Contexts"
    ]
  },
  {
    "objectID": "tutorials/16-contexts/index.html#contexts-within-contexts",
    "href": "tutorials/16-contexts/index.html#contexts-within-contexts",
    "title": "A Mini Turing Implementation II: Contexts",
    "section": "Contexts within contexts",
    "text": "Contexts within contexts\nLet’s use the above two contexts to provide a slightly more general definition of the SamplingContext and the Metropolis-Hastings sampler we wrote in the mini Turing tutorial.\n\nstruct SamplingContext{S&lt;:AbstractMCMC.AbstractSampler,R&lt;:Random.AbstractRNG}\n    rng::R\n    sampler::S\n    subcontext::Union{PriorContext, JointContext}\nend\n\nThe new aspect here is the subcontext field. Note that this is a context within a context! The idea is that we don’t need to hard code how the MCMC sampler evaluates the log probability, but rather can pass that work onto the subcontext. This way the same sampler can be used to sample from either the joint or the prior distribution.\nThe methods for SamplingContext are largely as in the our earlier mini Turing case, except they now pass some of the work onto the subcontext:\n\nfunction observe(context::SamplingContext, args...)\n    # Sampling doesn't affect the observed values, so nothing to do here other than pass to\n    # the subcontext.\n    return observe(context.subcontext, args...)\nend\n\nstruct PriorSampler &lt;: AbstractMCMC.AbstractSampler end\n\nfunction assume(context::SamplingContext{PriorSampler}, varinfo, dist, var_id)\n    sample = Random.rand(context.rng, dist)\n    varinfo[var_id] = (sample, NaN)\n    # Once the value has been sampled, let the subcontext handle evaluating the log\n    # probability.\n    return assume(context.subcontext, varinfo, dist, var_id)\nend;\n\n# The subcontext field of the MHSampler determines which distribution this sampler\n# samples from.\nstruct MHSampler{D, T&lt;:Real} &lt;: AbstractMCMC.AbstractSampler\n    sigma::T\n    subcontext::D\nend\n\nMHSampler(subcontext) = MHSampler(1, subcontext)\n\nfunction assume(context::SamplingContext{&lt;:MHSampler}, varinfo, dist, var_id)\n    sampler = context.sampler\n    old_value = varinfo.values[var_id]\n\n    # propose a random-walk step, i.e, add the current value to a random \n    # value sampled from a Normal distribution centered at 0\n    value = rand(context.rng, Normal(old_value, sampler.sigma))\n    varinfo[var_id] = (value, NaN)\n    # Once the value has been sampled, let the subcontext handle evaluating the log\n    # probability.\n    return assume(context.subcontext, varinfo, dist, var_id)\nend;\n\n# The following three methods are identical to before, except for passing\n# `sampler.subcontext` to the context SamplingContext.\nfunction AbstractMCMC.step(\n    rng::Random.AbstractRNG, model::MiniModel, sampler::MHSampler; kwargs...\n)\n    vi = VarInfo()\n    ctx = SamplingContext(rng, PriorSampler(), sampler.subcontext)\n    model.f(vi, ctx, values(model.data)...)\n    return vi, vi\nend\n\nfunction AbstractMCMC.step(\n    rng::Random.AbstractRNG,\n    model::MiniModel,\n    sampler::MHSampler,\n    prev_state::VarInfo; # is just the old trace\n    kwargs...,\n)\n    vi = prev_state\n    new_vi = deepcopy(vi)\n    ctx = SamplingContext(rng, sampler, sampler.subcontext)\n    model.f(new_vi, ctx, values(model.data)...)\n\n    # Compute log acceptance probability\n    # Since the proposal is symmetric the computation can be simplified\n    logα = sum(values(new_vi.logps)) - sum(values(vi.logps))\n\n    # Accept proposal with computed acceptance probability\n    if -Random.randexp(rng) &lt; logα\n        return new_vi, new_vi\n    else\n        return prev_state, prev_state\n    end\nend;\n\nfunction AbstractMCMC.bundle_samples(\n    samples, model::MiniModel, ::MHSampler, ::Any, ::Type{Chains}; kwargs...\n)\n    # We get a vector of traces\n    values = [sample.values for sample in samples]\n    params = [key for key in keys(values[1]) if key ∉ keys(model.data)]\n    vals = reduce(hcat, [value[p] for value in values] for p in params)\n    # Composing the `Chains` data-structure, of which analyzing infrastructure is provided\n    chains = Chains(vals, params)\n    return chains\nend;\n\nWe can use this to sample from the joint distribution just like before:\n\nsample(MiniModel(m, (x=3.0,)), MHSampler(JointContext()), 1_000_000; chain_type=Chains, progress=false)\n\nChains MCMC chain (1000000×2×1 Array{Float64, 3}):\n\nIterations        = 1:1:1000000\nNumber of chains  = 1\nSamples per chain = 1000000\nparameters        = a, b\n\nSummary Statistics\n  parameters      mean       std      mcse      ess_bulk      ess_tail      rh ⋯\n      Symbol   Float64   Float64   Float64       Float64       Float64   Float ⋯\n\n           a    0.9761    0.9014    0.0032    81014.2171   118428.5323    1.00 ⋯\n           b    2.8805    0.4888    0.0012   168949.1947   212906.6186    1.00 ⋯\n                                                               2 columns omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n           a   -0.7962    0.3674    0.9768    1.5850    2.7389\n           b    1.9196    2.5516    2.8807    3.2097    3.8414\n\n\nor we can choose to sample from the prior instead\n\nsample(MiniModel(m, (x=3.0,)), MHSampler(PriorContext()), 1_000_000; chain_type=Chains, progress=false)\n\nChains MCMC chain (1000000×2×1 Array{Float64, 3}):\n\nIterations        = 1:1:1000000\nNumber of chains  = 1\nSamples per chain = 1000000\nparameters        = a, b\n\nSummary Statistics\n  parameters      mean       std      mcse     ess_bulk      ess_tail      rha ⋯\n      Symbol   Float64   Float64   Float64      Float64       Float64   Float6 ⋯\n\n           a    0.5023    1.0016    0.0039   64795.2401   122822.5448    1.000 ⋯\n           b    0.5100    2.2386    0.0134   27848.3744    52010.4890    1.000 ⋯\n                                                               2 columns omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n           a   -1.4574   -0.1739    0.4998    1.1748    2.4765\n           b   -3.8768   -0.9950    0.5062    2.0160    4.9111\n\n\nOf course, using an MCMC algorithm to sample from the prior is unnecessary and silly (PriorSampler exists, after all), but the point is to illustrate the flexibility of the context system. We could, for instance, use the same setup to implement an Approximate Bayesian Computation (ABC) algorithm.\nThe use of contexts also goes far beyond just evaluating log probabilities and sampling. Some examples from Turing are\n\nFixedContext, which fixes some variables to given values and removes them completely from the evaluation of any log probabilities. They power the Turing.fix and Turing.unfix functions.\nConditionContext conditions the model on fixed values for some parameters. They are used by Turing.condition and Turing.uncondition, i.e. the model | (parameter=value,) syntax. The difference between fix and condition is whether the log probability for the corresponding variable is included in the overall log density.\nPriorExtractorContext collects information about what the prior distribution of each variable is.\nPrefixContext adds prefixes to variable names, allowing models to be used within other models without variable name collisions.\nPointwiseLikelihoodContext records the log likelihood of each individual variable.\nDebugContext collects useful debugging information while executing the model.\n\nAll of the above are what Turing calls parent contexts, which is to say that they all keep a subcontext just like our above SamplingContext did. Their implementations of assume and observe call the implementation of the subcontext once they are done doing their own work of fixing/conditioning/prefixing/etc. Contexts are often chained, so that e.g. a DebugContext may wrap within it a PrefixContext, which may in turn wrap a ConditionContext, etc. The only contexts that don’t have a subcontext in the Turing are the ones for evaluating the prior, likelihood, and joint distributions. These are called leaf contexts.\nThe above version of mini Turing is still much simpler than the full Turing language, but the principles of how contexts are used are the same.",
    "crumbs": [
      "Get Started",
      "Developers",
      "DynamicPPL in Depth",
      "A Mini Turing Implementation II: Contexts"
    ]
  },
  {
    "objectID": "tutorials/01-gaussian-mixture-model/index.html",
    "href": "tutorials/01-gaussian-mixture-model/index.html",
    "title": "Unsupervised Learning using Bayesian Mixture Models",
    "section": "",
    "text": "The following tutorial illustrates the use of Turing for clustering data using a Bayesian mixture model. The aim of this task is to infer a latent grouping (hidden structure) from unlabelled data.",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Gaussian Mixture Models"
    ]
  },
  {
    "objectID": "tutorials/01-gaussian-mixture-model/index.html#synthetic-data",
    "href": "tutorials/01-gaussian-mixture-model/index.html#synthetic-data",
    "title": "Unsupervised Learning using Bayesian Mixture Models",
    "section": "Synthetic Data",
    "text": "Synthetic Data\nWe generate a synthetic dataset of \\(N = 60\\) two-dimensional points \\(x_i \\in \\mathbb{R}^2\\) drawn from a Gaussian mixture model. For simplicity, we use \\(K = 2\\) clusters with\n\nequal weights, i.e., we use mixture weights \\(w = [0.5, 0.5]\\), and\nisotropic Gaussian distributions of the points in each cluster.\n\nMore concretely, we use the Gaussian distributions \\(\\mathcal{N}([\\mu_k, \\mu_k]^\\mathsf{T}, I)\\) with parameters \\(\\mu_1 = -3.5\\) and \\(\\mu_2 = 0.5\\).\n\nusing Distributions\nusing FillArrays\nusing StatsPlots\n\nusing LinearAlgebra\nusing Random\n\n# Set a random seed.\nRandom.seed!(3)\n\n# Define Gaussian mixture model.\nw = [0.5, 0.5]\nμ = [-3.5, 0.5]\nmixturemodel = MixtureModel([MvNormal(Fill(μₖ, 2), I) for μₖ in μ], w)\n\n# We draw the data points.\nN = 60\nx = rand(mixturemodel, N);\n\nThe following plot shows the dataset.\n\nscatter(x[1, :], x[2, :]; legend=false, title=\"Synthetic Dataset\")",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Gaussian Mixture Models"
    ]
  },
  {
    "objectID": "tutorials/01-gaussian-mixture-model/index.html#gaussian-mixture-model-in-turing",
    "href": "tutorials/01-gaussian-mixture-model/index.html#gaussian-mixture-model-in-turing",
    "title": "Unsupervised Learning using Bayesian Mixture Models",
    "section": "Gaussian Mixture Model in Turing",
    "text": "Gaussian Mixture Model in Turing\nWe are interested in recovering the grouping from the dataset. More precisely, we want to infer the mixture weights, the parameters \\(\\mu_1\\) and \\(\\mu_2\\), and the assignment of each datum to a cluster for the generative Gaussian mixture model.\nIn a Bayesian Gaussian mixture model with \\(K\\) components each data point \\(x_i\\) (\\(i = 1,\\ldots,N\\)) is generated according to the following generative process. First we draw the model parameters, i.e., in our example we draw parameters \\(\\mu_k\\) for the mean of the isotropic normal distributions and the mixture weights \\(w\\) of the \\(K\\) clusters. We use standard normal distributions as priors for \\(\\mu_k\\) and a Dirichlet distribution with parameters \\(\\alpha_1 = \\cdots = \\alpha_K = 1\\) as prior for \\(w\\): \\[\n\\begin{aligned}\n\\mu_k &\\sim \\mathcal{N}(0, 1) \\qquad (k = 1,\\ldots,K)\\\\\nw &\\sim \\operatorname{Dirichlet}(\\alpha_1, \\ldots, \\alpha_K)\n\\end{aligned}\n\\] After having constructed all the necessary model parameters, we can generate an observation by first selecting one of the clusters \\[\nz_i \\sim \\operatorname{Categorical}(w) \\qquad (i = 1,\\ldots,N),\n\\] and then drawing the datum accordingly, i.e., in our example drawing \\[\nx_i \\sim \\mathcal{N}([\\mu_{z_i}, \\mu_{z_i}]^\\mathsf{T}, I) \\qquad (i=1,\\ldots,N).\n\\] For more details on Gaussian mixture models, we refer to Christopher M. Bishop, Pattern Recognition and Machine Learning, Section 9.\nWe specify the model with Turing.\n\nusing Turing\n\n@model function gaussian_mixture_model(x)\n    # Draw the parameters for each of the K=2 clusters from a standard normal distribution.\n    K = 2\n    μ ~ MvNormal(Zeros(K), I)\n\n    # Draw the weights for the K clusters from a Dirichlet distribution with parameters αₖ = 1.\n    w ~ Dirichlet(K, 1.0)\n    # Alternatively, one could use a fixed set of weights.\n    # w = fill(1/K, K)\n\n    # Construct categorical distribution of assignments.\n    distribution_assignments = Categorical(w)\n\n    # Construct multivariate normal distributions of each cluster.\n    D, N = size(x)\n    distribution_clusters = [MvNormal(Fill(μₖ, D), I) for μₖ in μ]\n\n    # Draw assignments for each datum and generate it from the multivariate normal distribution.\n    k = Vector{Int}(undef, N)\n    for i in 1:N\n        k[i] ~ distribution_assignments\n        x[:, i] ~ distribution_clusters[k[i]]\n    end\n\n    return k\nend\n\nmodel = gaussian_mixture_model(x);\n\nWe run a MCMC simulation to obtain an approximation of the posterior distribution of the parameters \\(\\mu\\) and \\(w\\) and assignments \\(k\\). We use a Gibbs sampler that combines a particle Gibbs sampler for the discrete parameters (assignments \\(k\\)) and a Hamiltonion Monte Carlo sampler for the continuous parameters (\\(\\mu\\) and \\(w\\)). We generate multiple chains in parallel using multi-threading.\n\nsampler = Gibbs(PG(100, :k), HMC(0.05, 10, :μ, :w))\nnsamples = 150\nnchains = 4\nburn = 10\nchains = sample(model, sampler, MCMCThreads(), nsamples, nchains, discard_initial = burn);\n\n\n\n\n\n\n\nSampling With Multiple Threads\n\n\n\n\n\nThe sample() call above assumes that you have at least nchains threads available in your Julia instance. If you do not, the multiple chains will run sequentially, and you may notice a warning. For more information, see the Turing documentation on sampling multiple chains.",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Gaussian Mixture Models"
    ]
  },
  {
    "objectID": "tutorials/01-gaussian-mixture-model/index.html#inferred-mixture-model",
    "href": "tutorials/01-gaussian-mixture-model/index.html#inferred-mixture-model",
    "title": "Unsupervised Learning using Bayesian Mixture Models",
    "section": "Inferred Mixture Model",
    "text": "Inferred Mixture Model\nAfter sampling we can visualize the trace and density of the parameters of interest.\nWe consider the samples of the location parameters \\(\\mu_1\\) and \\(\\mu_2\\) for the two clusters.\n\nplot(chains[[\"μ[1]\", \"μ[2]\"]]; legend=true)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt can happen that the modes of \\(\\mu_1\\) and \\(\\mu_2\\) switch between chains. For more information see the Stan documentation. This is because it’s possible for either model parameter \\(\\mu_k\\) to be assigned to either of the corresponding true means, and this assignment need not be consistent between chains.\nThat is, the posterior is fundamentally multimodal, and different chains can end up in different modes, complicating inference. One solution here is to enforce an ordering on our \\(\\mu\\) vector, requiring \\(\\mu_k &gt; \\mu_{k-1}\\) for all \\(k\\). Bijectors.jl provides an easy transformation (ordered()) for this purpose:\n\n@model function gaussian_mixture_model_ordered(x)\n    # Draw the parameters for each of the K=2 clusters from a standard normal distribution.\n    K = 2\n    μ ~ Bijectors.ordered(MvNormal(Zeros(K), I))\n    # Draw the weights for the K clusters from a Dirichlet distribution with parameters αₖ = 1.\n    w ~ Dirichlet(K, 1.0)\n    # Alternatively, one could use a fixed set of weights.\n    # w = fill(1/K, K)\n    # Construct categorical distribution of assignments.\n    distribution_assignments = Categorical(w)\n    # Construct multivariate normal distributions of each cluster.\n    D, N = size(x)\n    distribution_clusters = [MvNormal(Fill(μₖ, D), I) for μₖ in μ]\n    # Draw assignments for each datum and generate it from the multivariate normal distribution.\n    k = Vector{Int}(undef, N)\n    for i in 1:N\n        k[i] ~ distribution_assignments\n        x[:, i] ~ distribution_clusters[k[i]]\n    end\n    return k\nend\n\nmodel = gaussian_mixture_model_ordered(x);\n\nNow, re-running our model, we can see that the assigned means are consistent across chains:\n\nchains = sample(model, sampler, MCMCThreads(), nsamples, nchains, discard_initial = burn);\n\n\nplot(chains[[\"μ[1]\", \"μ[2]\"]]; legend=true)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe also inspect the samples of the mixture weights \\(w\\).\n\nplot(chains[[\"w[1]\", \"w[2]\"]]; legend=true)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs the distributions of the samples for the parameters \\(\\mu_1\\), \\(\\mu_2\\), \\(w_1\\), and \\(w_2\\) are unimodal, we can safely visualize the density region of our model using the average values.\n\n# Model with mean of samples as parameters.\nμ_mean = [mean(chains, \"μ[$i]\") for i in 1:2]\nw_mean = [mean(chains, \"w[$i]\") for i in 1:2]\nmixturemodel_mean = MixtureModel([MvNormal(Fill(μₖ, 2), I) for μₖ in μ_mean], w_mean)\ncontour(\n    range(-7.5, 3; length=1_000),\n    range(-6.5, 3; length=1_000),\n    (x, y) -&gt; logpdf(mixturemodel_mean, [x, y]);\n    widen=false,\n)\nscatter!(x[1, :], x[2, :]; legend=false, title=\"Synthetic Dataset\")",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Gaussian Mixture Models"
    ]
  },
  {
    "objectID": "tutorials/01-gaussian-mixture-model/index.html#inferred-assignments",
    "href": "tutorials/01-gaussian-mixture-model/index.html#inferred-assignments",
    "title": "Unsupervised Learning using Bayesian Mixture Models",
    "section": "Inferred Assignments",
    "text": "Inferred Assignments\nFinally, we can inspect the assignments of the data points inferred using Turing. As we can see, the dataset is partitioned into two distinct groups.\n\nassignments = [mean(chains, \"k[$i]\") for i in 1:N]\nscatter(\n    x[1, :],\n    x[2, :];\n    legend=false,\n    title=\"Assignments on Synthetic Dataset\",\n    zcolor=assignments,\n)",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Gaussian Mixture Models"
    ]
  },
  {
    "objectID": "tutorials/01-gaussian-mixture-model/index.html#marginalizing-out-the-assignments",
    "href": "tutorials/01-gaussian-mixture-model/index.html#marginalizing-out-the-assignments",
    "title": "Unsupervised Learning using Bayesian Mixture Models",
    "section": "Marginalizing Out The Assignments",
    "text": "Marginalizing Out The Assignments\nWe can write out the marginal posterior of (continuous) \\(w, \\mu\\) by summing out the influence of our (discrete) assignments \\(z_i\\) from our likelihood: \\[\np(y \\mid w, \\mu ) = \\sum_{k=1}^K w_k p_k(y \\mid \\mu_k)\n\\] In our case, this gives us: \\[\np(y \\mid w, \\mu) = \\sum_{k=1}^K w_k \\cdot \\operatorname{MvNormal}(y \\mid \\mu_k, I)\n\\]\n\nMarginalizing By Hand\nWe could implement the above version of the Gaussian mixture model in Turing as follows: First, Turing uses log-probabilities, so the likelihood above must be converted into log-space: \\[\n\\log \\left( p(y \\mid w, \\mu) \\right) = \\text{logsumexp} \\left[\\log (w_k) + \\log(\\operatorname{MvNormal}(y \\mid \\mu_k, I)) \\right]\n\\]\nWhere we sum the components with logsumexp from the LogExpFunctions.jl package. The manually incremented likelihood can be added to the log-probability with Turing.@addlogprob!, giving us the following model:\n\nusing LogExpFunctions\n\n@model function gmm_marginalized(x)\n    K = 2\n    D, N = size(x)\n    μ ~ Bijectors.ordered(MvNormal(Zeros(K), I))\n    w ~ Dirichlet(K, 1.0)\n    dists = [MvNormal(Fill(μₖ, D), I) for μₖ in μ]\n    for i in 1:N\n        lvec = Vector(undef, K)\n        for k in 1:K\n            lvec[k] = (w[k] + logpdf(dists[k], x[:, i]))\n        end\n        Turing.@addlogprob! logsumexp(lvec)\n    end\nend\n\n\n\n\n\n\n\nManually Incrementing Probablity\n\n\n\n\n\nWhen possible, use of Turing.@addlogprob! should be avoided, as it exists outside the usual structure of a Turing model. In most cases, a custom distribution should be used instead.\nHere, the next section demonstrates the perfered method — using the MixtureModel distribution we have seen already to perform the marginalization automatically.\n\n\n\n\n\nMarginalizing For Free With Distribution.jl’s MixtureModel Implementation\nWe can use Turing’s ~ syntax with anything that Distributions.jl provides logpdf and rand methods for. It turns out that the MixtureModel distribution it provides has, as its logpdf method, logpdf(MixtureModel([Component_Distributions], weight_vector), Y), where Y can be either a single observation or vector of observations.\nIn fact, Distributions.jl provides many convenient constructors for mixture models, allowing further simplification in common special cases.\nFor example, when mixtures distributions are of the same type, one can write: ~ MixtureModel(Normal, [(μ1, σ1), (μ2, σ2)], w), or when the weight vector is known to allocate probability equally, it can be ommited.\nThe logpdf implementation for a MixtureModel distribution is exactly the marginalization defined above, and so our model becomes simply:\n\n@model function gmm_marginalized(x)\n    K = 2\n    D, _ = size(x)\n    μ ~ Bijectors.ordered(MvNormal(Zeros(K), I))\n    w ~ Dirichlet(K, 1.0)\n    x ~ MixtureModel([MvNormal(Fill(μₖ, D), I) for μₖ in μ], w)\nend\nmodel = gmm_marginalized(x);\n\nAs we’ve summed out the discrete components, we can perform inference using NUTS() alone.\n\nsampler = NUTS()\nchains = sample(model, sampler, MCMCThreads(), nsamples, nchains; discard_initial = burn);\n\nNUTS() significantly outperforms our compositional Gibbs sampler, in large part because our model is now Rao-Blackwellized thanks to the marginalization of our assignment parameter.\n\nplot(chains[[\"μ[1]\", \"μ[2]\"]], legend=true)",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Gaussian Mixture Models"
    ]
  },
  {
    "objectID": "tutorials/01-gaussian-mixture-model/index.html#inferred-assignments---marginalized-model",
    "href": "tutorials/01-gaussian-mixture-model/index.html#inferred-assignments---marginalized-model",
    "title": "Unsupervised Learning using Bayesian Mixture Models",
    "section": "Inferred Assignments - Marginalized Model",
    "text": "Inferred Assignments - Marginalized Model\nAs we’ve summed over possible assignments, the associated parameter is no longer available in our chain. This is not a problem, however, as given any fixed sample \\((\\mu, w)\\), the assignment probability — \\(p(z_i \\mid y_i)\\) — can be recovered using Bayes rule: \\[\np(z_i \\mid y_i) = \\frac{p(y_i \\mid z_i) p(z_i)}{\\sum_{k = 1}^K \\left(p(y_i \\mid z_i) p(z_i) \\right)}\n\\]\nThis quantity can be computed for every \\(p(z = z_i \\mid y_i)\\), resulting in a probability vector, which is then used to sample posterior predictive assignments from a categorial distribution. For details on the mathematics here, see the Stan documentation on latent discrete parameters.\n\nfunction sample_class(xi, dists, w)\n    lvec = [(logpdf(d, xi) + log(w[i])) for (i, d) in enumerate(dists)]\n    rand(Categorical(softmax(lvec)))\nend\n\n@model function gmm_recover(x)\n    K = 2\n    D, N =  size(x)\n    μ ~ Bijectors.ordered(MvNormal(Zeros(K), I))\n    w ~ Dirichlet(K, 1.0)\n    dists = [MvNormal(Fill(μₖ, D), I) for μₖ in μ]\n    x ~ MixtureModel(dists, w)\n    # Return assignment draws for each datapoint.\n    return [sample_class(x[:, i], dists, w) for i in 1:N]\nend\n\nWe sample from this model as before:\n\nmodel = gmm_recover(x)\nchains = sample(model, sampler, MCMCThreads(), nsamples, nchains, discard_initial = burn);\n\nGiven a sample from the marginalized posterior, these assignments can be recovered with:\n\nassignments = mean(generated_quantities(gmm_recover(x), chains));\n\n\nscatter(\n    x[1, :],\n    x[2, :];\n    legend=false,\n    title=\"Assignments on Synthetic Dataset - Recovered\",\n    zcolor=assignments,\n)",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Gaussian Mixture Models"
    ]
  },
  {
    "objectID": "tutorials/dev-model-manual/index.html",
    "href": "tutorials/dev-model-manual/index.html",
    "title": "Manually Defining a Model",
    "section": "",
    "text": "Traditionally, models in Turing are defined using the @model macro:\n\nusing Turing\n\n@model function gdemo(x)\n    # Set priors.\n    s² ~ InverseGamma(2, 3)\n    m ~ Normal(0, sqrt(s²))\n\n    # Observe each value of x.\n    @. x ~ Normal(m, sqrt(s²))\nend\n\nmodel = gdemo([1.5, 2.0])\n\nDynamicPPL.Model{typeof(gdemo), (:x,), (), (), Tuple{Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}(Main.Notebook.gdemo, (x = [1.5, 2.0],), NamedTuple(), DynamicPPL.DefaultContext())\n\n\nThe @model macro accepts a function definition and rewrites it such that call of the function generates a Model struct for use by the sampler.\nHowever, models can be constructed by hand without the use of a macro. Taking the gdemo model above as an example, the macro-based definition can be implemented also (a bit less generally) with the macro-free version\n\n# Create the model function.\nfunction gdemo2(model, varinfo, context, x)\n    # Assume s² has an InverseGamma distribution.\n    s², varinfo = DynamicPPL.tilde_assume!!(\n        context, InverseGamma(2, 3), Turing.@varname(s²), varinfo\n    )\n\n    # Assume m has a Normal distribution.\n    m, varinfo = DynamicPPL.tilde_assume!!(\n        context, Normal(0, sqrt(s²)), Turing.@varname(m), varinfo\n    )\n\n    # Observe each value of x[i] according to a Normal distribution.\n    return DynamicPPL.dot_tilde_observe!!(\n        context, Normal(m, sqrt(s²)), x, Turing.@varname(x), varinfo\n    )\nend\ngdemo2(x) = Turing.Model(gdemo2, (; x))\n\n# Instantiate a Model object with our data variables.\nmodel2 = gdemo2([1.5, 2.0])\n\nDynamicPPL.Model{typeof(gdemo2), (:x,), (), (), Tuple{Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}(Main.Notebook.gdemo2, (x = [1.5, 2.0],), NamedTuple(), DynamicPPL.DefaultContext())\n\n\nWe can sample from this model in the same way:\n\nchain = sample(model2, NUTS(), 1000; progress=false)\n\n┌ Info: Found initial step size\n└   ϵ = 0.4\n\n\nChains MCMC chain (1000×14×1 Array{Float64, 3}):\n\nIterations        = 501:1:1500\nNumber of chains  = 1\nSamples per chain = 1000\nWall duration     = 6.94 seconds\nCompute duration  = 6.94 seconds\nparameters        = s², m\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n          s²    2.2130    2.5818    0.1548   394.9013   364.8973    0.9993     ⋯\n           m    1.0629    0.8862    0.0557   383.5089   391.2854    1.0056     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n          s²    0.5591    1.0276    1.5729    2.3196    8.9422\n           m   -0.5735    0.5770    1.1267    1.5545    2.7219\n\n\nThe subsequent pages in this section will show how the @model macro does this behind-the-scenes.\n\n\n\n Back to top",
    "crumbs": [
      "Get Started",
      "Developers",
      "DynamicPPL in Depth",
      "Manually Defining a Model"
    ]
  },
  {
    "objectID": "tutorials/docs-01-contributing-guide/index.html",
    "href": "tutorials/docs-01-contributing-guide/index.html",
    "title": "Contributing",
    "section": "",
    "text": "Turing is an open-source project and is hosted on GitHub. We welcome contributions from the community in all forms large or small: bug reports, feature implementations, code contributions, or improvements to documentation or infrastructure are all extremely valuable. We would also very much appreciate examples of models written using Turing.\n\nHow to get involved\nOur outstanding issues are tabulated on our issue tracker. Closing one of these may involve implementing new features, fixing bugs, or writing example models.\nYou can also join the #turing channel on the Julia Slack and say hello!\nIf you are new to open-source software, please see GitHub’s introduction or Julia’s contribution guide on using version control for collaboration.\n\n\nDocumentation\nEach of the packages in the Turing ecosystem (see Libraries) has its own documentation, which is typically found in the docs folder of the corresponding package. For example, the source code for DynamicPPL’s documentation can be found in its repository.\nThe documentation for Turing.jl itself consists of the tutorials that you see on this website, and is built from the separate docs repository. None of the documentation is generated from the main Turing.jl repository; in particular, the API that Turing exports does not currently form part of the documentation.\nOther sections of the website (anything that isn’t a package, or a tutorial) – for example, the list of libraries – is built from the turinglang.github.io repository.\n\n\nTests\nTuring, like most software libraries, has a test suite. You can run the whole suite the usual Julia way with\nPkg.test(\"Turing\")\nThe test suite subdivides into files in the test folder, and you can run only some of them using commands like\nPkg.test(\"Turing\"; test_args=[\"optim\", \"hmc\", \"--skip\", \"ext\"])\nThis one would run all files with “optim” or “hmc” in their path, such as test/optimisation/Optimisation.jl, but not files with “ext” in their path. Alternatively, you can set these arguments as command line arguments when you run Julia\njulia --project=. -e 'import Pkg; Pkg.test(; test_args=ARGS)' -- optim hmc --skip ext\nOr otherwise, set the global ARGS variable, and call include(\"test/runtests.jl\").\n\n\nStyle Guide\nTuring has a style guide, described below. Reviewing it before making a pull request is not strictly necessary, but you may be asked to change portions of your code to conform with the style guide before it is merged.\nMost Turing code follows Blue: a Style Guide for Julia. These conventions were created from a variety of sources including Python’s PEP8, Julia’s Notes for Contributors, and Julia’s Style Guide.\n\nSynopsis\n\nUse 4 spaces per indentation level, no tabs.\nTry to adhere to a 92 character line length limit.\nUse upper camel case convention for modules and types.\nUse lower case with underscores for method names (note: Julia code likes to use lower case without underscores).\nComments are good, try to explain the intentions of the code.\nUse whitespace to make the code more readable.\nNo whitespace at the end of a line (trailing whitespace).\nAvoid padding brackets with spaces. ex. Int64(value) preferred over Int64( value ).\n\n\n\nA Word on Consistency\nWhen adhering to the Blue style, it’s important to realize that these are guidelines, not rules. This is stated best in the PEP8:\n\nA style guide is about consistency. Consistency with this style guide is important. Consistency within a project is more important. Consistency within one module or function is most important.\n\n\nBut most importantly: know when to be inconsistent – sometimes the style guide just doesn’t apply. When in doubt, use your best judgment. Look at other examples and decide what looks best. And don’t hesitate to ask!\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Get Started",
      "Developers",
      "Contributing",
      "How to Contribute"
    ]
  },
  {
    "objectID": "tutorials/14-minituring/index.html",
    "href": "tutorials/14-minituring/index.html",
    "title": "A Mini Turing Implementation I: Compiler",
    "section": "",
    "text": "In this tutorial we develop a very simple probabilistic programming language. The implementation is similar to DynamicPPL. This is intentional as we want to demonstrate some key ideas from Turing’s internal implementation.\nTo make things easy to understand and to implement we restrict our language to a very simple subset of the language that Turing actually supports. Defining an accurate syntax description is not our goal here, instead, we give a simple example and all similar programs should work.\n\nConsider a probabilistic model defined by\n\\[\n\\begin{aligned}\na &\\sim \\operatorname{Normal}(0.5, 1^2) \\\\\nb &\\sim \\operatorname{Normal}(a, 2^2) \\\\\nx &\\sim \\operatorname{Normal}(b, 0.5^2)\n\\end{aligned}\n\\]\nWe assume that x is data, i.e., an observed variable. In our small language this model will be defined as\n\n@mini_model function m(x)\n    a ~ Normal(0.5, 1)\n    b ~ Normal(a, 2)\n    x ~ Normal(b, 0.5)\n    return nothing\nend\n\nSpecifically, we demand that\n\nall observed variables are arguments of the program,\nthe model definition does not contain any control flow,\nall variables are scalars, and\nthe function returns nothing.\n\nFirst, we import some required packages:\n\nusing MacroTools, Distributions, Random, AbstractMCMC, MCMCChains\n\nBefore getting to the actual “compiler”, we first build the data structure for the program trace. A program trace for a probabilistic programming language needs to at least record the values of stochastic variables and their log-probabilities.\n\nstruct VarInfo{V,L}\n    values::V\n    logps::L\nend\n\nVarInfo() = VarInfo(Dict{Symbol,Float64}(), Dict{Symbol,Float64}())\n\nfunction Base.setindex!(varinfo::VarInfo, (value, logp), var_id)\n    varinfo.values[var_id] = value\n    varinfo.logps[var_id] = logp\n    return varinfo\nend\n\nInternally, our probabilistic programming language works with two main functions:\n\nassume for sampling unobserved variables and computing their log-probabilities, and\nobserve for computing log-probabilities of observed variables (but not sampling them).\n\nFor different inference algorithms we may have to use different sampling procedures and different log-probability computations. For instance, in some cases we might want to sample all variables from their prior distributions and in other cases we might only want to compute the log-likelihood of the observations based on a given set of values for the unobserved variables. Thus depending on the inference algorithm we want to use different assume and observe implementations. We can achieve this by providing this context information as a function argument to assume and observe.\nNote: Although the context system in this tutorial is inspired by DynamicPPL, it is very simplistic. We expand this mini Turing example in the contexts tutorial with some more complexity, to illustrate how and why contexts are central to Turing’s design. For the full details one still needs to go to the actual source of DynamicPPL though.\nHere we can see the implementation of a sampler that draws values of unobserved variables from the prior and computes the log-probability for every variable.\n\nstruct SamplingContext{S&lt;:AbstractMCMC.AbstractSampler,R&lt;:Random.AbstractRNG}\n    rng::R\n    sampler::S\nend\n\nstruct PriorSampler &lt;: AbstractMCMC.AbstractSampler end\n\nfunction observe(context::SamplingContext, varinfo, dist, var_id, var_value)\n    logp = logpdf(dist, var_value)\n    varinfo[var_id] = (var_value, logp)\n    return nothing\nend\n\nfunction assume(context::SamplingContext{PriorSampler}, varinfo, dist, var_id)\n    sample = Random.rand(context.rng, dist)\n    logp = logpdf(dist, sample)\n    varinfo[var_id] = (sample, logp)\n    return sample\nend;\n\nNext we define the “compiler” for our simple programming language. The term compiler is actually a bit misleading here since its only purpose is to transform the function definition in the @mini_model macro by\n\nadding the context information (context) and the tracing data structure (varinfo) as additional arguments, and\nreplacing tildes with calls to assume and observe.\n\nAfterwards, as usual the Julia compiler will just-in-time compile the model function when it is called.\nThe manipulation of Julia expressions is an advanced part of the Julia language. The Julia documentation provides an introduction to and more details about this so-called metaprogramming.\n\nmacro mini_model(expr)\n    return esc(mini_model(expr))\nend\n\nfunction mini_model(expr)\n    # Split the function definition into a dictionary with its name, arguments, body etc.\n    def = MacroTools.splitdef(expr)\n\n    # Replace tildes in the function body with calls to `assume` or `observe`\n    def[:body] = MacroTools.postwalk(def[:body]) do sub_expr\n        if MacroTools.@capture(sub_expr, var_ ~ dist_)\n            if var in def[:args]\n                # If the variable is an argument of the model function, it is observed\n                return :($(observe)(context, varinfo, $dist, $(Meta.quot(var)), $var))\n            else\n                # Otherwise it is unobserved\n                return :($var = $(assume)(context, varinfo, $dist, $(Meta.quot(var))))\n            end\n        else\n            return sub_expr\n        end\n    end\n\n    # Add `context` and `varinfo` arguments to the model function\n    def[:args] = vcat(:varinfo, :context, def[:args])\n\n    # Reassemble the function definition from its name, arguments, body etc.\n    return MacroTools.combinedef(def)\nend;\n\nFor inference, we make use of the AbstractMCMC interface. It provides a default implementation of a sample function for sampling a Markov chain. The default implementation already supports e.g. sampling of multiple chains in parallel, thinning of samples, or discarding initial samples.\nThe AbstractMCMC interface requires us to at least\n\ndefine a model that is a subtype of AbstractMCMC.AbstractModel,\ndefine a sampler that is a subtype of AbstractMCMC.AbstractSampler,\nimplement AbstractMCMC.step for our model and sampler.\n\nThus here we define a MiniModel model. In this model we store the model function and the observed data.\n\nstruct MiniModel{F,D} &lt;: AbstractMCMC.AbstractModel\n    f::F\n    data::D # a NamedTuple of all the data\nend\n\nIn the Turing compiler, the model-specific DynamicPPL.Model is constructed automatically when calling the model function. But for the sake of simplicity here we construct the model manually.\nTo illustrate probabilistic inference with our mini language we implement an extremely simplistic Random-Walk Metropolis-Hastings sampler. We hard-code the proposal step as part of the sampler and only allow normal distributions with zero mean and fixed standard deviation. The Metropolis-Hastings sampler in Turing is more flexible.\n\nstruct MHSampler{T&lt;:Real} &lt;: AbstractMCMC.AbstractSampler\n    sigma::T\nend\n\nMHSampler() = MHSampler(1)\n\nfunction assume(context::SamplingContext{&lt;:MHSampler}, varinfo, dist, var_id)\n    sampler = context.sampler\n    old_value = varinfo.values[var_id]\n\n    # propose a random-walk step, i.e, add the current value to a random \n    # value sampled from a Normal distribution centered at 0\n    value = rand(context.rng, Normal(old_value, sampler.sigma))\n    logp = Distributions.logpdf(dist, value)\n    varinfo[var_id] = (value, logp)\n\n    return value\nend;\n\nWe need to define two step functions, one for the first step and the other for the following steps. In the first step we sample values from the prior distributions and in the following steps we sample with the random-walk proposal. The two functions are identified by the different arguments they take.\n\n# The fist step: Sampling from the prior distributions\nfunction AbstractMCMC.step(\n    rng::Random.AbstractRNG, model::MiniModel, sampler::MHSampler; kwargs...\n)\n    vi = VarInfo()\n    ctx = SamplingContext(rng, PriorSampler())\n    model.f(vi, ctx, values(model.data)...)\n    return vi, vi\nend\n\n# The following steps: Sampling with random-walk proposal\nfunction AbstractMCMC.step(\n    rng::Random.AbstractRNG,\n    model::MiniModel,\n    sampler::MHSampler,\n    prev_state::VarInfo; # is just the old trace\n    kwargs...,\n)\n    vi = prev_state\n    new_vi = deepcopy(vi)\n    ctx = SamplingContext(rng, sampler)\n    model.f(new_vi, ctx, values(model.data)...)\n\n    # Compute log acceptance probability\n    # Since the proposal is symmetric the computation can be simplified\n    logα = sum(values(new_vi.logps)) - sum(values(vi.logps))\n\n    # Accept proposal with computed acceptance probability\n    if -randexp(rng) &lt; logα\n        return new_vi, new_vi\n    else\n        return prev_state, prev_state\n    end\nend;\n\nTo make it easier to analyze the samples and compare them with results from Turing, additionally we define a version of AbstractMCMC.bundle_samples for our model and sampler that returns a MCMCChains.Chains object of samples.\n\nfunction AbstractMCMC.bundle_samples(\n    samples, model::MiniModel, ::MHSampler, ::Any, ::Type{Chains}; kwargs...\n)\n    # We get a vector of traces\n    values = [sample.values for sample in samples]\n    params = [key for key in keys(values[1]) if key ∉ keys(model.data)]\n    vals = reduce(hcat, [value[p] for value in values] for p in params)\n    # Composing the `Chains` data-structure, of which analyzing infrastructure is provided\n    chains = Chains(vals, params)\n    return chains\nend;\n\nLet us check how our mini probabilistic programming language works. We define the probabilistic model:\n\n@mini_model function m(x)\n    a ~ Normal(0.5, 1)\n    b ~ Normal(a, 2)\n    x ~ Normal(b, 0.5)\n    return nothing\nend;\n\nWe perform inference with data x = 3.0:\n\nsample(MiniModel(m, (x=3.0,)), MHSampler(), 1_000_000; chain_type=Chains, progress=false)\n\nChains MCMC chain (1000000×2×1 Array{Float64, 3}):\n\nIterations        = 1:1:1000000\nNumber of chains  = 1\nSamples per chain = 1000000\nparameters        = a, b\n\nSummary Statistics\n  parameters      mean       std      mcse      ess_bulk      ess_tail      rh ⋯\n      Symbol   Float64   Float64   Float64       Float64       Float64   Float ⋯\n\n           a    0.9741    0.8978    0.0032    80452.3591   119923.2631    1.00 ⋯\n           b    2.8816    0.4883    0.0012   171248.8999   214816.3094    1.00 ⋯\n                                                               2 columns omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n           a   -0.7845    0.3671    0.9758    1.5828    2.7320\n           b    1.9235    2.5511    2.8825    3.2116    3.8360\n\n\nWe compare these results with Turing.\n\nusing Turing\nusing PDMats\n\n@model function turing_m(x)\n    a ~ Normal(0.5, 1)\n    b ~ Normal(a, 2)\n    x ~ Normal(b, 0.5)\n    return nothing\nend\n\nsample(turing_m(3.0), MH(ScalMat(2, 1.0)), 1_000_000, progress=false)\n\nChains MCMC chain (1000000×3×1 Array{Float64, 3}):\n\nIterations        = 1:1:1000000\nNumber of chains  = 1\nSamples per chain = 1000000\nWall duration     = 40.8 seconds\nCompute duration  = 40.8 seconds\nparameters        = a, b\ninternals         = lp\n\nSummary Statistics\n  parameters      mean       std      mcse      ess_bulk      ess_tail      rh ⋯\n      Symbol   Float64   Float64   Float64       Float64       Float64   Float ⋯\n\n           a    0.9813    0.8995    0.0031    82655.0753   122931.7084    1.00 ⋯\n           b    2.8798    0.4879    0.0012   173156.2289   211967.5189    1.00 ⋯\n                                                               2 columns omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n           a   -0.7849    0.3749    0.9828    1.5863    2.7460\n           b    1.9241    2.5521    2.8807    3.2082    3.8373\n\n\nAs you can see, with our simple probabilistic programming language and custom samplers we get similar results as Turing.\n\n\n\n\n Back to top",
    "crumbs": [
      "Get Started",
      "Developers",
      "DynamicPPL in Depth",
      "A Mini Turing Implementation I: Compiler"
    ]
  },
  {
    "objectID": "tutorials/docs-04-for-developers-abstractmcmc-turing/index.html",
    "href": "tutorials/docs-04-for-developers-abstractmcmc-turing/index.html",
    "title": "How Turing implements AbstractMCMC",
    "section": "",
    "text": "Prerequisite: Interface guide.",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "How Turing implements AbstractMCMC"
    ]
  },
  {
    "objectID": "tutorials/docs-04-for-developers-abstractmcmc-turing/index.html#introduction",
    "href": "tutorials/docs-04-for-developers-abstractmcmc-turing/index.html#introduction",
    "title": "How Turing implements AbstractMCMC",
    "section": "Introduction",
    "text": "Introduction\nConsider the following Turing, code block:\n\nusing Turing\n\n@model function gdemo(x, y)\n    s² ~ InverseGamma(2, 3)\n    m ~ Normal(0, sqrt(s²))\n    x ~ Normal(m, sqrt(s²))\n    return y ~ Normal(m, sqrt(s²))\nend\n\nmod = gdemo(1.5, 2)\nalg = IS()\nn_samples = 1000\n\nchn = sample(mod, alg, n_samples, progress=false)\n\nChains MCMC chain (1000×3×1 Array{Float64, 3}):\n\nLog evidence      = -3.7305602419054322\nIterations        = 1:1:1000\nNumber of chains  = 1\nSamples per chain = 1000\nWall duration     = 2.29 seconds\nCompute duration  = 2.29 seconds\nparameters        = s², m\ninternals         = lp\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n          s²    2.8795    4.0775    0.1381   985.5265   847.0259    1.0039     ⋯\n           m   -0.0838    1.6428    0.0544   912.1986   934.8019    1.0009     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n          s²    0.5335    1.0777    1.8098    3.1746   11.2965\n           m   -3.5336   -0.9789   -0.0333    0.8717    3.1015\n\n\nThe function sample is part of the AbstractMCMC interface. As explained in the interface guide, building a sampling method that can be used by sample consists in overloading the structs and functions in AbstractMCMC. The interface guide also gives a standalone example of their implementation, AdvancedMH.jl.\nTuring sampling methods (most of which are written here) also implement AbstractMCMC. Turing defines a particular architecture for AbstractMCMC implementations, that enables working with models defined by the @model macro, and uses DynamicPPL as a backend. The goal of this page is to describe this architecture, and how you would go about implementing your own sampling method in Turing, using Importance Sampling as an example. I don’t go into all the details: for instance, I don’t address selectors or parallelism.\nFirst, we explain how Importance Sampling works in the abstract. Consider the model defined in the first code block. Mathematically, it can be written:\n\\[\n\\begin{align*}\ns &\\sim \\text{InverseGamma}(2, 3), \\\\\nm &\\sim \\text{Normal}(0, \\sqrt{s}), \\\\\nx &\\sim \\text{Normal}(m, \\sqrt{s}), \\\\\ny &\\sim \\text{Normal}(m, \\sqrt{s}).\n\\end{align*}\n\\]\nThe latent variables are \\(s\\) and \\(m\\), the observed variables are \\(x\\) and \\(y\\). The model joint distribution \\(p(s,m,x,y)\\) decomposes into the prior \\(p(s,m)\\) and the likelihood \\(p(x,y \\mid s,m).\\) Since \\(x = 1.5\\) and \\(y = 2\\) are observed, the goal is to infer the posterior distribution \\(p(s,m \\mid x,y).\\)\nImportance Sampling produces independent samples \\((s_i, m_i)\\) from the prior distribution. It also outputs unnormalized weights\n\\[\nw_i = \\frac {p(x,y,s_i,m_i)} {p(s_i, m_i)} = p(x,y \\mid s_i, m_i)\n\\]\nsuch that the empirical distribution\n\\[\n\\frac{1}{N} \\sum_{i =1}^N \\frac {w_i} {\\sum_{j=1}^N w_j} \\delta_{(s_i, m_i)}\n\\]\nis a good approximation of the posterior.",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "How Turing implements AbstractMCMC"
    ]
  },
  {
    "objectID": "tutorials/docs-04-for-developers-abstractmcmc-turing/index.html#define-a-sampler",
    "href": "tutorials/docs-04-for-developers-abstractmcmc-turing/index.html#define-a-sampler",
    "title": "How Turing implements AbstractMCMC",
    "section": "1. Define a Sampler",
    "text": "1. Define a Sampler\nRecall the last line of the above code block:\n\nchn = sample(mod, alg, n_samples, progress=false)\n\nChains MCMC chain (1000×3×1 Array{Float64, 3}):\n\nLog evidence      = -3.804462613647176\nIterations        = 1:1:1000\nNumber of chains  = 1\nSamples per chain = 1000\nWall duration     = 0.08 seconds\nCompute duration  = 0.08 seconds\nparameters        = s², m\ninternals         = lp\n\nSummary Statistics\n  parameters      mean       std      mcse    ess_bulk   ess_tail      rhat    ⋯\n      Symbol   Float64   Float64   Float64     Float64    Float64   Float64    ⋯\n\n          s²    3.0974    4.6309    0.1543    722.4327   588.1708    1.0021    ⋯\n           m   -0.0457    1.7388    0.0535   1024.1448   888.2241    1.0011    ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n          s²    0.5571    1.1922    1.8804    3.3932   12.4002\n           m   -3.5371   -1.0026    0.0619    0.8493    3.5885\n\n\nHere sample takes as arguments a model mod, an algorithm alg, and a number of samples n_samples, and returns an instance chn of Chains which can be analysed using the functions in MCMCChains.\n\nModels\nTo define a model, you declare a joint distribution on variables in the @model macro, and specify which variables are observed and which should be inferred, as well as the value of the observed variables. Thus, when implementing Importance Sampling,\n\nmod = gdemo(1.5, 2)\n\nDynamicPPL.Model{typeof(gdemo), (:x, :y), (), (), Tuple{Float64, Int64}, Tuple{}, DynamicPPL.DefaultContext}(Main.Notebook.gdemo, (x = 1.5, y = 2), NamedTuple(), DynamicPPL.DefaultContext())\n\n\ncreates an instance mod of the struct Model, which corresponds to the observations of a value of 1.5 for x, and a value of 2 for y.\nThis is all handled by DynamicPPL, more specifically here. I will return to how models are used to inform sampling algorithms below.\n\n\nAlgorithms\nAn algorithm is just a sampling method: in Turing, it is a subtype of the abstract type InferenceAlgorithm. Defining an algorithm may require specifying a few high-level parameters. For example, “Hamiltonian Monte-Carlo” may be too vague, but “Hamiltonian Monte Carlo with 10 leapfrog steps per proposal and a stepsize of 0.01” is an algorithm. “Metropolis-Hastings” may be too vague, but “Metropolis-Hastings with proposal distribution p” is an algorithm. Thus\n\nstepsize = 0.01\nL = 10\nalg = HMC(stepsize, L)\n\nHMC{AutoForwardDiff{nothing, Nothing}, (), AdvancedHMC.UnitEuclideanMetric}(0.01, 10, AutoForwardDiff{nothing, Nothing}(nothing))\n\n\ndefines a Hamiltonian Monte-Carlo algorithm, an instance of HMC, which is a subtype of InferenceAlgorithm.\nIn the case of Importance Sampling, there is no need to specify additional parameters:\n\nalg = IS()\n\nIS{()}()\n\n\ndefines an Importance Sampling algorithm, an instance of IS, a subtype of InferenceAlgorithm.\nWhen creating your own Turing sampling method, you must, therefore, build a subtype of InferenceAlgorithm corresponding to your method.\n\n\nSamplers\nSamplers are not the same as algorithms. An algorithm is a generic sampling method, a sampler is an object that stores information about how algorithm and model interact during sampling, and is modified as sampling progresses. The Sampler struct is defined in DynamicPPL.\nTuring implements AbstractMCMC’s AbstractSampler with the Sampler struct defined in DynamicPPL. The most important attributes of an instance spl of Sampler are:\n\nspl.alg: the sampling method used, an instance of a subtype of InferenceAlgorithm\nspl.state: information about the sampling process, see below\n\nWhen you call sample(mod, alg, n_samples), Turing first uses model and alg to build an instance spl of Sampler , then calls the native AbstractMCMC function sample(mod, spl, n_samples).\nWhen you define your own Turing sampling method, you must therefore build:\n\na sampler constructor that uses a model and an algorithm to initialize an instance of Sampler. For Importance Sampling:\n\n\nfunction Sampler(alg::IS, model::Model, s::Selector)\n    info = Dict{Symbol,Any}()\n    state = ISState(model)\n    return Sampler(alg, info, s, state)\nend\n\n\na state struct implementing AbstractSamplerState corresponding to your method: we cover this in the following paragraph.\n\n\n\nStates\nThe vi field contains all the important information about sampling: first and foremost, the values of all the samples, but also the distributions from which they are sampled, the names of model parameters, and other metadata. As we will see below, many important steps during sampling correspond to queries or updates to spl.state.vi.\nBy default, you can use SamplerState, a concrete type defined in inference/Inference.jl, which extends AbstractSamplerState and has no field except for vi:\n\nmutable struct SamplerState{VIType&lt;:VarInfo} &lt;: AbstractSamplerState\n    vi::VIType\nend\n\nWhen doing Importance Sampling, we care not only about the values of the samples but also their weights. We will see below that the weight of each sample is also added to spl.state.vi. Moreover, the average\n\\[\n\\frac 1 N \\sum_{j=1}^N w_i = \\frac 1 N \\sum_{j=1}^N p(x,y \\mid s_i, m_i)\n\\]\nof the sample weights is a particularly important quantity:\n\nit is used to normalize the empirical approximation of the posterior distribution\nits logarithm is the importance sampling estimate of the log evidence \\(\\log p(x, y)\\)\n\nTo avoid having to compute it over and over again, is.jldefines an IS-specific concrete type ISState for sampler states, with an additional field final_logevidence containing\n\\[\n\\log \\frac 1 N \\sum_{j=1}^N w_i.\n\\]\n\nmutable struct ISState{V&lt;:VarInfo,F&lt;:AbstractFloat} &lt;: AbstractSamplerState\n    vi::V\n    final_logevidence::F\nend\n\n# additional constructor\nISState(model::Model) = ISState(VarInfo(model), 0.0)\n\nThe following diagram summarizes the hierarchy presented above.\n\n\n\n\n\n\n\nG\n\n\n\nspl\n\nspl\nSampler\n&lt;:AbstractSampler\n\n\n\nstate\n\nspl.state\nState\n&lt;:AbstractSamplerState\n\n\n\nspl-&gt;state\n\n\n\n\n\nalg\n\nspl.alg\nAlgorithm\n&lt;:InferenceAlgorithm\n\n\n\nspl-&gt;alg\n\n\n\n\n\nplaceholder1\n\n...\n\n\n\nspl-&gt;placeholder1\n\n\n\n\n\nvi\n\nspl.state.vi\nVarInfo\n&lt;:AbstractVarInfo\n\n\n\nstate-&gt;vi\n\n\n\n\n\nplaceholder2\n\n...\n\n\n\nstate-&gt;placeholder2\n\n\n\n\n\nplaceholder3\n\n...\n\n\n\nalg-&gt;placeholder3\n\n\n\n\n\nplaceholder4\n\n...\n\n\n\nplaceholder1-&gt;placeholder4",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "How Turing implements AbstractMCMC"
    ]
  },
  {
    "objectID": "tutorials/docs-04-for-developers-abstractmcmc-turing/index.html#overload-the-functions-used-inside-mcmcsample",
    "href": "tutorials/docs-04-for-developers-abstractmcmc-turing/index.html#overload-the-functions-used-inside-mcmcsample",
    "title": "How Turing implements AbstractMCMC",
    "section": "2. Overload the functions used inside mcmcsample",
    "text": "2. Overload the functions used inside mcmcsample\nA lot of the things here are method-specific. However, Turing also has some functions that make it easier for you to implement these functions, for example.\n\nTransitions\nAbstractMCMC stores information corresponding to each individual sample in objects called transition, but does not specify what the structure of these objects could be. You could decide to implement a type MyTransition for transitions corresponding to the specifics of your methods. However, there are many situations in which the only information you need for each sample is:\n\nits value: \\(\\theta\\)\nlog of the joint probability of the observed data and this sample: lp\n\nInference.jl defines a struct Transition, which corresponds to this default situation\n\nstruct Transition{T,F&lt;:AbstractFloat}\n    θ::T\n    lp::F\nend\n\nIt also contains a constructor that builds an instance of Transition from an instance spl of Sampler: \\(\\theta\\) is spl.state.vi converted to a namedtuple, and lp is getlogp(spl.state.vi). is.jl uses this default constructor at the end of the step! function here.\n\n\nHow sample works\nA crude summary, which ignores things like parallelism, is the following:\nsample calls mcmcsample, which calls\n\nsample_init! to set things up\nstep! repeatedly to produce multiple new transitions\nsample_end! to perform operations once all samples have been obtained\nbundle_samples to convert a vector of transitions into a more palatable type, for instance a Chain.\n\nYou can, of course, implement all of these functions, but AbstractMCMC as well as Turing, also provide default implementations for simple cases. For instance, importance sampling uses the default implementations of sample_init! and bundle_samples, which is why you don’t see code for them inside is.jl.",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "How Turing implements AbstractMCMC"
    ]
  },
  {
    "objectID": "tutorials/docs-04-for-developers-abstractmcmc-turing/index.html#overload-assume-and-observe",
    "href": "tutorials/docs-04-for-developers-abstractmcmc-turing/index.html#overload-assume-and-observe",
    "title": "How Turing implements AbstractMCMC",
    "section": "3. Overload assume and observe",
    "text": "3. Overload assume and observe\nThe functions mentioned above, such as sample_init!, step!, etc., must, of course, use information about the model in order to generate samples! In particular, these functions may need samples from distributions defined in the model or to evaluate the density of these distributions at some values of the corresponding parameters or observations.\nFor an example of the former, consider Importance Sampling as defined in is.jl. This implementation of Importance Sampling uses the model prior distribution as a proposal distribution, and therefore requires samples from the prior distribution of the model. Another example is Approximate Bayesian Computation, which requires multiple samples from the model prior and likelihood distributions in order to generate a single sample.\nAn example of the latter is the Metropolis-Hastings algorithm. At every step of sampling from a target posterior\n\\[\np(\\theta \\mid x_{\\text{obs}}),\n\\]\nin order to compute the acceptance ratio, you need to evaluate the model joint density\n\\[\np\\left(\\theta_{\\text{prop}}, x_{\\text{obs}}\\right)\n\\]\nwith \\(\\theta_{\\text{prop}}\\) a sample from the proposal and \\(x_{\\text{obs}}\\) the observed data.\nThis begs the question: how can these functions access model information during sampling? Recall that the model is stored as an instance m of Model. One of the attributes of m is the model evaluation function m.f, which is built by compiling the @model macro. Executing f runs the tilde statements of the model in order, and adds model information to the sampler (the instance of Sampler that stores information about the ongoing sampling process) at each step (see here for more information about how the @model macro is compiled). The DynamicPPL functions assume and observe determine what kind of information to add to the sampler for every tilde statement.\nConsider an instance m of Model and a sampler spl, with associated VarInfo vi = spl.state.vi. At some point during the sampling process, an AbstractMCMC function such as step! calls m(vi, ...), which calls the model evaluation function m.f(vi, ...).\n\nfor every tilde statement in the @model macro, m.f(vi, ...) returns model-related information (samples, value of the model density, etc.), and adds it to vi. How does it do that?\n\nrecall that the code for m.f(vi, ...) is automatically generated by compilation of the @model macro\nfor every tilde statement in the @model declaration, this code contains a call to assume(vi, ...) if the variable on the LHS of the tilde is a model parameter to infer, and observe(vi, ...) if the variable on the LHS of the tilde is an observation\nin the file corresponding to your sampling method (ie in Turing.jl/src/inference/&lt;your_method&gt;.jl), you have overloaded assume and observe, so that they can modify vi to include the information and samples that you care about!\nat a minimum, assume and observe return the log density lp of the sample or observation. the model evaluation function then immediately calls acclogp!!(vi, lp), which adds lp to the value of the log joint density stored in vi.\n\n\nHere’s what assume looks like for Importance Sampling:\n\nfunction DynamicPPL.assume(rng, spl::Sampler{&lt;:IS}, dist::Distribution, vn::VarName, vi)\n    r = rand(rng, dist)\n    push!(vi, vn, r, dist, spl)\n    return r, 0\nend\n\nThe function first generates a sample r from the distribution dist (the right hand side of the tilde statement). It then adds r to vi, and returns r and 0.\nThe observe function is even simpler:\n\nfunction DynamicPPL.observe(spl::Sampler{&lt;:IS}, dist::Distribution, value, vi)\n    return logpdf(dist, value)\nend\n\nIt simply returns the density (in the discrete case, the probability) of the observed value under the distribution dist.",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "How Turing implements AbstractMCMC"
    ]
  },
  {
    "objectID": "tutorials/docs-04-for-developers-abstractmcmc-turing/index.html#summary-importance-sampling-step-by-step",
    "href": "tutorials/docs-04-for-developers-abstractmcmc-turing/index.html#summary-importance-sampling-step-by-step",
    "title": "How Turing implements AbstractMCMC",
    "section": "4. Summary: Importance Sampling step by step",
    "text": "4. Summary: Importance Sampling step by step\nWe focus on the AbstractMCMC functions that are overridden in is.jl and executed inside mcmcsample: step!, which is called n_samples times, and sample_end!, which is executed once after those n_samples iterations.\n\nDuring the \\(i\\)-th iteration, step! does 3 things:\n\nempty!!(spl.state.vi): remove information about the previous sample from the sampler’s VarInfo\nmodel(rng, spl.state.vi, spl): call the model evaluation function\n\ncalls to assume add the samples from the prior \\(s_i\\) and \\(m_i\\) to spl.state.vi\ncalls to assume or observe are followed by the line acclogp!!(vi, lp), where lp is an output of assume and observe\nlp is set to 0 after assume, and to the value of the density at the observation after observe\nWhen all the tilde statements have been covered, spl.state.vi.logp[] is the sum of the lp, i.e., the likelihood \\(\\log p(x, y \\mid s_i, m_i) = \\log p(x \\mid s_i, m_i) + \\log p(y \\mid s_i, m_i)\\) of the observations given the latent variable samples \\(s_i\\) and \\(m_i\\).\n\nreturn Transition(spl): build a transition from the sampler, and return that transition\n\nthe transition’s vi field is simply spl.state.vi\nthe lp field contains the likelihood spl.state.vi.logp[]\n\n\nWhen the n_samples iterations are completed, sample_end! fills the final_logevidence field of spl.state\n\nIt simply takes the logarithm of the average of the sample weights, using the log weights for numerical stability",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "How Turing implements AbstractMCMC"
    ]
  },
  {
    "objectID": "tutorials/usage-custom-distribution/index.html",
    "href": "tutorials/usage-custom-distribution/index.html",
    "title": "Custom Distributions",
    "section": "",
    "text": "Turing.jl supports the use of distributions from the Distributions.jl package. By extension, it also supports the use of customized distributions by defining them as subtypes of Distribution type of the Distributions.jl package, as well as corresponding functions.\nThis page shows a workflow of how to define a customized distribution, using our own implementation of a simple Uniform distribution as a simple example.\nusing Distributions, Turing, Random, Bijectors",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Custom Distributions"
    ]
  },
  {
    "objectID": "tutorials/usage-custom-distribution/index.html#define-the-distribution-type",
    "href": "tutorials/usage-custom-distribution/index.html#define-the-distribution-type",
    "title": "Custom Distributions",
    "section": "Define the Distribution Type",
    "text": "Define the Distribution Type\nFirst, define a type of the distribution, as a subtype of a corresponding distribution type in the Distributions.jl package.\n\nstruct CustomUniform &lt;: ContinuousUnivariateDistribution end",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Custom Distributions"
    ]
  },
  {
    "objectID": "tutorials/usage-custom-distribution/index.html#implement-sampling-and-evaluation-of-the-log-pdf",
    "href": "tutorials/usage-custom-distribution/index.html#implement-sampling-and-evaluation-of-the-log-pdf",
    "title": "Custom Distributions",
    "section": "Implement Sampling and Evaluation of the log-pdf",
    "text": "Implement Sampling and Evaluation of the log-pdf\nSecond, implement the rand and logpdf functions for your new distribution, which will be used to run the model.\n\n# sample in [0, 1]\nDistributions.rand(rng::AbstractRNG, d::CustomUniform) = rand(rng)\n\n# p(x) = 1 → log[p(x)] = 0\nDistributions.logpdf(d::CustomUniform, x::Real) = zero(x)",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Custom Distributions"
    ]
  },
  {
    "objectID": "tutorials/usage-custom-distribution/index.html#define-helper-functions",
    "href": "tutorials/usage-custom-distribution/index.html#define-helper-functions",
    "title": "Custom Distributions",
    "section": "Define Helper Functions",
    "text": "Define Helper Functions\nIn most cases, it may be required to define some helper functions.\n\nDomain Transformation\nCertain samplers, such as HMC, require the domain of the priors to be unbounded. Therefore, to use our CustomUniform as a prior in a model we also need to define how to transform samples from [0, 1] to ℝ. To do this, we need to define the corresponding Bijector from Bijectors.jl, which is what Turing.jl uses internally to deal with constrained distributions.\nTo transform from [0, 1] to ℝ we can use the Logit bijector:\n\nBijectors.bijector(d::CustomUniform) = Logit(0.0, 1.0)\n\nIn the present example, CustomUniform is a subtype of ContinuousUnivariateDistribution. The procedure for subtypes of ContinuousMultivariateDistribution and ContinuousMatrixDistribution is exactly the same. For example, Wishart defines a distribution over positive-definite matrices and so bijector returns a PDBijector when called with a Wishart distribution as an argument. For discrete distributions, there is no need to define a bijector; the Identity bijector is used by default.\nAs an alternative to the above, for UnivariateDistribution we could define the minimum and maximum of the distribution:\n\nDistributions.minimum(d::CustomUniform) = 0.0\nDistributions.maximum(d::CustomUniform) = 1.0\n\nand Bijectors.jl will return a default Bijector called TruncatedBijector which makes use of minimum and maximum derive the correct transformation.\nInternally, Turing basically does the following when it needs to convert a constrained distribution to an unconstrained distribution, e.g. when sampling using HMC:\n\ndist = Gamma(2,3)\nb = bijector(dist)\ntransformed_dist = transformed(dist, b) # results in distribution with transformed support + correction for logpdf\n\nBijectors.UnivariateTransformed{Distributions.Gamma{Float64}, Base.Fix1{typeof(broadcast), typeof(log)}}(\ndist: Distributions.Gamma{Float64}(α=2.0, θ=3.0)\ntransform: Base.Fix1{typeof(broadcast), typeof(log)}(broadcast, log)\n)\n\n\nand then we can call rand and logpdf as usual, where\n\nrand(transformed_dist) returns a sample in the unconstrained space, and\nlogpdf(transformed_dist, y) returns the log density of the original distribution, but with y living in the unconstrained space.\n\nTo read more about Bijectors.jl, check out its documentation.",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Custom Distributions"
    ]
  },
  {
    "objectID": "tutorials/02-logistic-regression/index.html",
    "href": "tutorials/02-logistic-regression/index.html",
    "title": "Bayesian Logistic Regression",
    "section": "",
    "text": "Bayesian logistic regression is the Bayesian counterpart to a common tool in machine learning, logistic regression. The goal of logistic regression is to predict a one or a zero for a given training item. An example might be predicting whether someone is sick or ill given their symptoms and personal information.\nIn our example, we’ll be working to predict whether someone is likely to default with a synthetic dataset found in the RDatasets package. This dataset, Defaults, comes from R’s ISLR package and contains information on borrowers.\nTo start, let’s import all the libraries we’ll need.\n# Import Turing and Distributions.\nusing Turing, Distributions\n\n# Import RDatasets.\nusing RDatasets\n\n# Import MCMCChains, Plots, and StatsPlots for visualizations and diagnostics.\nusing MCMCChains, Plots, StatsPlots\n\n# We need a logistic function, which is provided by StatsFuns.\nusing StatsFuns: logistic\n\n# Functionality for splitting and normalizing the data\nusing MLDataUtils: shuffleobs, stratifiedobs, rescale!\n\n# Set a seed for reproducibility.\nusing Random\nRandom.seed!(0);",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Bayesian Logistic Regression"
    ]
  },
  {
    "objectID": "tutorials/02-logistic-regression/index.html#data-cleaning-set-up",
    "href": "tutorials/02-logistic-regression/index.html#data-cleaning-set-up",
    "title": "Bayesian Logistic Regression",
    "section": "Data Cleaning & Set Up",
    "text": "Data Cleaning & Set Up\nNow we’re going to import our dataset. The first six rows of the dataset are shown below so you can get a good feel for what kind of data we have.\n\n# Import the \"Default\" dataset.\ndata = RDatasets.dataset(\"ISLR\", \"Default\");\n\n# Show the first six rows of the dataset.\nfirst(data, 6)\n\n6×4 DataFrame\n\n\n\nRow\nDefault\nStudent\nBalance\nIncome\n\n\n\nCat…\nCat…\nFloat64\nFloat64\n\n\n\n\n1\nNo\nNo\n729.526\n44361.6\n\n\n2\nNo\nYes\n817.18\n12106.1\n\n\n3\nNo\nNo\n1073.55\n31767.1\n\n\n4\nNo\nNo\n529.251\n35704.5\n\n\n5\nNo\nNo\n785.656\n38463.5\n\n\n6\nNo\nYes\n919.589\n7491.56\n\n\n\n\n\n\nMost machine learning processes require some effort to tidy up the data, and this is no different. We need to convert the Default and Student columns, which say “Yes” or “No” into 1s and 0s. Afterwards, we’ll get rid of the old words-based columns.\n\n# Convert \"Default\" and \"Student\" to numeric values.\ndata[!, :DefaultNum] = [r.Default == \"Yes\" ? 1.0 : 0.0 for r in eachrow(data)]\ndata[!, :StudentNum] = [r.Student == \"Yes\" ? 1.0 : 0.0 for r in eachrow(data)]\n\n# Delete the old columns which say \"Yes\" and \"No\".\nselect!(data, Not([:Default, :Student]))\n\n# Show the first six rows of our edited dataset.\nfirst(data, 6)\n\n6×4 DataFrame\n\n\n\nRow\nBalance\nIncome\nDefaultNum\nStudentNum\n\n\n\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n729.526\n44361.6\n0.0\n0.0\n\n\n2\n817.18\n12106.1\n0.0\n1.0\n\n\n3\n1073.55\n31767.1\n0.0\n0.0\n\n\n4\n529.251\n35704.5\n0.0\n0.0\n\n\n5\n785.656\n38463.5\n0.0\n0.0\n\n\n6\n919.589\n7491.56\n0.0\n1.0\n\n\n\n\n\n\nAfter we’ve done that tidying, it’s time to split our dataset into training and testing sets, and separate the labels from the data. We separate our data into two halves, train and test. You can use a higher percentage of splitting (or a lower one) by modifying the at = 0.05 argument. We have highlighted the use of only a 5% sample to show the power of Bayesian inference with small sample sizes.\nWe must rescale our variables so that they are centered around zero by subtracting each column by the mean and dividing it by the standard deviation. Without this step, Turing’s sampler will have a hard time finding a place to start searching for parameter estimates. To do this we will leverage MLDataUtils, which also lets us effortlessly shuffle our observations and perform a stratified split to get a representative test set.\n\nfunction split_data(df, target; at=0.70)\n    shuffled = shuffleobs(df)\n    return trainset, testset = stratifiedobs(row -&gt; row[target], shuffled; p=at)\nend\n\nfeatures = [:StudentNum, :Balance, :Income]\nnumerics = [:Balance, :Income]\ntarget = :DefaultNum\n\ntrainset, testset = split_data(data, target; at=0.05)\nfor feature in numerics\n    μ, σ = rescale!(trainset[!, feature]; obsdim=1)\n    rescale!(testset[!, feature], μ, σ; obsdim=1)\nend\n\n# Turing requires data in matrix form, not dataframe\ntrain = Matrix(trainset[:, features])\ntest = Matrix(testset[:, features])\ntrain_label = trainset[:, target]\ntest_label = testset[:, target];",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Bayesian Logistic Regression"
    ]
  },
  {
    "objectID": "tutorials/02-logistic-regression/index.html#model-declaration",
    "href": "tutorials/02-logistic-regression/index.html#model-declaration",
    "title": "Bayesian Logistic Regression",
    "section": "Model Declaration",
    "text": "Model Declaration\nFinally, we can define our model.\nlogistic_regression takes four arguments:\n\nx is our set of independent variables;\ny is the element we want to predict;\nn is the number of observations we have; and\nσ is the standard deviation we want to assume for our priors.\n\nWithin the model, we create four coefficients (intercept, student, balance, and income) and assign a prior of normally distributed with means of zero and standard deviations of σ. We want to find values of these four coefficients to predict any given y.\nThe for block creates a variable v which is the logistic function. We then observe the likelihood of calculating v given the actual label, y[i].\n\n# Bayesian logistic regression (LR)\n@model function logistic_regression(x, y, n, σ)\n    intercept ~ Normal(0, σ)\n\n    student ~ Normal(0, σ)\n    balance ~ Normal(0, σ)\n    income ~ Normal(0, σ)\n\n    for i in 1:n\n        v = logistic(intercept + student * x[i, 1] + balance * x[i, 2] + income * x[i, 3])\n        y[i] ~ Bernoulli(v)\n    end\nend;",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Bayesian Logistic Regression"
    ]
  },
  {
    "objectID": "tutorials/02-logistic-regression/index.html#sampling",
    "href": "tutorials/02-logistic-regression/index.html#sampling",
    "title": "Bayesian Logistic Regression",
    "section": "Sampling",
    "text": "Sampling\nNow we can run our sampler. This time we’ll use NUTS to sample from our posterior.\n\nsetprogress!(false)\n\n\n# Retrieve the number of observations.\nn, _ = size(train)\n\n# Sample using NUTS.\nm = logistic_regression(train, train_label, n, 1)\nchain = sample(m, NUTS(), MCMCThreads(), 1_500, 3)\n\n\n\nChains MCMC chain (1500×16×3 Array{Float64, 3}):\n\nIterations        = 751:1:2250\nNumber of chains  = 3\nSamples per chain = 1500\nWall duration     = 13.02 seconds\nCompute duration  = 10.69 seconds\nparameters        = intercept, student, balance, income\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n  parameters      mean       std      mcse    ess_bulk    ess_tail      rhat   ⋯\n      Symbol   Float64   Float64   Float64     Float64     Float64   Float64   ⋯\n\n   intercept   -4.2131    0.4022    0.0075   2909.4307   2880.3696    1.0010   ⋯\n     student   -0.9800    0.6162    0.0122   2572.7491   2663.3742    1.0012   ⋯\n     balance    1.8262    0.2967    0.0055   2938.0215   2346.9083    1.0005   ⋯\n      income   -0.4186    0.3466    0.0070   2470.9212   2633.4921    1.0009   ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n   intercept   -5.0226   -4.4787   -4.1987   -3.9314   -3.4704\n     student   -2.1802   -1.3931   -0.9773   -0.5709    0.2260\n     balance    1.2413    1.6306    1.8177    2.0219    2.4276\n      income   -1.1091   -0.6518   -0.4101   -0.1906    0.2653\n\n\n\n\n\n\n\n\nSampling With Multiple Threads\n\n\n\n\n\nThe sample() call above assumes that you have at least nchains threads available in your Julia instance. If you do not, the multiple chains will run sequentially, and you may notice a warning. For more information, see the Turing documentation on sampling multiple chains.\n\n\n\nSince we ran multiple chains, we may as well do a spot check to make sure each chain converges around similar points.\n\nplot(chain)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLooks good!\nWe can also use the corner function from MCMCChains to show the distributions of the various parameters of our logistic regression.\n\n# The labels to use.\nl = [:student, :balance, :income]\n\n# Use the corner function. Requires StatsPlots and MCMCChains.\ncorner(chain, l)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFortunately the corner plot appears to demonstrate unimodal distributions for each of our parameters, so it should be straightforward to take the means of each parameter’s sampled values to estimate our model to make predictions.",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Bayesian Logistic Regression"
    ]
  },
  {
    "objectID": "tutorials/02-logistic-regression/index.html#making-predictions",
    "href": "tutorials/02-logistic-regression/index.html#making-predictions",
    "title": "Bayesian Logistic Regression",
    "section": "Making Predictions",
    "text": "Making Predictions\nHow do we test how well the model actually predicts whether someone is likely to default? We need to build a prediction function that takes the test object we made earlier and runs it through the average parameter calculated during sampling.\nThe prediction function below takes a Matrix and a Chain object. It takes the mean of each parameter’s sampled values and re-runs the logistic function using those mean values for every element in the test set.\n\nfunction prediction(x::Matrix, chain, threshold)\n    # Pull the means from each parameter's sampled values in the chain.\n    intercept = mean(chain[:intercept])\n    student = mean(chain[:student])\n    balance = mean(chain[:balance])\n    income = mean(chain[:income])\n\n    # Retrieve the number of rows.\n    n, _ = size(x)\n\n    # Generate a vector to store our predictions.\n    v = Vector{Float64}(undef, n)\n\n    # Calculate the logistic function for each element in the test set.\n    for i in 1:n\n        num = logistic(\n            intercept .+ student * x[i, 1] + balance * x[i, 2] + income * x[i, 3]\n        )\n        if num &gt;= threshold\n            v[i] = 1\n        else\n            v[i] = 0\n        end\n    end\n    return v\nend;\n\nLet’s see how we did! We run the test matrix through the prediction function, and compute the mean squared error (MSE) for our prediction. The threshold variable sets the sensitivity of the predictions. For example, a threshold of 0.07 will predict a defualt value of 1 for any predicted value greater than 0.07 and no default if it is less than 0.07.\n\n# Set the prediction threshold.\nthreshold = 0.07\n\n# Make the predictions.\npredictions = prediction(test, chain, threshold)\n\n# Calculate MSE for our test set.\nloss = sum((predictions - test_label) .^ 2) / length(test_label)\n\n0.12021052631578948\n\n\nPerhaps more important is to see what percentage of defaults we correctly predicted. The code below simply counts defaults and predictions and presents the results.\n\ndefaults = sum(test_label)\nnot_defaults = length(test_label) - defaults\n\npredicted_defaults = sum(test_label .== predictions .== 1)\npredicted_not_defaults = sum(test_label .== predictions .== 0)\n\nprintln(\"Defaults: $defaults\n    Predictions: $predicted_defaults\n    Percentage defaults correct $(predicted_defaults/defaults)\")\n\nprintln(\"Not defaults: $not_defaults\n    Predictions: $predicted_not_defaults\n    Percentage non-defaults correct $(predicted_not_defaults/not_defaults)\")\n\nDefaults: 316.0\n    Predictions: 279\n    Percentage defaults correct 0.8829113924050633\nNot defaults: 9184.0\n    Predictions: 8079\n    Percentage non-defaults correct 0.8796820557491289\n\n\nThe above shows that with a threshold of 0.07, we correctly predict a respectable portion of the defaults, and correctly identify most non-defaults. This is fairly sensitive to a choice of threshold, and you may wish to experiment with it.\nThis tutorial has demonstrated how to use Turing to perform Bayesian logistic regression.",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Bayesian Logistic Regression"
    ]
  },
  {
    "objectID": "tutorials/docs-11-using-turing-dynamichmc/index.html",
    "href": "tutorials/docs-11-using-turing-dynamichmc/index.html",
    "title": "Using DynamicHMC",
    "section": "",
    "text": "Turing supports the use of DynamicHMC as a sampler through the DynamicNUTS function.\nTo use the DynamicNUTS function, you must import the DynamicHMC package as well as Turing. Turing does not formally require DynamicHMC but will include additional functionality if both packages are present.\nHere is a brief example:\n\nHow to apply DynamicNUTS:\n\n# Import Turing and DynamicHMC.\nusing DynamicHMC, Turing\n\n# Model definition.\n@model function gdemo(x, y)\n    s² ~ InverseGamma(2, 3)\n    m ~ Normal(0, sqrt(s²))\n    x ~ Normal(m, sqrt(s²))\n    return y ~ Normal(m, sqrt(s²))\nend\n\n# Pull 2,000 samples using DynamicNUTS.\ndynamic_nuts = externalsampler(DynamicHMC.NUTS())\nchn = sample(gdemo(1.5, 2.0), dynamic_nuts, 2000, progress=false)\n\nChains MCMC chain (2000×3×1 Array{Float64, 3}):\n\nIterations        = 1:1:2000\nNumber of chains  = 1\nSamples per chain = 2000\nWall duration     = 8.13 seconds\nCompute duration  = 8.13 seconds\nparameters        = s², m\ninternals         = lp\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n          s²    2.0276    2.2138    0.0834   920.7662   810.5409    1.0001     ⋯\n           m    1.1562    0.7886    0.0280   893.6169   735.8048    0.9997     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n          s²    0.5535    1.0351    1.4852    2.2951    6.4053\n           m   -0.5804    0.7332    1.1721    1.6137    2.7329\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Using DynamicHMC"
    ]
  },
  {
    "objectID": "tutorials/07-poisson-regression/index.html",
    "href": "tutorials/07-poisson-regression/index.html",
    "title": "Bayesian Poisson Regression",
    "section": "",
    "text": "This notebook is ported from the example notebook of PyMC3 on Poisson Regression.\nPoisson Regression is a technique commonly used to model count data. Some of the applications include predicting the number of people defaulting on their loans or the number of cars running on a highway on a given day. This example describes a method to implement the Bayesian version of this technique using Turing.\nWe will generate the dataset that we will be working on which describes the relationship between number of times a person sneezes during the day with his alcohol consumption and medicinal intake.\nWe start by importing the required libraries.\n\n#Import Turing, Distributions and DataFrames\nusing Turing, Distributions, DataFrames, Distributed\n\n# Import MCMCChain, Plots, and StatsPlots for visualizations and diagnostics.\nusing MCMCChains, Plots, StatsPlots\n\n# Set a seed for reproducibility.\nusing Random\nRandom.seed!(12);\n\n\nGenerating data\nWe start off by creating a toy dataset. We take the case of a person who takes medicine to prevent excessive sneezing. Alcohol consumption increases the rate of sneezing for that person. Thus, the two factors affecting the number of sneezes in a given day are alcohol consumption and whether the person has taken his medicine. Both these variable are taken as boolean valued while the number of sneezes will be a count valued variable. We also take into consideration that the interaction between the two boolean variables will affect the number of sneezes\n5 random rows are printed from the generated data to get a gist of the data generated.\n\ntheta_noalcohol_meds = 1    # no alcohol, took medicine\ntheta_alcohol_meds = 3      # alcohol, took medicine\ntheta_noalcohol_nomeds = 6  # no alcohol, no medicine\ntheta_alcohol_nomeds = 36   # alcohol, no medicine\n\n# no of samples for each of the above cases\nq = 100\n\n#Generate data from different Poisson distributions\nnoalcohol_meds = Poisson(theta_noalcohol_meds)\nalcohol_meds = Poisson(theta_alcohol_meds)\nnoalcohol_nomeds = Poisson(theta_noalcohol_nomeds)\nalcohol_nomeds = Poisson(theta_alcohol_nomeds)\n\nnsneeze_data = vcat(\n    rand(noalcohol_meds, q),\n    rand(alcohol_meds, q),\n    rand(noalcohol_nomeds, q),\n    rand(alcohol_nomeds, q),\n)\nalcohol_data = vcat(zeros(q), ones(q), zeros(q), ones(q))\nmeds_data = vcat(zeros(q), zeros(q), ones(q), ones(q))\n\ndf = DataFrame(;\n    nsneeze=nsneeze_data,\n    alcohol_taken=alcohol_data,\n    nomeds_taken=meds_data,\n    product_alcohol_meds=meds_data .* alcohol_data,\n)\ndf[sample(1:nrow(df), 5; replace=false), :]\n\n5×4 DataFrame\n\n\n\nRow\nnsneeze\nalcohol_taken\nnomeds_taken\nproduct_alcohol_meds\n\n\n\nInt64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n33\n1.0\n1.0\n1.0\n\n\n2\n37\n1.0\n1.0\n1.0\n\n\n3\n2\n0.0\n0.0\n0.0\n\n\n4\n33\n1.0\n1.0\n1.0\n\n\n5\n0\n0.0\n0.0\n0.0\n\n\n\n\n\n\n\n\nVisualisation of the dataset\nWe plot the distribution of the number of sneezes for the 4 different cases taken above. As expected, the person sneezes the most when he has taken alcohol and not taken his medicine. He sneezes the least when he doesn’t consume alcohol and takes his medicine.\n\n# Data Plotting\n\np1 = Plots.histogram(\n    df[(df[:, :alcohol_taken] .== 0) .& (df[:, :nomeds_taken] .== 0), 1];\n    title=\"no_alcohol+meds\",\n)\np2 = Plots.histogram(\n    (df[(df[:, :alcohol_taken] .== 1) .& (df[:, :nomeds_taken] .== 0), 1]);\n    title=\"alcohol+meds\",\n)\np3 = Plots.histogram(\n    (df[(df[:, :alcohol_taken] .== 0) .& (df[:, :nomeds_taken] .== 1), 1]);\n    title=\"no_alcohol+no_meds\",\n)\np4 = Plots.histogram(\n    (df[(df[:, :alcohol_taken] .== 1) .& (df[:, :nomeds_taken] .== 1), 1]);\n    title=\"alcohol+no_meds\",\n)\nplot(p1, p2, p3, p4; layout=(2, 2), legend=false)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe must convert our DataFrame data into the Matrix form as the manipulations that we are about are designed to work with Matrix data. We also separate the features from the labels which will be later used by the Turing sampler to generate samples from the posterior.\n\n# Convert the DataFrame object to matrices.\ndata = Matrix(df[:, [:alcohol_taken, :nomeds_taken, :product_alcohol_meds]])\ndata_labels = df[:, :nsneeze]\ndata\n\n400×3 Matrix{Float64}:\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n ⋮         \n 1.0  1.0  1.0\n 1.0  1.0  1.0\n 1.0  1.0  1.0\n 1.0  1.0  1.0\n 1.0  1.0  1.0\n 1.0  1.0  1.0\n 1.0  1.0  1.0\n 1.0  1.0  1.0\n 1.0  1.0  1.0\n\n\nWe must recenter our data about 0 to help the Turing sampler in initialising the parameter estimates. So, normalising the data in each column by subtracting the mean and dividing by the standard deviation:\n\n# Rescale our matrices.\ndata = (data .- mean(data; dims=1)) ./ std(data; dims=1)\n\n400×3 Matrix{Float64}:\n -0.998749  -0.998749  -0.576628\n -0.998749  -0.998749  -0.576628\n -0.998749  -0.998749  -0.576628\n -0.998749  -0.998749  -0.576628\n -0.998749  -0.998749  -0.576628\n -0.998749  -0.998749  -0.576628\n -0.998749  -0.998749  -0.576628\n -0.998749  -0.998749  -0.576628\n -0.998749  -0.998749  -0.576628\n -0.998749  -0.998749  -0.576628\n  ⋮                    \n  0.998749   0.998749   1.72988\n  0.998749   0.998749   1.72988\n  0.998749   0.998749   1.72988\n  0.998749   0.998749   1.72988\n  0.998749   0.998749   1.72988\n  0.998749   0.998749   1.72988\n  0.998749   0.998749   1.72988\n  0.998749   0.998749   1.72988\n  0.998749   0.998749   1.72988\n\n\n\n\nDeclaring the Model: Poisson Regression\nOur model, poisson_regression takes four arguments:\n\nx is our set of independent variables;\ny is the element we want to predict;\nn is the number of observations we have; and\nσ² is the standard deviation we want to assume for our priors.\n\nWithin the model, we create four coefficients (b0, b1, b2, and b3) and assign a prior of normally distributed with means of zero and standard deviations of σ². We want to find values of these four coefficients to predict any given y.\nIntuitively, we can think of the coefficients as:\n\nb1 is the coefficient which represents the effect of taking alcohol on the number of sneezes;\nb2 is the coefficient which represents the effect of taking in no medicines on the number of sneezes;\nb3 is the coefficient which represents the effect of interaction between taking alcohol and no medicine on the number of sneezes;\n\nThe for block creates a variable theta which is the weighted combination of the input features. We have defined the priors on these weights above. We then observe the likelihood of calculating theta given the actual label, y[i].\n\n# Bayesian poisson regression (LR)\n@model function poisson_regression(x, y, n, σ²)\n    b0 ~ Normal(0, σ²)\n    b1 ~ Normal(0, σ²)\n    b2 ~ Normal(0, σ²)\n    b3 ~ Normal(0, σ²)\n    for i in 1:n\n        theta = b0 + b1 * x[i, 1] + b2 * x[i, 2] + b3 * x[i, 3]\n        y[i] ~ Poisson(exp(theta))\n    end\nend;\n\n\n\nSampling from the posterior\nWe use the NUTS sampler to sample values from the posterior. We run multiple chains using the MCMCThreads() function to nullify the effect of a problematic chain. We then use the Gelman, Rubin, and Brooks Diagnostic to check the convergence of these multiple chains.\n\n# Retrieve the number of observations.\nn, _ = size(data)\n\n# Sample using NUTS.\n\nnum_chains = 4\nm = poisson_regression(data, data_labels, n, 10)\nchain = sample(m, NUTS(), MCMCThreads(), 2_500, num_chains; discard_adapt=false, progress=false)\n\n\n\nChains MCMC chain (2500×16×4 Array{Float64, 3}):\n\nIterations        = 1:1:2500\nNumber of chains  = 4\nSamples per chain = 2500\nWall duration     = 18.41 seconds\nCompute duration  = 16.02 seconds\nparameters        = b0, b1, b2, b3\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n          b0    1.3477    1.9658    0.2558   206.8787    43.2100    1.0180     ⋯\n          b1    0.4577    1.3704    0.1404   336.2219   135.0028    1.0138     ⋯\n          b2    1.0129    0.9613    0.1295   543.8321    65.0783    1.0152     ⋯\n          b3    0.4414    1.3959    0.1485   355.6939   134.3731    1.0146     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n          b0   -0.7810    1.6061    1.6289    1.6503    1.6920\n          b1    0.3583    0.4628    0.5046    0.5473    1.7111\n          b2    0.7557    0.8307    0.8684    0.9088    3.0996\n          b3   -0.2945    0.2980    0.3381    0.3778    0.4786\n\n\n\n\n\n\n\n\nSampling With Multiple Threads\n\n\n\n\n\nThe sample() call above assumes that you have at least nchains threads available in your Julia instance. If you do not, the multiple chains will run sequentially, and you may notice a warning. For more information, see the Turing documentation on sampling multiple chains.\n\n\n\n\n\nViewing the Diagnostics\nWe use the Gelman, Rubin, and Brooks Diagnostic to check whether our chains have converged. Note that we require multiple chains to use this diagnostic which analyses the difference between these multiple chains.\nWe expect the chains to have converged. This is because we have taken sufficient number of iterations (1500) for the NUTS sampler. However, in case the test fails, then we will have to take a larger number of iterations, resulting in longer computation time.\n\ngelmandiag(chain)\n\nGelman, Rubin, and Brooks diagnostic\n  parameters      psrf    psrfci\n      Symbol   Float64   Float64\n\n          b0    1.2492    1.6703\n          b1    1.1925    1.3827\n          b2    1.2502    1.7107\n          b3    1.2237    1.4823\n\n\nFrom the above diagnostic, we can conclude that the chains have converged because the PSRF values of the coefficients are close to 1.\nSo, we have obtained the posterior distributions of the parameters. We transform the coefficients and recover theta values by taking the exponent of the meaned values of the coefficients b0, b1, b2 and b3. We take the exponent of the means to get a better comparison of the relative values of the coefficients. We then compare this with the intuitive meaning that was described earlier.\n\n# Taking the first chain\nc1 = chain[:, :, 1]\n\n# Calculating the exponentiated means\nb0_exp = exp(mean(c1[:b0]))\nb1_exp = exp(mean(c1[:b1]))\nb2_exp = exp(mean(c1[:b2]))\nb3_exp = exp(mean(c1[:b3]))\n\nprint(\"The exponent of the meaned values of the weights (or coefficients are): \\n\")\nprintln(\"b0: \", b0_exp)\nprintln(\"b1: \", b1_exp)\nprintln(\"b2: \", b2_exp)\nprintln(\"b3: \", b3_exp)\nprint(\"The posterior distributions obtained after sampling can be visualised as :\\n\")\n\nThe exponent of the meaned values of the weights (or coefficients are): \nb0: 4.728374290533704\nb1: 1.602978912398034\nb2: 2.440716971649441\nb3: 1.4676551812080876\nThe posterior distributions obtained after sampling can be visualised as :\n\n\nVisualising the posterior by plotting it:\n\nplot(chain)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpreting the Obtained Mean Values\nThe exponentiated mean of the coefficient b1 is roughly half of that of b2. This makes sense because in the data that we generated, the number of sneezes was more sensitive to the medicinal intake as compared to the alcohol consumption. We also get a weaker dependence on the interaction between the alcohol consumption and the medicinal intake as can be seen from the value of b3.\n\n\nRemoving the Warmup Samples\nAs can be seen from the plots above, the parameters converge to their final distributions after a few iterations. The initial values during the warmup phase increase the standard deviations of the parameters and are not required after we get the desired distributions. Thus, we remove these warmup values and once again view the diagnostics. To remove these warmup values, we take all values except the first 200. This is because we set the second parameter of the NUTS sampler (which is the number of adaptations) to be equal to 200.\n\nchains_new = chain[201:end, :, :]\n\nChains MCMC chain (2300×16×4 Array{Float64, 3}):\n\nIterations        = 201:1:2500\nNumber of chains  = 4\nSamples per chain = 2300\nWall duration     = 18.41 seconds\nCompute duration  = 16.02 seconds\nparameters        = b0, b1, b2, b3\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n  parameters      mean       std      mcse    ess_bulk   ess_tail      rhat    ⋯\n      Symbol   Float64   Float64   Float64     Float64    Float64   Float64    ⋯\n\n          b0    1.6163    0.1733    0.0162    930.0722   398.3579    1.0045    ⋯\n          b1    0.5341    0.3626    0.0336    992.4072   424.9402    1.0020    ⋯\n          b2    0.8962    0.3568    0.0333    866.7129   408.4578    1.0031    ⋯\n          b3    0.3122    0.3170    0.0293   1055.4925   439.0177    1.0020    ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n          b0    1.5650    1.6094    1.6304    1.6513    1.6915\n          b1    0.3890    0.4644    0.5047    0.5449    0.6341\n          b2    0.7619    0.8304    0.8670    0.9048    0.9853\n          b3    0.2190    0.2995    0.3376    0.3756    0.4446\n\n\n\nplot(chains_new)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs can be seen from the numeric values and the plots above, the standard deviation values have decreased and all the plotted values are from the estimated posteriors. The exponentiated mean values, with the warmup samples removed, have not changed by much and they are still in accordance with their intuitive meanings as described earlier.\n\n\n\n\n Back to top",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Bayesian Poisson Regression"
    ]
  },
  {
    "objectID": "tutorials/docs-07-for-developers-variational-inference/index.html",
    "href": "tutorials/docs-07-for-developers-variational-inference/index.html",
    "title": "Variational Inference",
    "section": "",
    "text": "In this post, we’ll examine variational inference (VI), a family of approximate Bayesian inference methods. We will focus on one of the more standard VI methods, Automatic Differentiation Variational Inference (ADVI).\nHere, we’ll examine the theory behind VI, but if you’re interested in using ADVI in Turing, check out this tutorial.",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "Variational Inference"
    ]
  },
  {
    "objectID": "tutorials/docs-07-for-developers-variational-inference/index.html#computing-kl-divergence-without-knowing-the-posterior",
    "href": "tutorials/docs-07-for-developers-variational-inference/index.html#computing-kl-divergence-without-knowing-the-posterior",
    "title": "Variational Inference",
    "section": "Computing KL-divergence without knowing the posterior",
    "text": "Computing KL-divergence without knowing the posterior\nFirst off, recall that\n\n\\[\np(z \\mid x\\_i) = \\frac{p(x\\_i, z)}{p(x\\_i)}\n\\]\n\nso we can write\n\n\\[\n\\begin{align*}\n\\mathrm{D\\_{KL}} \\left( q(z), p(z \\mid \\\\{ x\\_i \\\\}\\_{i = 1}^n) \\right) &= \\mathbb{E}\\_{z \\sim q(z)} \\left[ \\log q(z) \\right] - \\sum\\_{i = 1}^n \\mathbb{E}\\_{z \\sim q(z)} \\left[ \\log p(x\\_i, z) - \\log p(x\\_i) \\right] \\\\\n    &= \\mathbb{E}\\_{z \\sim q(z)} \\left[ \\log q(z) \\right] - \\sum\\_{i = 1}^n \\mathbb{E}\\_{z \\sim q(z)} \\left[ \\log p(x\\_i, z) \\right] + \\sum\\_{i = 1}^n \\mathbb{E}\\_{z \\sim q(z)} \\left[ \\log p(x_i) \\right] \\\\\n    &= \\mathbb{E}\\_{z \\sim q(z)} \\left[ \\log q(z) \\right] - \\sum\\_{i = 1}^n \\mathbb{E}\\_{z \\sim q(z)} \\left[ \\log p(x\\_i, z) \\right] + \\sum\\_{i = 1}^n \\log p(x\\_i),\n\\end{align*}\n\\]\n\nwhere in the last equality we used the fact that \\(p(x_i)\\) is independent of \\(z\\).\nNow you’re probably thinking “Oh great! Now you’ve introduced \\(p(x_i)\\) which we also can’t compute (in general)!”. Woah. Calm down human. Let’s do some more algebra. The above expression can be rearranged to\n\n\\[\n\\mathrm{D\\_{KL}} \\left( q(z), p(z \\mid \\\\{ x\\_i \\\\}\\_{i = 1}^n) \\right) + \\underbrace{\\sum\\_{i = 1}^n \\mathbb{E}\\_{z \\sim q(z)} \\left[ \\log p(x\\_i, z) \\right] - \\mathbb{E}\\_{z \\sim q(z)} \\left[ \\log q(z) \\right]}\\_{=: \\mathrm{ELBO}(q)} = \\underbrace{\\sum\\_{i = 1}^n \\mathbb{E}\\_{z \\sim q(z)} \\left[ \\log p(x\\_i) \\right]}\\_{\\text{constant}}.\n\\]\n\nSee? The left-hand side is constant and, as we mentioned before, \\(\\mathrm{D_{KL}} \\ge 0\\). What happens if we try to maximize the term we just gave the completely arbitrary name \\(\\mathrm{ELBO}\\)? Well, if \\(\\mathrm{ELBO}\\) goes up while \\(p(x_i)\\) stays constant then \\(\\mathrm{D_{KL}}\\) has to go down! That is, the \\(q(z)\\) which minimizes the KL-divergence is the same \\(q(z)\\) which maximizes \\(\\mathrm{ELBO}(q)\\):\n\n\\[\n\\underset{q}{\\mathrm{argmin}} \\  \\mathrm{D\\_{KL}} \\left( q(z), p(z \\mid \\\\{ x\\_i \\\\}\\_{i = 1}^n) \\right) = \\underset{q}{\\mathrm{argmax}} \\ \\mathrm{ELBO}(q)\n\\]\n\nwhere\n\n\\[\n\\begin{align*}\n\\mathrm{ELBO}(q) &:= \\left( \\sum\\_{i = 1}^n \\mathbb{E}\\_{z \\sim q(z)} \\left[ \\log p(x\\_i, z) \\right]  \\right) - \\mathbb{E}\\_{z \\sim q(z)} \\left[ \\log q(z) \\right] \\\\\n    &= \\left( \\sum\\_{i = 1}^n \\mathbb{E}\\_{z \\sim q(z)} \\left[ \\log p(x\\_i, z) \\right] \\right) + \\mathbb{H}\\left( q(z) \\right)\n\\end{align*}\n\\]\n\nand \\(\\mathbb{H} \\left(q(z) \\right)\\) denotes the (differential) entropy of \\(q(z)\\).\nAssuming joint \\(p(x_i, z)\\) and the entropy \\(\\mathbb{H}\\left(q(z)\\right)\\) are both tractable, we can use a Monte-Carlo for the remaining expectation. This leaves us with the following tractable expression\n\n\\[\n\\underset{q}{\\mathrm{argmin}} \\ \\mathrm{D\\_{KL}} \\left( q(z), p(z \\mid \\\\{ x\\_i \\\\}\\_{i = 1}^n) \\right) \\approx \\underset{q}{\\mathrm{argmax}} \\ \\widehat{\\mathrm{ELBO}}(q)\n\\]\n\nwhere\n\n\\[\n\\widehat{\\mathrm{ELBO}}(q) = \\frac{1}{m} \\left( \\sum\\_{k = 1}^m \\sum\\_{i = 1}^n \\log p(x\\_i, z\\_k) \\right) + \\mathbb{H} \\left(q(z)\\right) \\quad \\text{where} \\quad z\\_k \\sim q(z) \\quad \\forall k = 1, \\dots, m.\n\\]\n\nHence, as long as we can sample from \\(q(z)\\) somewhat efficiently, we can indeed minimize the KL-divergence! Neat, eh?\nSidenote: in the case where \\(q(z)\\) is tractable but \\(\\mathbb{H} \\left(q(z) \\right)\\) is not , we can use an Monte-Carlo estimate for this term too but this generally results in a higher-variance estimate.\nAlso, I fooled you real good: the ELBO isn’t an arbitrary name, hah! In fact it’s an abbreviation for the expected lower bound (ELBO) because it, uhmm, well, it’s the expected lower bound (remember \\(\\mathrm{D_{KL}} \\ge 0\\)). Yup.",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "Variational Inference"
    ]
  },
  {
    "objectID": "tutorials/docs-07-for-developers-variational-inference/index.html#maximizing-the-elbo",
    "href": "tutorials/docs-07-for-developers-variational-inference/index.html#maximizing-the-elbo",
    "title": "Variational Inference",
    "section": "Maximizing the ELBO",
    "text": "Maximizing the ELBO\nFinding the optimal \\(q\\) over all possible densities of course isn’t feasible. Instead we consider a family of parameterized densities \\(\\mathscr{D}\\_{\\Theta}\\) where \\(\\Theta\\) denotes the space of possible parameters. Each density in this family \\(q\\_{\\theta} \\in \\mathscr{D}\\_{\\Theta}\\) is parameterized by a unique \\(\\theta \\in \\Theta\\). Moreover, we’ll assume\n\n\\(q\\_{\\theta}(z)\\), i.e. evaluating the probability density \\(q\\) at any point \\(z\\), is differentiable\n\\(z \\sim q\\_{\\theta}(z)\\), i.e. the process of sampling from \\(q\\_{\\theta}(z)\\), is differentiable\n\n\nis fairly straight-forward, but (2) is a bit tricky. What does it even mean for a sampling process to be differentiable? This is quite an interesting problem in its own right and would require something like a 50-page paper to properly review the different approaches (highly recommended read).\n\nWe’re going to make use of a particular such approach which goes under a bunch of different names: reparametrization trick, path derivative, etc. This refers to making the assumption that all elements \\(q\\_{\\theta} \\in \\mathscr{Q}\\_{\\Theta}\\) can be considered as reparameterizations of some base density, say \\(\\bar{q}(z)\\). That is, if \\(q\\_{\\theta} \\in \\mathscr{Q}\\_{\\Theta}\\) then\n\n\\[\nz \\sim q\\_{\\theta}(z) \\quad \\iff \\quad z := g\\_{\\theta}(\\tilde{z}) \\quad \\text{where} \\quad \\bar{z} \\sim \\bar{q}(z)\n\\]\n\nfor some function \\(g\\_{\\theta}\\) differentiable wrt. \\(\\theta\\). So all \\(q_{\\theta} \\in \\mathscr{Q}\\_{\\Theta}\\) are using the same reparameterization-function \\(g\\) but each \\(q\\_{\\theta}\\) correspond to different choices of \\(\\theta\\) for \\(f\\_{\\theta}\\).\nUnder this assumption we can differentiate the sampling process by taking the derivative of \\(g\\_{\\theta}\\) wrt. \\(\\theta\\), and thus we can differentiate the entire \\(\\widehat{\\mathrm{ELBO}}(q\\_{\\theta})\\) wrt. \\(\\theta\\)! With the gradient available we can either try to solve for optimality either by setting the gradient equal to zero or maximize \\(\\widehat{\\mathrm{ELBO}}(q\\_{\\theta})\\) stepwise by traversing \\(\\mathscr{Q}\\_{\\Theta}\\) in the direction of steepest ascent. For the sake of generality, we’re going to go with the stepwise approach.\nWith all this nailed down, we eventually reach the section on Automatic Differentiation Variational Inference (ADVI).",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "Variational Inference"
    ]
  },
  {
    "objectID": "tutorials/docs-07-for-developers-variational-inference/index.html#automatic-differentiation-variational-inference-advi",
    "href": "tutorials/docs-07-for-developers-variational-inference/index.html#automatic-differentiation-variational-inference-advi",
    "title": "Variational Inference",
    "section": "Automatic Differentiation Variational Inference (ADVI)",
    "text": "Automatic Differentiation Variational Inference (ADVI)\nSo let’s revisit the assumptions we’ve made at this point:\n\nThe variational posterior \\(q\\_{\\theta}\\) is in a parameterized family of densities denoted \\(\\mathscr{Q}\\_{\\Theta}\\), with \\(\\theta \\in \\Theta\\).\n\\(\\mathscr{Q}\\_{\\Theta}\\) is a space of reparameterizable densities with \\(\\bar{q}(z)\\) as the base-density.\nThe parameterization function \\(g\\_{\\theta}\\) is differentiable wrt. \\(\\theta\\).\nEvaluation of the probability density \\(q\\_{\\theta}(z)\\) is differentiable wrt. \\(\\theta\\).\n\\(\\mathbb{H}\\left(q\\_{\\theta}(z)\\right)\\) is tractable.\nEvaluation of the joint density \\(p(x, z)\\) is tractable and differentiable wrt. \\(z\\)\nThe support of \\(q(z)\\) is a subspace of the support of \\(p(z \\mid x)\\) : \\(\\mathrm{supp}\\left(q(z)\\right) \\subseteq \\mathrm{supp}\\left(p(z \\mid x)\\right)\\).\n\nAll of these are not necessary to do VI, but they are very convenient and results in a fairly flexible approach. One distribution which has a density satisfying all of the above assumptions except (7) (we’ll get back to this in second) for any tractable and differentiable \\(p(z \\mid \\\\{ x\\_i \\\\}\\_{i = 1}^n)\\) is the good ole’ Gaussian/normal distribution:\n\n\\[\nz \\sim \\mathcal{N}(\\mu, \\Sigma) \\quad \\iff \\quad z = g\\_{\\mu, L}(\\bar{z}) := \\mu + L^T \\tilde{z} \\quad \\text{where} \\quad \\bar{z} \\sim \\bar{q}(z) := \\mathcal{N}(1\\_d, I\\_{d \\times d})\n\\]\n\nwhere \\(\\Sigma = L L^T,\\) with \\(L\\) obtained from the Cholesky-decomposition. Abusing notation a bit, we’re going to write\n\n\\[\n\\theta = (\\mu, \\Sigma) := (\\mu\\_1, \\dots, \\mu\\_d, L\\_{11}, \\dots, L\\_{1, d}, L\\_{2, 1}, \\dots, L\\_{2, d}, \\dots, L\\_{d, 1}, \\dots, L\\_{d, d}).\n\\]\n\nWith this assumption we finally have a tractable expression for \\(\\widehat{\\mathrm{ELBO}}(q_{\\mu, \\Sigma})\\)! Well, assuming (7) is holds. Since a Gaussian has non-zero probability on the entirety of \\(\\mathbb{R}^d\\), we also require \\(p(z \\mid \\\\{ x_i \\\\}_{i = 1}^n)\\) to have non-zero probability on all of \\(\\mathbb{R}^d\\).\nThough not necessary, we’ll often make a mean-field assumption for the variational posterior \\(q(z)\\), i.e. assume independence between the latent variables. In this case, we’ll write\n\n\\[\n\\theta = (\\mu, \\sigma^2) := (\\mu\\_1, \\dots, \\mu\\_d, \\sigma\\_1^2, \\dots, \\sigma\\_d^2).\n\\]\n\n\nExamples\nAs a (trivial) example we could apply the approach described above to is the following generative model for \\(p(z \\mid \\\\{ x_i \\\\}\\_{i = 1}^n)\\):\n\n\\[\n\\begin{align*}\n    m &\\sim \\mathcal{N}(0, 1) \\\\\n    x\\_i &\\overset{\\text{i.i.d.}}{=} \\mathcal{N}(m, 1), \\quad i = 1, \\dots, n.\n\\end{align*}\n\\]\n\nIn this case \\(z = m\\) and we have the posterior defined \\(p(m \\mid \\\\{ x\\_i \\\\}\\_{i = 1}^n) = p(m) \\prod\\_{i = 1}^n p(x\\_i \\mid m)\\). Then the variational posterior would be\n\n\\[\nq\\_{\\mu, \\sigma} = \\mathcal{N}(\\mu, \\sigma^2), \\quad \\text{where} \\quad \\mu \\in \\mathbb{R}, \\ \\sigma^2 \\in \\mathbb{R}^{ + }.\n\\]\n\nAnd since prior of \\(m\\), \\(\\mathcal{N}(0, 1)\\), has non-zero probability on the entirety of \\(\\mathbb{R}\\), same as \\(q(m)\\), i.e. assumption (7) above holds, everything is fine and life is good.\nBut what about this generative model for \\(p(z \\mid \\\\{ x_i \\\\}_{i = 1}^n)\\):\n\n\\[\n\\begin{align*}\n    s &\\sim \\mathrm{InverseGamma}(2, 3), \\\\\n    m &\\sim \\mathcal{N}(0, s), \\\\\n    x\\_i &\\overset{\\text{i.i.d.}}{=} \\mathcal{N}(m, s), \\quad i = 1, \\dots, n,\n\\end{align*}\n\\]\n\nwith posterior \\(p(s, m \\mid \\\\{ x\\_i \\\\}\\_{i = 1}^n) = p(s) p(m \\mid s) \\prod\\_{i = 1}^n p(x\\_i \\mid s, m)\\) and the mean-field variational posterior \\(q(s, m)\\) will be\n\n\\[\nq\\_{\\mu\\_1, \\mu\\_2, \\sigma\\_1^2, \\sigma\\_2^2}(s, m) = p\\_{\\mathcal{N}(\\mu\\_1, \\sigma\\_1^2)}(s)\\ p\\_{\\mathcal{N}(\\mu\\_2, \\sigma\\_2^2)}(m),\n\\]\n\nwhere we’ve denoted the evaluation of the probability density of a Gaussian as \\(p_{\\mathcal{N}(\\mu, \\sigma^2)}(x)\\).\nObserve that \\(\\mathrm{InverseGamma}(2, 3)\\) has non-zero probability only on \\(\\mathbb{R}^{ + } := (0, \\infty)\\) which is clearly not all of \\(\\mathbb{R}\\) like \\(q(s, m)\\) has, i.e.\n\n\\[\n\\mathrm{supp} \\left( q(s, m) \\right) \\not\\subseteq \\mathrm{supp} \\left( p(z \\mid \\\\{ x\\_i \\\\}\\_{i = 1}^n) \\right).\n\\]\n\nRecall from the definition of the KL-divergence that when this is the case, the KL-divergence isn’t well defined. This gets us to the automatic part of ADVI.\n\n\n“Automatic”? How?\nFor a lot of the standard (continuous) densities \\(p\\) we can actually construct a probability density \\(\\tilde{p}\\) with non-zero probability on all of \\(\\mathbb{R}\\) by transforming the “constrained” probability density \\(p\\) to \\(\\tilde{p}\\). In fact, in these cases this is a one-to-one relationship. As we’ll see, this helps solve the support-issue we’ve been going on and on about.\n\nTransforming densities using change of variables\nIf we want to compute the probability of \\(x\\) taking a value in some set \\(A \\subseteq \\mathrm{supp} \\left( p(x) \\right)\\), we have to integrate \\(p(x)\\) over \\(A\\), i.e.\n\n\\[\n\\mathbb{P}_p(x \\in A) = \\int_A p(x) \\mathrm{d}x.\n\\]\n\nThis means that if we have a differentiable bijection \\(f: \\mathrm{supp} \\left( q(x) \\right) \\to \\mathbb{R}^d\\) with differentiable inverse \\(f^{-1}: \\mathbb{R}^d \\to \\mathrm{supp} \\left( p(x) \\right)\\), we can perform a change of variables\n\n\\[\n\\mathbb{P}\\_p(x \\in A) = \\int\\_{f^{-1}(A)} p \\left(f^{-1}(y) \\right) \\ \\left| \\det \\mathcal{J}\\_{f^{-1}}(y) \\right| \\mathrm{d}y,\n\\]\n\nwhere \\(\\mathcal{J}_{f^{-1}}(x)\\) denotes the jacobian of \\(f^{-1}\\) evaluated at \\(x\\). Observe that this defines a probability distribution\n\n\\[\n\\mathbb{P}\\_{\\tilde{p}}\\left(y \\in f^{-1}(A) \\right) = \\int\\_{f^{-1}(A)} \\tilde{p}(y) \\mathrm{d}y,\n\\]\n\nsince \\(f^{-1}\\left(\\mathrm{supp} (p(x)) \\right) = \\mathbb{R}^d\\) which has probability 1. This probability distribution has density \\(\\tilde{p}(y)\\) with \\(\\mathrm{supp} \\left( \\tilde{p}(y) \\right) = \\mathbb{R}^d\\), defined\n\n\\[\n\\tilde{p}(y) = p \\left( f^{-1}(y) \\right) \\ \\left| \\det \\mathcal{J}\\_{f^{-1}}(y) \\right|\n\\]\n\nor equivalently\n\n\\[\n\\tilde{p} \\left( f(x) \\right) = \\frac{p(x)}{\\big| \\det \\mathcal{J}\\_{f}(x) \\big|}\n\\]\n\ndue to the fact that\n\n\\[\n\\big| \\det \\mathcal{J}\\_{f^{-1}}(y) \\big| = \\big| \\det \\mathcal{J}\\_{f}(x) \\big|^{-1}\n\\]\n\nNote: it’s also necessary that the log-abs-det-jacobian term is non-vanishing. This can for example be accomplished by assuming \\(f\\) to also be elementwise monotonic.\n\n\nBack to VI\nSo why is this is useful? Well, we’re looking to generalize our approach using a normal distribution to cases where the supports don’t match up. How about defining \\(q(z)\\) by\n\n\\[\n\\begin{align*}\n  \\eta &\\sim \\mathcal{N}(\\mu, \\Sigma), \\\\\\\\\n  z &= f^{-1}(\\eta),\n\\end{align*}\n\\]\n\nwhere \\(f^{-1}: \\mathbb{R}^d \\to \\mathrm{supp} \\left( p(z \\mid x) \\right)\\) is a differentiable bijection with differentiable inverse. Then \\(z \\sim q_{\\mu, \\Sigma}(z) \\implies z \\in \\mathrm{supp} \\left( p(z \\mid x) \\right)\\) as we wanted. The resulting variational density is\n\n\\[\nq\\_{\\mu, \\Sigma}(z) = p\\_{\\mathcal{N}(\\mu, \\Sigma)}\\left( f(z) \\right) \\ \\big| \\det \\mathcal{J}\\_{f}(z) \\big|.\n\\]\n\nNote that the way we’ve constructed \\(q(z)\\) here is basically a reverse of the approach we described above. Here we sample from a distribution with support on \\(\\mathbb{R}\\) and transform to \\(\\mathrm{supp} \\left( p(z \\mid x) \\right)\\).\nIf we want to write the ELBO explicitly in terms of \\(\\eta\\) rather than \\(z\\), the first term in the ELBO becomes\n\n\\[\n\\begin{align*}\n  \\mathbb{E}\\_{z \\sim q_{\\mu, \\Sigma}(z)} \\left[ \\log p(x\\_i, z) \\right] &= \\mathbb{E}\\_{\\eta \\sim \\mathcal{N}(\\mu, \\Sigma)} \\Bigg[ \\log \\frac{p\\left(x\\_i, f^{-1}(\\eta) \\right)}{\\big| \\det \\mathcal{J}_{f^{-1}}(\\eta) \\big|} \\Bigg] \\\\\n  &= \\mathbb{E}\\_{\\eta \\sim \\mathcal{N}(\\mu, \\Sigma)} \\left[ \\log p\\left(x\\_i, f^{-1}(\\eta) \\right) \\right] - \\mathbb{E}\\_{\\eta \\sim \\mathcal{N}(\\mu, \\Sigma)} \\left[ \\left| \\det \\mathcal{J}\\_{f^{-1}}(\\eta) \\right| \\right].\n\\end{align*}\n\\]\n\nThe entropy is invariant under change of variables, thus \\(\\mathbb{H} \\left(q\\_{\\mu, \\Sigma}(z)\\right)\\) is simply the entropy of the normal distribution which is known analytically.\nHence, the resulting empirical estimate of the ELBO is\n\n\\[\n\\begin{align*}\n\\widehat{\\mathrm{ELBO}}(q\\_{\\mu, \\Sigma}) &= \\frac{1}{m} \\left( \\sum\\_{k = 1}^m \\sum\\_{i = 1}^n \\left(\\log p\\left(x\\_i, f^{-1}(\\eta_k)\\right) - \\log \\big| \\det \\mathcal{J}\\_{f^{-1}}(\\eta\\_k) \\big| \\right) \\right) + \\mathbb{H} \\left(p\\_{\\mathcal{N}(\\mu, \\Sigma)}(z)\\right) \\\\\n& \\text{where} \\quad z\\_k  \\sim \\mathcal{N}(\\mu, \\Sigma) \\quad \\forall k = 1, \\dots, m\n\\end{align*}.\n\\]\n\nAnd maximizing this wrt. \\(\\mu\\) and \\(\\Sigma\\) is what’s referred to as Automatic Differentiation Variational Inference (ADVI)!\nNow if you want to try it out, check out the tutorial on how to use ADVI in Turing.jl!",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "Variational Inference"
    ]
  },
  {
    "objectID": "tutorials/usage-generated-quantities/index.html",
    "href": "tutorials/usage-generated-quantities/index.html",
    "title": "Generated Quantities",
    "section": "",
    "text": "Often, the most natural parameterization for a model is not the most computationally feasible. Consider the following (efficiently reparametrized) implementation of Neal’s funnel (Neal, 2003):\n\nusing Turing\n\n@model function Neal()\n    # Raw draws\n    y_raw ~ Normal(0, 1)\n    x_raw ~ arraydist([Normal(0, 1) for i in 1:9])\n\n    # Transform:\n    y = 3 * y_raw\n    x = exp.(y ./ 2) .* x_raw\n\n    # Return:\n    return [x; y]\nend\n\nNeal (generic function with 2 methods)\n\n\nIn this case, the random variables exposed in the chain (x_raw, y_raw) are not in a helpful form — what we’re after are the deterministically transformed variables x and y.\nMore generally, there are often quantities in our models that we might be interested in viewing, but which are not explicitly present in our chain.\nWe can generate draws from these variables — in this case, x and y — by adding them as a return statement to the model, and then calling generated_quantities(model, chain). Calling this function outputs an array of values specified in the return statement of the model.\nFor example, in the above reparametrization, we sample from our model:\n\nchain = sample(Neal(), NUTS(), 1000; progress=false)\n\n┌ Info: Found initial step size\n└   ϵ = 3.2\n\n\nChains MCMC chain (1000×22×1 Array{Float64, 3}):\n\nIterations        = 501:1:1500\nNumber of chains  = 1\nSamples per chain = 1000\nWall duration     = 8.37 seconds\nCompute duration  = 8.37 seconds\nparameters        = y_raw, x_raw[1], x_raw[2], x_raw[3], x_raw[4], x_raw[5], x_raw[6], x_raw[7], x_raw[8], x_raw[9]\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n  parameters      mean       std      mcse    ess_bulk   ess_tail      rhat    ⋯\n      Symbol   Float64   Float64   Float64     Float64    Float64   Float64    ⋯\n\n       y_raw    0.0090    1.0429    0.0261   1589.2131   734.0486    0.9992    ⋯\n    x_raw[1]    0.0220    0.9862    0.0272   1310.0540   709.4837    1.0005    ⋯\n    x_raw[2]    0.0218    1.0303    0.0226   2036.8451   620.1185    1.0025    ⋯\n    x_raw[3]    0.0144    1.0252    0.0246   1762.5507   848.7930    0.9992    ⋯\n    x_raw[4]    0.0370    1.0146    0.0314   1025.2368   663.8774    0.9993    ⋯\n    x_raw[5]    0.0150    0.9940    0.0315   1001.9675   786.9313    1.0050    ⋯\n    x_raw[6]   -0.0554    0.9920    0.0264   1392.3110   840.7347    1.0001    ⋯\n    x_raw[7]    0.0562    1.0111    0.0286   1236.8841   836.7368    1.0026    ⋯\n    x_raw[8]    0.0453    1.0384    0.0265   1543.3230   626.4064    0.9993    ⋯\n    x_raw[9]    0.0268    1.0134    0.0281   1305.4884   842.7605    0.9994    ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n       y_raw   -1.9296   -0.6537   -0.0339    0.7163    2.0209\n    x_raw[1]   -1.8772   -0.6848    0.0253    0.6837    1.9105\n    x_raw[2]   -1.9372   -0.7292    0.0202    0.7351    2.0206\n    x_raw[3]   -1.9785   -0.6398    0.0152    0.7066    2.0092\n    x_raw[4]   -1.9647   -0.6239    0.0167    0.7526    1.8950\n    x_raw[5]   -1.9609   -0.6697   -0.0055    0.7161    1.8022\n    x_raw[6]   -1.9823   -0.7141   -0.0911    0.6055    1.9804\n    x_raw[7]   -1.9280   -0.6267    0.0317    0.7304    2.0865\n    x_raw[8]   -1.9211   -0.6728    0.0391    0.7347    2.0704\n    x_raw[9]   -1.9052   -0.6700    0.0414    0.7194    2.0118\n\n\nNotice that only x_raw and y_raw are stored in the chain; x and y are not because they do not appear on the left-hand side of a tilde-statement.\nTo get x and y, we can then call:\n\ngenerated_quantities(Neal(), chain)\n\n1000×1 Matrix{Vector{Float64}}:\n [0.0341355456551992, 0.034310313983359535, -0.017144311391840687, -0.014349527478535759, -0.005296969373792026, 0.005204891955165258, 0.020065184433088686, 0.024750216655683846, -0.014419129461276058, -6.950730195536747]\n [-0.28125954690012106, 0.16614881197627515, -0.21820435112885156, -0.017667019343221468, -0.09453143166112338, 0.07260231579677898, -0.08731433249779874, -0.3243455897635589, 0.3519406803436012, -1.9672076504235332]\n [1.0189564747013353, -1.3679714673424148, 2.5331165430340565, 2.1422950715848854, 3.395914341247566, -1.4052509972410312, 1.1587078999332445, 2.8309937100336056, -1.1137621972357905, 2.493325922915478]\n [0.15026058042381085, 0.4944466340951115, -0.5782695863153551, 0.06555711737623064, -0.1621303405690233, 0.5725749839290925, -0.27961299126460953, -0.9213079187585187, 0.28991356683200875, 0.21070895899327802]\n [-0.05023853535182231, -0.42159430572794654, 0.23645838664200983, -0.843430818703451, 0.05689405497775985, -0.26044177394623846, 0.41553360645650583, 0.657010347404395, -0.42597467352051777, -0.3686918235957378]\n [0.6015449889434765, 0.38321814999559994, 0.23666931287441403, -0.8468854480574284, 0.3473962319711756, -0.38768235340426876, 1.3338516209530704, -0.09878518181375387, -1.0799057024269325, -1.1365681195864203]\n [1.8763417402567582, 0.489154574857355, -1.9101715559934225, -0.09659859672278279, -0.7336878085159853, -0.9404167687100956, -0.6152705098068575, 0.92184924360427, 0.33328696283103393, 0.3678288556326208]\n [14.133068376272728, 6.841398941793942, -17.802080129708802, -8.37473065208861, 4.156564887098981, 9.22050036751895, -15.999069768080899, 3.5524295848627494, 14.107153613123069, 4.394228692762007]\n [-4.172413944426301, -1.6550293693820812, 0.7064514585895855, 1.5978101528661095, 1.8581982626037112, 1.9638125453144895, 0.27307891481769114, 1.1715558214402246, -0.06222464031853473, 1.1572977300234644]\n [0.5059394469701467, 0.2993342616897959, -0.1649368935379115, -0.3002946113077054, -0.23596274564739173, -0.39505564086440853, -0.1159021654111728, -0.22290894874833075, -0.08888274160377087, -2.238420645077082]\n ⋮\n [0.7418851510935615, 0.06991071027015355, -0.9773369229549187, 0.30732622233129875, -1.020385731196063, 1.0111098787179955, 0.8661946792309303, 0.4077278700261228, -0.7424660549636295, -0.08513435804984049]\n [-0.5755944499578303, -0.13499151637529394, 1.3415089157230848, -1.1578338484069537, 1.2403418806035924, -1.024925145492422, -1.1382960174236998, -0.5684985231881569, 1.7877615778262108, 0.5381753245440801]\n [-2.624995048268169, 4.698419973670086, -4.499133960615535, -3.853663472083185, -1.9169664582396309, -2.3291469851032898, -3.1438890410812106, -2.420562005532607, -7.465279192601087, 2.313771026556644]\n [0.3504083067126091, 0.09131285591404749, 0.09732520974812443, 0.36673317721725374, 0.18470464326334116, 0.13931935311105842, -0.1739262063930958, 0.7356081502013767, 0.502660320226359, -2.605965209711232]\n [0.6326159744674712, 0.17471835669875624, 1.3375633457486389, -0.7648088048858827, 0.6942012606016682, -0.9330105898257753, 0.006142457369461634, -1.1124268219085356, -1.0968637587065266, -0.05057773646756014]\n [-0.09466806981027413, -0.09463045885148773, 0.22670086708204526, -0.1669277079664461, 0.1477354531126882, -0.00782409281247869, -0.012716062596668798, -0.18708656288771403, -0.0018581035044693852, -4.269901663904335]\n [9.648863104458357, 27.118888103620975, -1.8653024742675577, 27.92088575721476, -17.07334378244515, -13.804352758966678, 28.960564294039788, 29.314326456008455, 2.4012605161411096, 6.120312181698039]\n [0.08029589163922879, -0.024149775433474532, 0.07883441712299948, 0.0587699158316433, 0.03763762983624468, -0.017604786461825762, 0.00530859139426308, 0.009022094102896333, -0.045318922988396335, -5.231227288652271]\n [0.14644927016165823, -3.1334343914205953, 1.1681362153160533, 0.7587408736871041, 1.4545358416857213, -1.0259876056768547, 1.116885077700733, 2.7034967062680244, -1.9926133032000641, 1.2280301682768626]\n\n\nEach element of this corresponds to an array with the values of x1, x2, ..., x9, y for each posterior sample.\nIn this case, it might be useful to reorganize our output into a matrix for plotting:\n\nreparam_chain = reduce(hcat, generated_quantities(Neal(), chain))'\n\n1000×10 adjoint(::Matrix{Float64}) with eltype Float64:\n  0.0341355   0.0343103   -0.0171443  …   0.0247502   -0.0144191  -6.95073\n -0.28126     0.166149    -0.218204      -0.324346     0.351941   -1.96721\n  1.01896    -1.36797      2.53312        2.83099     -1.11376     2.49333\n  0.150261    0.494447    -0.57827       -0.921308     0.289914    0.210709\n -0.0502385  -0.421594     0.236458       0.65701     -0.425975   -0.368692\n  0.601545    0.383218     0.236669   …  -0.0987852   -1.07991    -1.13657\n  1.87634     0.489155    -1.91017        0.921849     0.333287    0.367829\n 14.1331      6.8414     -17.8021         3.55243     14.1072      4.39423\n -4.17241    -1.65503      0.706451       1.17156     -0.0622246   1.1573\n  0.505939    0.299334    -0.164937      -0.222909    -0.0888827  -2.23842\n  ⋮                                   ⋱                           \n  0.741885    0.0699107   -0.977337       0.407728    -0.742466   -0.0851344\n -0.575594   -0.134992     1.34151       -0.568499     1.78776     0.538175\n -2.625       4.69842     -4.49913       -2.42056     -7.46528     2.31377\n  0.350408    0.0913129    0.0973252      0.735608     0.50266    -2.60597\n  0.632616    0.174718     1.33756    …  -1.11243     -1.09686    -0.0505777\n -0.0946681  -0.0946305    0.226701      -0.187087    -0.0018581  -4.2699\n  9.64886    27.1189      -1.8653        29.3143       2.40126     6.12031\n  0.0802959  -0.0241498    0.0788344      0.00902209  -0.0453189  -5.23123\n  0.146449   -3.13343      1.16814        2.7035      -1.99261     1.22803\n\n\nfrom which we can recover a vector of our samples:\n\nx1_samples = reparam_chain[:, 1]\ny_samples = reparam_chain[:, 10]\n\n1000-element Vector{Float64}:\n -6.950730195536747\n -1.9672076504235332\n  2.493325922915478\n  0.21070895899327802\n -0.3686918235957378\n -1.1365681195864203\n  0.3678288556326208\n  4.394228692762007\n  1.1572977300234644\n -2.238420645077082\n  ⋮\n -0.08513435804984049\n  0.5381753245440801\n  2.313771026556644\n -2.605965209711232\n -0.05057773646756014\n -4.269901663904335\n  6.120312181698039\n -5.231227288652271\n  1.2280301682768626\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Generated Quantities"
    ]
  },
  {
    "objectID": "tutorials/docs-08-using-turing/index.html",
    "href": "tutorials/docs-08-using-turing/index.html",
    "title": "Turing Documentation",
    "section": "",
    "text": "Turing Documentation\nWelcome to the documentation for Turing. Turing is a general-purpose probabilistic programming language for robust, efficient Bayesian inference and decision making. Current features include:\n\nGeneral-purpose probabilistic programming with an intuitive modelling interface;\nRobust, efficient Hamiltonian Monte Carlo (HMC) sampling for differentiable posterior distributions;\nParticle MCMC sampling for complex posterior distributions involving discrete variables and stochastic control flow; and\nGibbs sampling that combines particle MCMC, HMC and random-walk MH (RWMH) etc.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tutorials/13-seasonal-time-series/index.html",
    "href": "tutorials/13-seasonal-time-series/index.html",
    "title": "Bayesian Time Series Analysis",
    "section": "",
    "text": "In time series analysis we are often interested in understanding how various real-life circumstances impact our quantity of interest. These can be, for instance, season, day of week, or time of day. To analyse this it is useful to decompose time series into simpler components (corresponding to relevant circumstances) and infer their relevance. In this tutorial we are going to use Turing for time series analysis and learn about useful ways to decompose time series.\n\nModelling time series\nBefore we start coding, let us talk about what exactly we mean with time series decomposition. In a nutshell, it is a divide-and-conquer approach where we express a time series as a sum or a product of simpler series. For instance, the time series \\(f(t)\\) can be decomposed into a sum of \\(n\\) components\n\\[f(t) = \\sum_{i=1}^n f_i(t),\\]\nor we can decompose \\(g(t)\\) into a product of \\(m\\) components\n\\[g(t) = \\prod_{i=1}^m g_i(t).\\]\nWe refer to this as additive or multiplicative decomposition respectively. This type of decomposition is great since it lets us reason about individual components, which makes encoding prior information and interpreting model predictions very easy. Two common components are trends, which represent the overall change of the time series (often assumed to be linear), and cyclic effects which contribute oscillating effects around the trend. Let us simulate some data with an additive linear trend and oscillating effects.\n\nusing Turing\nusing FillArrays\nusing StatsPlots\n\nusing LinearAlgebra\nusing Random\nusing Statistics\n\nRandom.seed!(12345)\n\ntrue_sin_freq = 2\ntrue_sin_amp = 5\ntrue_cos_freq = 7\ntrue_cos_amp = 2.5\ntmax = 10\nβ_true = 2\nα_true = -1\ntt = 0:0.05:tmax\nf₁(t) = α_true + β_true * t\nf₂(t) = true_sin_amp * sinpi(2 * t * true_sin_freq / tmax)\nf₃(t) = true_cos_amp * cospi(2 * t * true_cos_freq / tmax)\nf(t) = f₁(t) + f₂(t) + f₃(t)\n\nplot(f, tt; label=\"f(t)\", title=\"Observed time series\", legend=:topleft, linewidth=3)\nplot!(\n    [f₁, f₂, f₃],\n    tt;\n    label=[\"f₁(t)\" \"f₂(t)\" \"f₃(t)\"],\n    style=[:dot :dash :dashdot],\n    linewidth=1,\n)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEven though we use simple components, combining them can give rise to fairly complex time series. In this time series, cyclic effects are just added on top of the trend. If we instead multiply the components the cyclic effects cause the series to oscillate between larger and larger values, since they get scaled by the trend.\n\ng(t) = f₁(t) * f₂(t) * f₃(t)\n\nplot(g, tt; label=\"f(t)\", title=\"Observed time series\", legend=:topleft, linewidth=3)\nplot!([f₁, f₂, f₃], tt; label=[\"f₁(t)\" \"f₂(t)\" \"f₃(t)\"], linewidth=1)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnlike \\(f\\), \\(g\\) oscillates around \\(0\\) since it is being multiplied with sines and cosines. To let a multiplicative decomposition oscillate around the trend we could define it as \\(\\tilde{g}(t) = f₁(t) * (1 + f₂(t)) * (1 + f₃(t)),\\) but for convenience we will leave it as is. The inference machinery is the same for both cases.\n\n\nModel fitting\nHaving discussed time series decomposition, let us fit a model to the time series above and recover the true parameters. Before building our model, we standardise the time axis to \\([0, 1]\\) and subtract the max of the time series. This helps convergence while maintaining interpretability and the correct scales for the cyclic components.\n\nσ_true = 0.35\nt = collect(tt[begin:3:end])\nt_min, t_max = extrema(t)\nx = (t .- t_min) ./ (t_max - t_min)\nyf = f.(t) .+ σ_true .* randn(size(t))\nyf_max = maximum(yf)\nyf = yf .- yf_max\n\nscatter(x, yf; title=\"Standardised data\", legend=false)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet us now build our model. We want to assume a linear trend, and cyclic effects. Encoding a linear trend is easy enough, but what about cyclical effects? We will take a scattergun approach, and create multiple cyclical features using both sine and cosine functions and let our inference machinery figure out which to keep. To do this, we define how long a one period should be, and create features in reference to said period. How long a period should be is problem dependent, but as an example let us say it is \\(1\\) year. If we then find evidence for a cyclic effect with a frequency of 2, that would mean a biannual effect. A frequency of 4 would mean quarterly etc. Since we are using synthetic data, we are simply going to let the period be 1, which is the entire length of the time series.\n\nfreqs = 1:10\nnum_freqs = length(freqs)\nperiod = 1\ncyclic_features = [sinpi.(2 .* freqs' .* x ./ period) cospi.(2 .* freqs' .* x ./ period)]\n\nplot_freqs = [1, 3, 5]\nfreq_ptl = plot(\n    cyclic_features[:, plot_freqs];\n    label=permutedims([\"sin(2π$(f)x)\" for f in plot_freqs]),\n    title=\"Cyclical features subset\",\n)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHaving constructed the cyclical features, we can finally build our model. The model we will implement looks like this\n\\[\nf(t) = \\alpha + \\beta_t t + \\sum_{i=1}^F \\beta_{\\sin{},i} \\sin{}(2\\pi f_i t) + \\sum_{i=1}^F \\beta_{\\cos{},i} \\cos{}(2\\pi f_i t),\n\\]\nwith a Gaussian likelihood \\(y \\sim \\mathcal{N}(f(t), \\sigma^2)\\). For convenience we are treating the cyclical feature weights \\(\\beta_{\\sin{},i}\\) and \\(\\beta_{\\cos{},i}\\) the same in code and weight them with \\(\\beta_c\\). And just because it is so easy, we parameterise our model with the operation with which to apply the cyclic effects. This lets us use the exact same code for both additive and multiplicative models. Finally, we plot prior predictive samples to make sure our priors make sense.\n\n@model function decomp_model(t, c, op)\n    α ~ Normal(0, 10)\n    βt ~ Normal(0, 2)\n    βc ~ MvNormal(Zeros(size(c, 2)), I)\n    σ ~ truncated(Normal(0, 0.1); lower=0)\n\n    cyclic = c * βc\n    trend = α .+ βt .* t\n    μ = op(trend, cyclic)\n    y ~ MvNormal(μ, σ^2 * I)\n    return (; trend, cyclic)\nend\n\ny_prior_samples = mapreduce(hcat, 1:100) do _\n    rand(decomp_model(t, cyclic_features, +)).y\nend\nplot(t, y_prior_samples; linewidth=1, alpha=0.5, color=1, label=\"\", title=\"Prior samples\")\nscatter!(t, yf; color=2, label=\"Data\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWith the model specified and with a reasonable prior we can now let Turing decompose the time series for us!\n\nfunction mean_ribbon(samples)\n    qs = quantile(samples)\n    low = qs[:, Symbol(\"2.5%\")]\n    up = qs[:, Symbol(\"97.5%\")]\n    m = mean(samples)[:, :mean]\n    return m, (m - low, up - m)\nend\n\nfunction get_decomposition(model, x, cyclic_features, chain, op)\n    chain_params = Turing.MCMCChains.get_sections(chain, :parameters)\n    return generated_quantities(model(x, cyclic_features, op), chain_params)\nend\n\nfunction plot_fit(x, y, decomp, ymax)\n    trend = mapreduce(x -&gt; x.trend, hcat, decomp)\n    cyclic = mapreduce(x -&gt; x.cyclic, hcat, decomp)\n\n    trend_plt = plot(\n        x,\n        trend .+ ymax;\n        color=1,\n        label=nothing,\n        alpha=0.2,\n        title=\"Trend\",\n        xlabel=\"Time\",\n        ylabel=\"f₁(t)\",\n    )\n    ls = [ones(length(t)) t] \\ y\n    α̂, β̂ = ls[1], ls[2:end]\n    plot!(\n        trend_plt,\n        t,\n        α̂ .+ t .* β̂ .+ ymax;\n        label=\"Least squares trend\",\n        color=5,\n        linewidth=4,\n    )\n\n    scatter!(trend_plt, x, y .+ ymax; label=nothing, color=2, legend=:topleft)\n    cyclic_plt = plot(\n        x,\n        cyclic;\n        color=1,\n        label=nothing,\n        alpha=0.2,\n        title=\"Cyclic effect\",\n        xlabel=\"Time\",\n        ylabel=\"f₂(t)\",\n    )\n    return trend_plt, cyclic_plt\nend\n\nchain = sample(decomp_model(x, cyclic_features, +) | (; y=yf), NUTS(), 2000, progress=false)\nyf_samples = predict(decomp_model(x, cyclic_features, +), chain)\nm, conf = mean_ribbon(yf_samples)\npredictive_plt = plot(\n    t,\n    m .+ yf_max;\n    ribbon=conf,\n    label=\"Posterior density\",\n    title=\"Posterior decomposition\",\n    xlabel=\"Time\",\n    ylabel=\"f(t)\",\n)\nscatter!(predictive_plt, t, yf .+ yf_max; color=2, label=\"Data\", legend=:topleft)\n\ndecomp = get_decomposition(decomp_model, x, cyclic_features, chain, +)\ndecomposed_plt = plot_fit(t, yf, decomp, yf_max)\nplot(predictive_plt, decomposed_plt...; layout=(3, 1), size=(700, 1000))\n\n┌ Info: Found initial step size\n└   ϵ = 0.025\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInference is successful and the posterior beautifully captures the data. We see that the least squares linear fit deviates somewhat from the posterior trend. Since our model takes cyclic effects into account separately, we get a better estimate of the true overall trend than if we would have just fitted a line. But what frequency content did the model identify?\n\nfunction plot_cyclic_features(βsin, βcos)\n    labels = reshape([\"freq = $i\" for i in freqs], 1, :)\n    colors = collect(freqs)'\n    style = reshape([i &lt;= 10 ? :solid : :dash for i in 1:length(labels)], 1, :)\n    sin_features_plt = density(\n        βsin[:, :, 1];\n        title=\"Sine features posterior\",\n        label=labels,\n        ylabel=\"Density\",\n        xlabel=\"Weight\",\n        color=colors,\n        linestyle=style,\n        legend=nothing,\n    )\n    cos_features_plt = density(\n        βcos[:, :, 1];\n        title=\"Cosine features posterior\",\n        ylabel=\"Density\",\n        xlabel=\"Weight\",\n        label=nothing,\n        color=colors,\n        linestyle=style,\n    )\n\n    return seasonal_features_plt = plot(\n        sin_features_plt,\n        cos_features_plt;\n        layout=(2, 1),\n        size=(800, 600),\n        legend=:outerright,\n    )\nend\n\nβc = Array(group(chain, :βc))\nplot_cyclic_features(βc[:, begin:num_freqs, :], βc[:, (num_freqs + 1):end, :])\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlotting the posterior over the cyclic features reveals that the model managed to extract the true frequency content.\nSince we wrote our model to accept a combining operator, we can easily run the same analysis for a multiplicative model.\n\nyg = g.(t) .+ σ_true .* randn(size(t))\n\ny_prior_samples = mapreduce(hcat, 1:100) do _\n    rand(decomp_model(t, cyclic_features, .*)).y\nend\nplot(t, y_prior_samples; linewidth=1, alpha=0.5, color=1, label=\"\", title=\"Prior samples\")\nscatter!(t, yf; color=2, label=\"Data\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nchain = sample(decomp_model(x, cyclic_features, .*) | (; y=yg), NUTS(), 2000, progress=false)\nyg_samples = predict(decomp_model(x, cyclic_features, .*), chain)\nm, conf = mean_ribbon(yg_samples)\npredictive_plt = plot(\n    t,\n    m;\n    ribbon=conf,\n    label=\"Posterior density\",\n    title=\"Posterior decomposition\",\n    xlabel=\"Time\",\n    ylabel=\"g(t)\",\n)\nscatter!(predictive_plt, t, yg; color=2, label=\"Data\", legend=:topleft)\n\ndecomp = get_decomposition(decomp_model, x, cyclic_features, chain, .*)\ndecomposed_plt = plot_fit(t, yg, decomp, 0)\nplot(predictive_plt, decomposed_plt...; layout=(3, 1), size=(700, 1000))\n\n┌ Info: Found initial step size\n└   ϵ = 0.0125\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe model fits! What about the infered cyclic components?\n\nβc = Array(group(chain, :βc))\nplot_cyclic_features(βc[:, begin:num_freqs, :], βc[:, (num_freqs + 1):end, :])\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhile multiplicative model fits to the data, it does not recover the true parameters for this dataset.\n\n\nWrapping up\nIn this tutorial we have seen how to implement and fit time series models using additive and multiplicative decomposition. We also saw how to visualise the model fit, and how to interpret learned cyclical components.\n\n\n\n\n Back to top",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Bayesian Time Series Analysis"
    ]
  },
  {
    "objectID": "tutorials/docs-12-using-turing-guide/index.html",
    "href": "tutorials/docs-12-using-turing-guide/index.html",
    "title": "Core Functionality",
    "section": "",
    "text": "This article provides an overview of the core functionality in Turing.jl, which are likely to be used across a wide range of models.",
    "crumbs": [
      "Get Started",
      "Users",
      "Core Functionality"
    ]
  },
  {
    "objectID": "tutorials/docs-12-using-turing-guide/index.html#basics",
    "href": "tutorials/docs-12-using-turing-guide/index.html#basics",
    "title": "Core Functionality",
    "section": "Basics",
    "text": "Basics\n\nIntroduction\nA probabilistic program is Julia code wrapped in a @model macro. It can use arbitrary Julia code, but to ensure correctness of inference it should not have external effects or modify global state. Stack-allocated variables are safe, but mutable heap-allocated objects may lead to subtle bugs when using task copying. By default Libtask deepcopies Array and Dict objects when copying task to avoid bugs with data stored in mutable structure in Turing models.\nTo specify distributions of random variables, Turing programs should use the ~ notation:\nx ~ distr where x is a symbol and distr is a distribution. If x is undefined in the model function, inside the probabilistic program, this puts a random variable named x, distributed according to distr, in the current scope. distr can be a value of any type that implements rand(distr), which samples a value from the distribution distr. If x is defined, this is used for conditioning in a style similar to Anglican (another PPL). In this case, x is an observed value, assumed to have been drawn from the distribution distr. The likelihood is computed using logpdf(distr,y). The observe statements should be arranged so that every possible run traverses all of them in exactly the same order. This is equivalent to demanding that they are not placed inside stochastic control flow.\nAvailable inference methods include Importance Sampling (IS), Sequential Monte Carlo (SMC), Particle Gibbs (PG), Hamiltonian Monte Carlo (HMC), Hamiltonian Monte Carlo with Dual Averaging (HMCDA) and The No-U-Turn Sampler (NUTS).\n\n\nSimple Gaussian Demo\nBelow is a simple Gaussian demo illustrate the basic usage of Turing.jl.\n\n# Import packages.\nusing Turing\nusing StatsPlots\n\n# Define a simple Normal model with unknown mean and variance.\n@model function gdemo(x, y)\n    s² ~ InverseGamma(2, 3)\n    m ~ Normal(0, sqrt(s²))\n    x ~ Normal(m, sqrt(s²))\n    return y ~ Normal(m, sqrt(s²))\nend\n\ngdemo (generic function with 2 methods)\n\n\nNote: As a sanity check, the prior expectation of s² is mean(InverseGamma(2, 3)) = 3/(2 - 1) = 3 and the prior expectation of m is 0. This can be easily checked using Prior:\n\nsetprogress!(false)\n\n\np1 = sample(gdemo(missing, missing), Prior(), 100000)\n\nChains MCMC chain (100000×5×1 Array{Float64, 3}):\n\nIterations        = 1:1:100000\nNumber of chains  = 1\nSamples per chain = 100000\nWall duration     = 1.66 seconds\nCompute duration  = 1.66 seconds\nparameters        = s², m, x, y\ninternals         = lp\n\nSummary Statistics\n  parameters      mean       std      mcse     ess_bulk     ess_tail      rhat ⋯\n      Symbol   Float64   Float64   Float64      Float64      Float64   Float64 ⋯\n\n          s²    3.0080    6.3572    0.0201   99659.2849   99449.5378    1.0000 ⋯\n           m    0.0008    1.7405    0.0055   99794.5860   99929.9059    1.0000 ⋯\n           x   -0.0072    2.4453    0.0078   99501.7924   99293.0252    1.0000 ⋯\n           y    0.0149    2.4678    0.0079   98950.5727   99210.4918    1.0000 ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n          s²    0.5390    1.1071    1.7822    3.1201   12.6268\n           m   -3.3914   -0.9013    0.0023    0.9028    3.4123\n           x   -4.8438   -1.2845    0.0029    1.2865    4.7559\n           y   -4.8226   -1.2662    0.0188    1.3003    4.8271\n\n\nWe can perform inference by using the sample function, the first argument of which is our probabilistic program and the second of which is a sampler. More information on each sampler is located in the API.\n\n#  Run sampler, collect results.\nc1 = sample(gdemo(1.5, 2), SMC(), 1000)\nc2 = sample(gdemo(1.5, 2), PG(10), 1000)\nc3 = sample(gdemo(1.5, 2), HMC(0.1, 5), 1000)\nc4 = sample(gdemo(1.5, 2), Gibbs(PG(10, :m), HMC(0.1, 5, :s²)), 1000)\nc5 = sample(gdemo(1.5, 2), HMCDA(0.15, 0.65), 1000)\nc6 = sample(gdemo(1.5, 2), NUTS(0.65), 1000)\n\n┌ Info: Found initial step size\n└   ϵ = 0.8\n┌ Info: Found initial step size\n└   ϵ = 1.6\n\n\nChains MCMC chain (1000×14×1 Array{Float64, 3}):\n\nIterations        = 501:1:1500\nNumber of chains  = 1\nSamples per chain = 1000\nWall duration     = 2.03 seconds\nCompute duration  = 2.03 seconds\nparameters        = s², m\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n          s²    1.9591    1.5069    0.0752   471.3656   496.2385    0.9995     ⋯\n           m    1.1550    0.7746    0.0316   602.9070   518.8840    0.9995     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n          s²    0.6120    1.0513    1.5563    2.2991    6.2317\n           m   -0.3588    0.7218    1.1452    1.6305    2.6644\n\n\nThe MCMCChains module (which is re-exported by Turing) provides plotting tools for the Chain objects returned by a sample function. See the MCMCChains repository for more information on the suite of tools available for diagnosing MCMC chains.\n\n# Summarise results\ndescribe(c3)\n\n# Plot results\nplot(c3)\nsavefig(\"gdemo-plot.png\")\n\nThe arguments for each sampler are:\n\nSMC: number of particles.\nPG: number of particles, number of iterations.\nHMC: leapfrog step size, leapfrog step numbers.\nGibbs: component sampler 1, component sampler 2, …\nHMCDA: total leapfrog length, target accept ratio.\nNUTS: number of adaptation steps (optional), target accept ratio.\n\nFor detailed information on the samplers, please review Turing.jl’s API documentation.\n\n\nModelling Syntax Explained\nUsing this syntax, a probabilistic model is defined in Turing. The model function generated by Turing can then be used to condition the model onto data. Subsequently, the sample function can be used to generate samples from the posterior distribution.\nIn the following example, the defined model is conditioned to the data (arg1 = 1, arg2 = 2) by passing (1, 2) to the model function.\n\n@model function model_name(arg_1, arg_2)\n    return ...\nend\n\nThe conditioned model can then be passed onto the sample function to run posterior inference.\n\nmodel_func = model_name(1, 2)\nchn = sample(model_func, HMC(..)) # Perform inference by sampling using HMC.\n\nThe returned chain contains samples of the variables in the model.\n\nvar_1 = mean(chn[:var_1]) # Taking the mean of a variable named var_1.\n\nThe key (:var_1) can be a Symbol or a String. For example, to fetch x[1], one can use chn[Symbol(\"x[1]\")] or chn[\"x[1]\"]. If you want to retrieve all parameters associated with a specific symbol, you can use group. As an example, if you have the parameters \"x[1]\", \"x[2]\", and \"x[3]\", calling group(chn, :x) or group(chn, \"x\") will return a new chain with only \"x[1]\", \"x[2]\", and \"x[3]\".\nTuring does not have a declarative form. More generally, the order in which you place the lines of a @model macro matters. For example, the following example works:\n\n# Define a simple Normal model with unknown mean and variance.\n@model function model_function(y)\n    s ~ Poisson(1)\n    y ~ Normal(s, 1)\n    return y\nend\n\nsample(model_function(10), SMC(), 100)\n\nChains MCMC chain (100×3×1 Array{Float64, 3}):\n\nLog evidence      = -23.51213405819592\nIterations        = 1:1:100\nNumber of chains  = 1\nSamples per chain = 100\nWall duration     = 2.0 seconds\nCompute duration  = 2.0 seconds\nparameters        = s\ninternals         = lp, weight\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n           s    3.9900    0.1000    0.0100   100.0801        NaN    1.0000     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n           s    4.0000    4.0000    4.0000    4.0000    4.0000\n\n\nBut if we switch the s ~ Poisson(1) and y ~ Normal(s, 1) lines, the model will no longer sample correctly:\n\n# Define a simple Normal model with unknown mean and variance.\n@model function model_function(y)\n    y ~ Normal(s, 1)\n    s ~ Poisson(1)\n    return y\nend\n\nsample(model_function(10), SMC(), 100)\n\n\n\nSampling Multiple Chains\nTuring supports distributed and threaded parallel sampling. To do so, call sample(model, sampler, parallel_type, n, n_chains), where parallel_type can be either MCMCThreads() or MCMCDistributed() for thread and parallel sampling, respectively.\nHaving multiple chains in the same object is valuable for evaluating convergence. Some diagnostic functions like gelmandiag require multiple chains.\nIf you do not want parallelism or are on an older version Julia, you can sample multiple chains with the mapreduce function:\n\n# Replace num_chains below with however many chains you wish to sample.\nchains = mapreduce(c -&gt; sample(model_fun, sampler, 1000), chainscat, 1:num_chains)\n\nThe chains variable now contains a Chains object which can be indexed by chain. To pull out the first chain from the chains object, use chains[:,:,1]. The method is the same if you use either of the below parallel sampling methods.\n\nMultithreaded sampling\nIf you wish to perform multithreaded sampling and are running Julia 1.3 or greater, you can call sample with the following signature:\n\nusing Turing\n\n@model function gdemo(x)\n    s² ~ InverseGamma(2, 3)\n    m ~ Normal(0, sqrt(s²))\n\n    for i in eachindex(x)\n        x[i] ~ Normal(m, sqrt(s²))\n    end\nend\n\nmodel = gdemo([1.5, 2.0])\n\n# Sample four chains using multiple threads, each with 1000 samples.\nsample(model, NUTS(), MCMCThreads(), 1000, 4)\n\nBe aware that Turing cannot add threads for you – you must have started your Julia instance with multiple threads to experience any kind of parallelism. See the Julia documentation for details on how to achieve this.\n\n\nDistributed sampling\nTo perform distributed sampling (using multiple processes), you must first import Distributed.\nProcess parallel sampling can be done like so:\n\n# Load Distributed to add processes and the @everywhere macro.\nusing Distributed\n\n# Load Turing.\nusing Turing\n\n# Add four processes to use for sampling.\naddprocs(4; exeflags=\"--project=$(Base.active_project())\")\n\n# Initialize everything on all the processes.\n# Note: Make sure to do this after you've already loaded Turing,\n#       so each process does not have to precompile.\n#       Parallel sampling may fail silently if you do not do this.\n@everywhere using Turing\n\n# Define a model on all processes.\n@everywhere @model function gdemo(x)\n    s² ~ InverseGamma(2, 3)\n    m ~ Normal(0, sqrt(s²))\n\n    for i in eachindex(x)\n        x[i] ~ Normal(m, sqrt(s²))\n    end\nend\n\n# Declare the model instance everywhere.\n@everywhere model = gdemo([1.5, 2.0])\n\n# Sample four chains using multiple processes, each with 1000 samples.\nsample(model, NUTS(), MCMCDistributed(), 1000, 4)\n\n\n\n\nSampling from an Unconditional Distribution (The Prior)\nTuring allows you to sample from a declared model’s prior. If you wish to draw a chain from the prior to inspect your prior distributions, you can simply run\n\nchain = sample(model, Prior(), n_samples)\n\nYou can also run your model (as if it were a function) from the prior distribution, by calling the model without specifying inputs or a sampler. In the below example, we specify a gdemo model which returns two variables, x and y. The model includes x and y as arguments, but calling the function without passing in x or y means that Turing’s compiler will assume they are missing values to draw from the relevant distribution. The return statement is necessary to retrieve the sampled x and y values. Assign the function with missing inputs to a variable, and Turing will produce a sample from the prior distribution.\n\n@model function gdemo(x, y)\n    s² ~ InverseGamma(2, 3)\n    m ~ Normal(0, sqrt(s²))\n    x ~ Normal(m, sqrt(s²))\n    y ~ Normal(m, sqrt(s²))\n    return x, y\nend\n\ngdemo (generic function with 2 methods)\n\n\nAssign the function with missing inputs to a variable, and Turing will produce a sample from the prior distribution.\n\n# Samples from p(x,y)\ng_prior_sample = gdemo(missing, missing)\ng_prior_sample()\n\n(-3.2067338223702917, -1.838365036604499)\n\n\n\n\nSampling from a Conditional Distribution (The Posterior)\n\nTreating observations as random variables\nInputs to the model that have a value missing are treated as parameters, aka random variables, to be estimated/sampled. This can be useful if you want to simulate draws for that parameter, or if you are sampling from a conditional distribution. Turing supports the following syntax:\n\n@model function gdemo(x, ::Type{T}=Float64) where {T}\n    if x === missing\n        # Initialize `x` if missing\n        x = Vector{T}(undef, 2)\n    end\n    s² ~ InverseGamma(2, 3)\n    m ~ Normal(0, sqrt(s²))\n    for i in eachindex(x)\n        x[i] ~ Normal(m, sqrt(s²))\n    end\nend\n\n# Construct a model with x = missing\nmodel = gdemo(missing)\nc = sample(model, HMC(0.01, 5), 500)\n\nChains MCMC chain (500×14×1 Array{Float64, 3}):\n\nIterations        = 1:1:500\nNumber of chains  = 1\nSamples per chain = 500\nWall duration     = 3.53 seconds\nCompute duration  = 3.53 seconds\nparameters        = s², m, x[1], x[2]\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n          s²    1.7631    0.4477    0.1440     9.5492    15.3035    0.9997     ⋯\n           m   -0.4424    0.5068    0.4415     1.3833    10.8708    2.0250     ⋯\n        x[1]   -1.4531    0.3861    0.2923     1.8106    15.3568    1.5886     ⋯\n        x[2]   -0.9446    0.4328    0.4073     1.3514    17.8105    2.1202     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n          s²    1.0095    1.4306    1.7250    2.0433    2.8291\n           m   -1.3258   -0.7928   -0.5106    0.0115    0.5285\n        x[1]   -2.1396   -1.7446   -1.4190   -1.1771   -0.7847\n        x[2]   -1.5795   -1.3598   -0.9659   -0.5728   -0.1827\n\n\nNote the need to initialize x when missing since we are iterating over its elements later in the model. The generated values for x can be extracted from the Chains object using c[:x].\nTuring also supports mixed missing and non-missing values in x, where the missing ones will be treated as random variables to be sampled while the others get treated as observations. For example:\n\n@model function gdemo(x)\n    s² ~ InverseGamma(2, 3)\n    m ~ Normal(0, sqrt(s²))\n    for i in eachindex(x)\n        x[i] ~ Normal(m, sqrt(s²))\n    end\nend\n\n# x[1] is a parameter, but x[2] is an observation\nmodel = gdemo([missing, 2.4])\nc = sample(model, HMC(0.01, 5), 500)\n\nChains MCMC chain (500×13×1 Array{Float64, 3}):\n\nIterations        = 1:1:500\nNumber of chains  = 1\nSamples per chain = 500\nWall duration     = 2.26 seconds\nCompute duration  = 2.26 seconds\nparameters        = s², m, x[1]\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n          s²    2.6690    0.4777    0.1323    15.1071    41.7224    1.0093     ⋯\n           m   -0.8297    0.3680    0.3164     1.5109    36.2755    1.8238     ⋯\n        x[1]   -1.6080    0.2480    0.1364     3.4562    20.6287    1.2548     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n          s²    1.9665    2.2709    2.5678    3.0719    3.5798\n           m   -1.4535   -1.1510   -0.8172   -0.4876   -0.2483\n        x[1]   -2.1122   -1.7453   -1.5884   -1.4174   -1.1932\n\n\n\n\nDefault Values\nArguments to Turing models can have default values much like how default values work in normal Julia functions. For instance, the following will assign missing to x and treat it as a random variable. If the default value is not missing, x will be assigned that value and will be treated as an observation instead.\n\nusing Turing\n\n@model function generative(x=missing, ::Type{T}=Float64) where {T&lt;:Real}\n    if x === missing\n        # Initialize x when missing\n        x = Vector{T}(undef, 10)\n    end\n    s² ~ InverseGamma(2, 3)\n    m ~ Normal(0, sqrt(s²))\n    for i in 1:length(x)\n        x[i] ~ Normal(m, sqrt(s²))\n    end\n    return s², m\nend\n\nm = generative()\nchain = sample(m, HMC(0.01, 5), 1000)\n\nChains MCMC chain (1000×22×1 Array{Float64, 3}):\n\nIterations        = 1:1:1000\nNumber of chains  = 1\nSamples per chain = 1000\nWall duration     = 2.99 seconds\nCompute duration  = 2.99 seconds\nparameters        = s², m, x[1], x[2], x[3], x[4], x[5], x[6], x[7], x[8], x[9], x[10]\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n          s²    1.3525    0.4592    0.1489     9.8806    40.1934    1.0549     ⋯\n           m   -0.0843    0.3244    0.1905     3.0637    27.6218    1.7112     ⋯\n        x[1]   -0.8326    0.9174    0.5974     2.6225    22.9118    2.0637     ⋯\n        x[2]   -2.0021    0.3663    0.1279     7.7189    23.3440    1.0774     ⋯\n        x[3]    1.1614    0.5656    0.3407     2.9109    19.1933    1.6565     ⋯\n        x[4]    0.8566    0.8813    0.5103     3.1366    12.8201    1.4908     ⋯\n        x[5]   -0.6514    0.5014    0.2412     5.2768    12.6487    1.1924     ⋯\n        x[6]   -1.8905    0.5092    0.2214     6.5294    20.3893    1.1391     ⋯\n        x[7]   -0.4863    0.4464    0.1494     8.4149    12.8359    1.0591     ⋯\n        x[8]    1.0387    0.4892    0.2571     4.1486    12.4603    1.2363     ⋯\n        x[9]    0.1673    0.5893    0.3777     2.7098    21.0767    1.9211     ⋯\n       x[10]    0.0803    0.4017    0.2137     3.8794    20.3032    1.3688     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n          s²    0.6842    1.0136    1.2673    1.5762    2.4087\n           m   -0.6224   -0.3350   -0.0966    0.2020    0.4955\n        x[1]   -2.4865   -1.5574   -0.7575    0.0687    0.3802\n        x[2]   -2.6119   -2.2615   -2.0544   -1.7536   -1.2237\n        x[3]    0.0237    0.7789    1.0705    1.6804    2.1495\n        x[4]   -0.5792    0.1854    0.8827    1.1925    2.7056\n        x[5]   -1.6853   -0.9342   -0.5443   -0.2760    0.0980\n        x[6]   -2.7094   -2.2234   -1.9289   -1.7079   -0.7541\n        x[7]   -1.0744   -0.8057   -0.6088   -0.2491    0.6535\n        x[8]    0.0498    0.6784    1.0007    1.4858    1.8356\n        x[9]   -0.8040   -0.3421    0.2401    0.6792    1.1264\n       x[10]   -0.5890   -0.2739    0.1455    0.3681    0.9138\n\n\n\n\nAccess Values inside Chain\nYou can access the values inside a chain several ways:\n\nTurn them into a DataFrame object\nUse their raw AxisArray form\nCreate a three-dimensional Array object\n\nFor example, let c be a Chain:\n\nDataFrame(c) converts c to a DataFrame,\nc.value retrieves the values inside c as an AxisArray, and\nc.value.data retrieves the values inside c as a 3D Array.\n\n\n\nVariable Types and Type Parameters\nThe element type of a vector (or matrix) of random variables should match the eltype of its prior distribution, &lt;: Integer for discrete distributions and &lt;: AbstractFloat for continuous distributions. Moreover, if the continuous random variable is to be sampled using a Hamiltonian sampler, the vector’s element type needs to either be:\n\nReal to enable auto-differentiation through the model which uses special number types that are sub-types of Real, or\nSome type parameter T defined in the model header using the type parameter syntax, e.g. function gdemo(x, ::Type{T} = Float64) where {T}.\n\nSimilarly, when using a particle sampler, the Julia variable used should either be:\n\nAn Array, or\nAn instance of some type parameter T defined in the model header using the type parameter syntax, e.g. function gdemo(x, ::Type{T} = Vector{Float64}) where {T}.\n\n\n\n\nQuerying Probabilities from Model or Chain\nTuring offers three functions: loglikelihood, logprior, and logjoint to query the log-likelihood, log-prior, and log-joint probabilities of a model, respectively.\nLet’s look at a simple model called gdemo:\n\n@model function gdemo0()\n    s ~ InverseGamma(2, 3)\n    m ~ Normal(0, sqrt(s))\n    return x ~ Normal(m, sqrt(s))\nend\n\ngdemo0 (generic function with 2 methods)\n\n\nIf we observe x to be 1.0, we can condition the model on this datum using the condition syntax:\n\nmodel = gdemo0() | (x=1.0,)\n\nDynamicPPL.Model{typeof(gdemo0), (), (), (), Tuple{}, Tuple{}, DynamicPPL.ConditionContext{@NamedTuple{x::Float64}, DynamicPPL.DefaultContext}}(Main.Notebook.gdemo0, NamedTuple(), NamedTuple(), ConditionContext((x = 1.0,), DynamicPPL.DefaultContext()))\n\n\nNow, let’s compute the log-likelihood of the observation given specific values of the model parameters, s and m:\n\nloglikelihood(model, (s=1.0, m=1.0))\n\n-0.9189385332046728\n\n\nWe can easily verify that value in this case:\n\nlogpdf(Normal(1.0, 1.0), 1.0)\n\n-0.9189385332046728\n\n\nWe can also compute the log-prior probability of the model for the same values of s and m:\n\nlogprior(model, (s=1.0, m=1.0))\n\n-2.221713955868453\n\n\n\nlogpdf(InverseGamma(2, 3), 1.0) + logpdf(Normal(0, sqrt(1.0)), 1.0)\n\n-2.221713955868453\n\n\nFinally, we can compute the log-joint probability of the model parameters and data:\n\nlogjoint(model, (s=1.0, m=1.0))\n\n-3.1406524890731258\n\n\n\nlogpdf(Normal(1.0, 1.0), 1.0) +\nlogpdf(InverseGamma(2, 3), 1.0) +\nlogpdf(Normal(0, sqrt(1.0)), 1.0)\n\n-3.1406524890731258\n\n\nQuerying with Chains object is easy as well:\n\nchn = sample(model, Prior(), 10)\n\nChains MCMC chain (10×3×1 Array{Float64, 3}):\n\nIterations        = 1:1:10\nNumber of chains  = 1\nSamples per chain = 10\nWall duration     = 0.02 seconds\nCompute duration  = 0.02 seconds\nparameters        = s, m\ninternals         = lp\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n           s    1.8983    1.9932    0.6303    10.0000    10.0000    1.0093     ⋯\n           m   -0.3517    1.7482    0.5528    10.0000    10.0000    0.9207     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n           s    0.7136    0.9821    1.3358    1.4380    6.2939\n           m   -3.8135   -0.8707   -0.0089    0.3356    1.7022\n\n\n\nloglikelihood(model, chn)\n\n10×1 Matrix{Float64}:\n -2.6342961988067994\n -1.8162341327332625\n -1.643830840418269\n -1.4007984552481865\n -1.0402606195241884\n -1.3070066783491618\n -4.061950593430905\n -2.506529608844854\n -1.3754754114430519\n -1.278715928377588\n\n\n\n\nMaximum likelihood and maximum a posterior estimates\nTuring also has functions for estimating the maximum aposteriori and maximum likelihood parameters of a model. This can be done with\n\nmle_estimate = maximum_likelihood(model)\nmap_estimate = maximum_a_posteriori(model)\n\nModeResult with maximized lp of -2.81\n[0.8125000000025786, 0.4999999999904795]\n\n\nFor more details see the mode estimation page.",
    "crumbs": [
      "Get Started",
      "Users",
      "Core Functionality"
    ]
  },
  {
    "objectID": "tutorials/docs-12-using-turing-guide/index.html#beyond-the-basics",
    "href": "tutorials/docs-12-using-turing-guide/index.html#beyond-the-basics",
    "title": "Core Functionality",
    "section": "Beyond the Basics",
    "text": "Beyond the Basics\n\nCompositional Sampling Using Gibbs\nTuring.jl provides a Gibbs interface to combine different samplers. For example, one can combine an HMC sampler with a PG sampler to run inference for different parameters in a single model as below.\n\n@model function simple_choice(xs)\n    p ~ Beta(2, 2)\n    z ~ Bernoulli(p)\n    for i in 1:length(xs)\n        if z == 1\n            xs[i] ~ Normal(0, 1)\n        else\n            xs[i] ~ Normal(2, 1)\n        end\n    end\nend\n\nsimple_choice_f = simple_choice([1.5, 2.0, 0.3])\n\nchn = sample(simple_choice_f, Gibbs(HMC(0.2, 3, :p), PG(20, :z)), 1000)\n\nChains MCMC chain (1000×3×1 Array{Float64, 3}):\n\nIterations        = 1:1:1000\nNumber of chains  = 1\nSamples per chain = 1000\nWall duration     = 13.46 seconds\nCompute duration  = 13.46 seconds\nparameters        = p, z\ninternals         = lp\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n           p    0.4141    0.2014    0.0204    91.6163   118.8508    1.0129     ⋯\n           z    0.1390    0.3461    0.0161   459.7041        NaN    1.0051     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n           p    0.0706    0.2620    0.3984    0.5574    0.8112\n           z    0.0000    0.0000    0.0000    0.0000    1.0000\n\n\nThe Gibbs sampler can be used to specify unique automatic differentiation backends for different variable spaces. Please see the Automatic Differentiation article for more.\nFor more details of compositional sampling in Turing.jl, please check the corresponding paper.\n\n\nWorking with filldist and arraydist\nTuring provides filldist(dist::Distribution, n::Int) and arraydist(dists::AbstractVector{&lt;:Distribution}) as a simplified interface to construct product distributions, e.g., to model a set of variables that share the same structure but vary by group.\n\nConstructing product distributions with filldist\nThe function filldist provides a general interface to construct product distributions over distributions of the same type and parameterisation. Note that, in contrast to the product distribution interface provided by Distributions.jl (Product), filldist supports product distributions over univariate or multivariate distributions.\nExample usage:\n\n@model function demo(x, g)\n    k = length(unique(g))\n    a ~ filldist(Exponential(), k) # = Product(fill(Exponential(), k))\n    mu = a[g]\n    return x .~ Normal.(mu)\nend\n\ndemo (generic function with 2 methods)\n\n\n\n\nConstructing product distributions with arraydist\nThe function arraydist provides a general interface to construct product distributions over distributions of varying type and parameterisation. Note that in contrast to the product distribution interface provided by Distributions.jl (Product), arraydist supports product distributions over univariate or multivariate distributions.\nExample usage:\n\n@model function demo(x, g)\n    k = length(unique(g))\n    a ~ arraydist([Exponential(i) for i in 1:k])\n    mu = a[g]\n    return x .~ Normal.(mu)\nend\n\ndemo (generic function with 2 methods)\n\n\n\n\n\nWorking with MCMCChains.jl\nTuring.jl wraps its samples using MCMCChains.Chain so that all the functions working for MCMCChains.Chain can be re-used in Turing.jl. Two typical functions are MCMCChains.describe and MCMCChains.plot, which can be used as follows for an obtained chain chn. For more information on MCMCChains, please see the GitHub repository.\n\ndescribe(chn) # Lists statistics of the samples.\nplot(chn) # Plots statistics of the samples.\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere are numerous functions in addition to describe and plot in the MCMCChains package, such as those used in convergence diagnostics. For more information on the package, please see the GitHub repository.\n\n\nChanging Default Settings\nSome of Turing.jl’s default settings can be changed for better usage.\n\nAD Chunk Size\nForwardDiff (Turing’s default AD backend) uses forward-mode chunk-wise AD. The chunk size can be set manually by AutoForwardDiff(;chunksize=new_chunk_size).\n\n\nAD Backend\nTuring supports four automatic differentiation (AD) packages in the back end during sampling. The default AD backend is ForwardDiff for forward-mode AD. Three reverse-mode AD backends are also supported, namely Tracker, Zygote and ReverseDiff. Zygote and ReverseDiff are supported optionally if explicitly loaded by the user with using Zygote or using ReverseDiff next to using Turing.\nFor more information on Turing’s automatic differentiation backend, please see the Automatic Differentiation article.\n\n\nProgress Logging\nTuring.jl uses ProgressLogging.jl to log the sampling progress. Progress logging is enabled as default but might slow down inference. It can be turned on or off by setting the keyword argument progress of sample to true or false. Moreover, you can enable or disable progress logging globally by calling setprogress!(true) or setprogress!(false), respectively.\nTuring uses heuristics to select an appropriate visualization backend. If you use Jupyter notebooks, the default backend is ConsoleProgressMonitor.jl. In all other cases, progress logs are displayed with TerminalLoggers.jl. Alternatively, if you provide a custom visualization backend, Turing uses it instead of the default backend.",
    "crumbs": [
      "Get Started",
      "Users",
      "Core Functionality"
    ]
  },
  {
    "objectID": "tutorials/11-probabilistic-pca/index.html",
    "href": "tutorials/11-probabilistic-pca/index.html",
    "title": "Probabilistic Principal Component Analysis (p-PCA)",
    "section": "",
    "text": "Principal component analysis (PCA) is a fundamental technique to analyse and visualise data. It is an unsupervised learning method mainly used for dimensionality reduction.\nFor example, we have a data matrix \\(\\mathbf{X} \\in \\mathbb{R}^{N \\times D}\\), and we would like to extract \\(k \\ll D\\) principal components which captures most of the information from the original matrix. The goal is to understand \\(\\mathbf{X}\\) through a lower dimensional subspace (e.g. two-dimensional subspace for visualisation convenience) spanned by the principal components.\nIn order to project the original data matrix into low dimensions, we need to find the principal directions where most of the variations of \\(\\mathbf{X}\\) lie in. Traditionally, this is implemented via singular value decomposition (SVD) which provides a robust and accurate computational framework for decomposing matrix into products of rotation-scaling-rotation matrices, particularly for large datasets(see an illustration here):\n\\[\n\\mathbf{X}_{N \\times D} =  \\mathbf{U}_{N \\times r} \\times \\boldsymbol{\\Sigma}_{r \\times r}  \\times  \\mathbf{V}^T_{r \\times D}\n\\]\nwhere \\(\\Sigma_{r \\times r}\\) contains only \\(r := \\operatorname{rank} \\mathbf{X} \\leq \\min\\{N,D\\}\\) non-zero singular values of \\(\\mathbf{X}\\). If we pad \\(\\Sigma\\) with zeros and add arbitrary orthonormal columns to \\(\\mathbf{U}\\) and \\(\\mathbf{V}\\), we obtain the more compact form:1\n\\[\n\\mathbf{X}_{N \\times D} = \\mathbf{U}_{N \\times N} \\mathbf{\\Sigma}_{N \\times D} \\mathbf{V}_{D \\times D}^T\n\\]\nwhere \\(\\mathbf{U}\\) and \\(\\mathbf{V}\\) are unitary matrices (i.e. with orthonormal columns). Such a decomposition always exists for any matrix. Columns of \\(\\mathbf{V}\\) are the principal directions/axes. The percentage of variations explained can be calculated using the ratios of singular values.2\nHere we take a probabilistic perspective. For more details and a mathematical derivation, we recommend Bishop’s textbook (Christopher M. Bishop, Pattern Recognition and Machine Learning, 2006). The idea of proabilistic PCA is to find a latent variable \\(z\\) that can be used to describe the hidden structure in a dataset.3 Consider a data set \\(\\mathbf{X}_{D \\times N}=\\{x_i\\}\\) with \\(i=1,2,...,N\\) data points, where each data point \\(x_i\\) is \\(D\\)-dimensional (i.e. \\(x_i \\in \\mathcal{R}^D\\)). Note that, here we use the flipped version of the data matrix. We aim to represent the original \\(n\\) dimensional vector using a lower dimensional a latent variable \\(z_i \\in \\mathcal{R}^k\\).\nWe first assume that each latent variable \\(z_i\\) is normally distributed:\n\\[\nz_i \\sim \\mathcal{N}(0, I)\n\\]\nand the corresponding data point is generated via projection:\n\\[\nx_i | z_i \\sim \\mathcal{N}(\\mathbf{W} z_i + \\boldsymbol{μ}, \\sigma^2 \\mathbf{I})\n\\]\nwhere the projection matrix \\(\\mathbf{W}_{D \\times k}\\) accommodates the principal axes. The above formula expresses \\(x_i\\) as a linear combination of the basis columns in the projection matrix W, where the combination coefficients sit in z_i (they are the coordinats of x_i in the new \\(k\\)-dimensional space.). We can also express the above formula in matrix form: \\(\\mathbf{X}_{D \\times N} \\approx \\mathbf{W}_{D \\times k} \\mathbf{Z}_{k \\times N}\\). We are interested in inferring \\(\\mathbf{W}\\), \\(μ\\) and \\(\\sigma\\).\nClassical PCA is the specific case of probabilistic PCA when the covariance of the noise becomes infinitesimally small, i.e. \\(\\sigma^2 \\to 0\\). Probabilistic PCA generalizes classical PCA, this can be seen by marginalizing out the the latent variable.4",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Probabilistic PCA"
    ]
  },
  {
    "objectID": "tutorials/11-probabilistic-pca/index.html#overview-of-pca",
    "href": "tutorials/11-probabilistic-pca/index.html#overview-of-pca",
    "title": "Probabilistic Principal Component Analysis (p-PCA)",
    "section": "",
    "text": "Principal component analysis (PCA) is a fundamental technique to analyse and visualise data. It is an unsupervised learning method mainly used for dimensionality reduction.\nFor example, we have a data matrix \\(\\mathbf{X} \\in \\mathbb{R}^{N \\times D}\\), and we would like to extract \\(k \\ll D\\) principal components which captures most of the information from the original matrix. The goal is to understand \\(\\mathbf{X}\\) through a lower dimensional subspace (e.g. two-dimensional subspace for visualisation convenience) spanned by the principal components.\nIn order to project the original data matrix into low dimensions, we need to find the principal directions where most of the variations of \\(\\mathbf{X}\\) lie in. Traditionally, this is implemented via singular value decomposition (SVD) which provides a robust and accurate computational framework for decomposing matrix into products of rotation-scaling-rotation matrices, particularly for large datasets(see an illustration here):\n\\[\n\\mathbf{X}_{N \\times D} =  \\mathbf{U}_{N \\times r} \\times \\boldsymbol{\\Sigma}_{r \\times r}  \\times  \\mathbf{V}^T_{r \\times D}\n\\]\nwhere \\(\\Sigma_{r \\times r}\\) contains only \\(r := \\operatorname{rank} \\mathbf{X} \\leq \\min\\{N,D\\}\\) non-zero singular values of \\(\\mathbf{X}\\). If we pad \\(\\Sigma\\) with zeros and add arbitrary orthonormal columns to \\(\\mathbf{U}\\) and \\(\\mathbf{V}\\), we obtain the more compact form:1\n\\[\n\\mathbf{X}_{N \\times D} = \\mathbf{U}_{N \\times N} \\mathbf{\\Sigma}_{N \\times D} \\mathbf{V}_{D \\times D}^T\n\\]\nwhere \\(\\mathbf{U}\\) and \\(\\mathbf{V}\\) are unitary matrices (i.e. with orthonormal columns). Such a decomposition always exists for any matrix. Columns of \\(\\mathbf{V}\\) are the principal directions/axes. The percentage of variations explained can be calculated using the ratios of singular values.2\nHere we take a probabilistic perspective. For more details and a mathematical derivation, we recommend Bishop’s textbook (Christopher M. Bishop, Pattern Recognition and Machine Learning, 2006). The idea of proabilistic PCA is to find a latent variable \\(z\\) that can be used to describe the hidden structure in a dataset.3 Consider a data set \\(\\mathbf{X}_{D \\times N}=\\{x_i\\}\\) with \\(i=1,2,...,N\\) data points, where each data point \\(x_i\\) is \\(D\\)-dimensional (i.e. \\(x_i \\in \\mathcal{R}^D\\)). Note that, here we use the flipped version of the data matrix. We aim to represent the original \\(n\\) dimensional vector using a lower dimensional a latent variable \\(z_i \\in \\mathcal{R}^k\\).\nWe first assume that each latent variable \\(z_i\\) is normally distributed:\n\\[\nz_i \\sim \\mathcal{N}(0, I)\n\\]\nand the corresponding data point is generated via projection:\n\\[\nx_i | z_i \\sim \\mathcal{N}(\\mathbf{W} z_i + \\boldsymbol{μ}, \\sigma^2 \\mathbf{I})\n\\]\nwhere the projection matrix \\(\\mathbf{W}_{D \\times k}\\) accommodates the principal axes. The above formula expresses \\(x_i\\) as a linear combination of the basis columns in the projection matrix W, where the combination coefficients sit in z_i (they are the coordinats of x_i in the new \\(k\\)-dimensional space.). We can also express the above formula in matrix form: \\(\\mathbf{X}_{D \\times N} \\approx \\mathbf{W}_{D \\times k} \\mathbf{Z}_{k \\times N}\\). We are interested in inferring \\(\\mathbf{W}\\), \\(μ\\) and \\(\\sigma\\).\nClassical PCA is the specific case of probabilistic PCA when the covariance of the noise becomes infinitesimally small, i.e. \\(\\sigma^2 \\to 0\\). Probabilistic PCA generalizes classical PCA, this can be seen by marginalizing out the the latent variable.4",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Probabilistic PCA"
    ]
  },
  {
    "objectID": "tutorials/11-probabilistic-pca/index.html#the-gene-expression-example",
    "href": "tutorials/11-probabilistic-pca/index.html#the-gene-expression-example",
    "title": "Probabilistic Principal Component Analysis (p-PCA)",
    "section": "The gene expression example",
    "text": "The gene expression example\nIn the first example, we illustrate:\n\nhow to specify the probabilistic model and\nhow to perform inference on \\(\\mathbf{W}\\), \\(\\boldsymbol{\\mu}\\) and \\(\\sigma\\) using MCMC.\n\nWe use simulated gemnome data to demonstrate these. The simulation is inspired by biological measurement of expression of genes in cells, and each cell is characterized by different gene features. While the human genome is (mostly) identical between all the cells in the body, there exist interesting differences in gene expression in different human tissues and disease conditions. One way to investigate certain diseases is to look at differences in gene expression in cells from patients and healthy controls (usually from the same tissue).\nUsually, we can assume that the changes in gene expression only affect a subset of all genes (and these can be linked to diseases in some way). One of the challenges for this kind of data is to explore the underlying structure, e.g. to make the connection between a certain state (healthy/disease) and gene expression. This becomes difficult when the dimensions is very large (up to 20000 genes across 1000s of cells). So in order to find structure in this data, it is useful to project the data into a lower dimensional space.\nRegardless of the biological background, the more abstract problem formulation is to project the data living in high-dimensional space onto a representation in lower-dimensional space where most of the variation is concentrated in the first few dimensions. We use PCA to explore underlying structure or pattern which may not necessarily be obvious from looking at the raw data itself.\n\nStep 1: configuration of dependencies\nFirst, we load the dependencies used.\n\nusing Turing\nusing ReverseDiff\nusing LinearAlgebra, FillArrays\n\n# Packages for visualization\nusing DataFrames, StatsPlots, Measures\n\n# Set a seed for reproducibility.\nusing Random\nRandom.seed!(1789);\n\nAll packages used in this tutorial are listed here. You can install them via using Pkg; Pkg.add(\"package_name\").\n\n\n\n\n\n\nPackage usages:\n\n\n\nWe use DataFrames for instantiating matrices, LinearAlgebra and FillArrays to perform matrix operations; Turing for model specification and MCMC sampling, ReverseDiff for setting the automatic differentiation backend when sampling. StatsPlots for visualising the resutls. , Measures for setting plot margin units. As all examples involve sampling, for reproducibility we set a fixed seed using the Random standard library.\n\n\n\n\nStep 2: Data generation\nHere, we simulate the biological gene expression problem described earlier. We simulate 60 cells, each cell has 9 gene features. This is a simplified problem with only a few cells and genes for demonstration purpose, which is not comparable to the complexity in real-life (e.g. thousands of features for each individual). Even so, spotting the structures or patterns in a 9-feature space would be a challenging task; it would be nice to reduce the dimentionality using p-PCA.\nBy design, we mannually divide the 60 cells into two groups. the first 3 gene features of the first 30 cells have mean 10, while those of the last 30 cells have mean 10. These two groups of cells differ in the expression of genes.\n\nn_genes = 9 # D\nn_cells = 60 # N\n\n# create a diagonal block like expression matrix, with some non-informative genes;\n# not all features/genes are informative, some might just not differ very much between cells)\nmat_exp = randn(n_genes, n_cells)\nmat_exp[1:(n_genes ÷ 3), 1:(n_cells ÷ 2)] .+= 10\nmat_exp[(2 * (n_genes ÷ 3) + 1):end, (n_cells ÷ 2 + 1):end] .+= 10\n\n3×30 view(::Matrix{Float64}, 7:9, 31:60) with eltype Float64:\n 10.0726   10.2916    9.18354  10.3939   …   9.7513   9.66523  10.7303\n  9.70245   9.05473  10.1899    9.23948     11.3653  11.1318    9.27742\n 10.849    10.0644    9.41066  10.0805      10.024   11.3112    9.42683\n\n\nTo visualize the \\((D=9) \\times (N=60)\\) data matrix mat_exp, we use the heatmap plot.\n\nheatmap(\n    mat_exp;\n    c=:summer,\n    colors=:value,\n    xlabel=\"cell number\",\n    yflip=true,\n    ylabel=\"gene feature\",\n    yticks=1:9,\n    colorbar_title=\"expression\",\n)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote that:\n\nWe have made distinct feature differences between these two groups of cells (it is fairly obvious from looking at the raw data), in practice and with large enough data sets, it is often impossible to spot the differences from the raw data alone.\nIf you have some patience and compute resources you can increase the size of the dataset, or play around with the noise levels to make the problem increasingly harder.\n\n\n\nStep 3: Create the pPCA model\nHere we construct the probabilistic model pPCA(). As per the p-PCA formula, we think of each row (i.e. each gene feature) following a \\(N=60\\) dimensional multivariate normal distribution centered around the corresponding row of \\(\\mathbf{W}_{D \\times k} \\times \\mathbf{Z}_{k \\times N} + \\boldsymbol{\\mu}_{D \\times N}\\).\n\n@model function pPCA(X::AbstractMatrix{&lt;:Real}, k::Int)\n    # retrieve the dimension of input matrix X.\n    N, D = size(X)\n\n    # weights/loadings W\n    W ~ filldist(Normal(), D, k)\n\n    # latent variable z\n    Z ~ filldist(Normal(), k, N)\n\n    # mean offset\n    μ ~ MvNormal(Eye(D))\n    genes_mean = W * Z .+ reshape(μ, n_genes, 1)\n    return X ~ arraydist([MvNormal(m, Eye(N)) for m in eachcol(genes_mean')])\nend;\n\nThe function pPCA() accepts:\n\nan data array \\(\\mathbf{X}\\) (with no. of instances x dimension no. of features, NB: it is a transpose of the original data matrix);\nan integer \\(k\\) which indicates the dimension of the latent space (the space the original feature matrix is projected onto).\n\nSpecifically:\n\nit first extracts the dimension \\(D\\) and number of instances \\(N\\) of the input matrix;\ndraw samples of each entries of the projection matrix \\(\\mathbf{W}\\) from a standard normal;\ndraw samples of the latent variable \\(\\mathbf{Z}_{k \\times N}\\) from an MND;\ndraw samples of the offset \\(\\boldsymbol{\\mu}\\) from an MND, assuming uniform offset for all instances;\nFinally, we iterate through each gene dimension in \\(\\mathbf{X}\\), and define an MND for the sampling distribution (i.e. likelihood).\n\n\n\nStep 4: Sampling-based inference of the pPCA model\nHere we aim to perform MCMC sampling to infer the projection matrix \\(\\mathbf{W}_{D \\times k}\\), the latent variable matrix \\(\\mathbf{Z}_{k \\times N}\\), and the offsets \\(\\boldsymbol{\\mu}_{N \\times 1}\\).\nWe run the inference using the NUTS sampler, of which the chain length is set to be 500, target accept ratio 0.65 and initial stepsize 0.1. By default, the NUTS sampler samples 1 chain. You are free to try different samplers.\n\nsetprogress!(false)\n\n\nk = 2 # k is the dimension of the projected space, i.e. the number of principal components/axes of choice\nppca = pPCA(mat_exp', k) # instantiate the probabilistic model\nchain_ppca = sample(ppca, NUTS(;adtype=AutoReverseDiff()), 500);\n\n┌ Info: Found initial step size\n└   ϵ = 0.4\n\n\nThe samples are saved in the Chains struct chain_ppca, whose shape can be checked:\n\nsize(chain_ppca) # (no. of iterations, no. of vars, no. of chains) = (500, 159, 1)\n\n(500, 159, 1)\n\n\nThe Chains struct chain_ppca also contains the sampling info such as r-hat, ess, mean estimates, etc. You can print it to check these quantities.\n\n\nStep 5: posterior predictive checks\nWe try to reconstruct the input data using the posterior mean as parameter estimates. We first retrieve the samples for the projection matrix W from chain_ppca. This can be done using the Julia group(chain, parameter_name) function. Then we calculate the mean value for each element in \\(W\\), averaging over the whole chain of samples.\n\n# Extract parameter estimates for predicting x - mean of posterior\nW = reshape(mean(group(chain_ppca, :W))[:, 2], (n_genes, k))\nZ = reshape(mean(group(chain_ppca, :Z))[:, 2], (k, n_cells))\nμ = mean(group(chain_ppca, :μ))[:, 2]\n\nmat_rec = W * Z .+ repeat(μ; inner=(1, n_cells))\n\n9×60 Matrix{Float64}:\n  6.62786     6.73151     6.65849     6.54758    …   3.36262      3.12965\n  6.77456     6.84922     6.79384     6.69806        3.53223      3.29779\n  6.78049     6.87195     6.80656     6.70319        3.59092      3.36227\n -0.103268   -0.0940559  -0.0999213  -0.106212      -0.193648    -0.1994\n -0.0294557  -0.0255876  -0.0279073  -0.0297306     -0.0215814   -0.0205672\n -0.0460541  -0.0375563  -0.0425896  -0.0462365  …  -0.00865711  -0.00492504\n  3.07441     2.96588     3.04208     3.15679        6.41369      6.65167\n  3.00437     2.92406     2.98336     3.08484        6.40553      6.65124\n  3.47516     3.38609     3.44994     3.55156        6.63473      6.8614\n\n\n\nheatmap(\n    mat_rec;\n    c=:summer,\n    colors=:value,\n    xlabel=\"cell number\",\n    yflip=true,\n    ylabel=\"gene feature\",\n    yticks=1:9,\n    colorbar_title=\"expression\",\n)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can quantitatively check the absolute magnitudes of the column average of the gap between mat_exp and mat_rec:\nWe observe that, using posterior mean, the recovered data matrix mat_rec has values align with the original data matrix - particularly the same pattern in the first and last 3 gene features are captured, which implies the inference and p-PCA decomposition are successful. This is satisfying as we have just projected the original 9-dimensional space onto a 2-dimensional space - some info has been cut off in the projection process, but we haven’t lost any important info, e.g. the key differences between the two groups. The is the desirable property of PCA: it picks up the principal axes along which most of the (original) data variations cluster, and remove those less relevant. If we choose the reduced space dimension \\(k\\) to be exactly \\(D\\) (the original data dimension), we would recover exactly the same original data matrix mat_exp, i.e. all information will be preserved.\nNow we have represented the original high-dimensional data in two dimensions, without lossing the key information about the two groups of cells in the input data. Finally, the benefits of performing PCA is to analyse and visualise the dimension-reduced data in the projected, low-dimensional space. we save the dimension-reduced matrix \\(\\mathbf{Z}\\) as a DataFrame, rename the columns and visualise the first two dimensions.\n\ndf_pca = DataFrame(Z', :auto)\nrename!(df_pca, Symbol.([\"z\" * string(i) for i in collect(1:k)]))\ndf_pca[!, :type] = repeat([1, 2]; inner=n_cells ÷ 2)\n\nscatter(df_pca[:, :z1], df_pca[:, :z2]; xlabel=\"z1\", ylabel=\"z2\", group=df_pca[:, :type])\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe see the two groups are well separated in this 2-D space. As an unsupervised learning method, performing PCA on this dataset gives membership for each cell instance. Another way to put it: 2 dimensions is enough to capture the main structure of the data.\n\n\nFurther extension: automatic choice of the number of principal components with ARD\nA direct question arises from above practice is: how many principal components do we want to keep, in order to sufficiently represent the latent structure in the data? This is a very central question for all latent factor models, i.e. how many dimensions are needed to represent that data in the latent space. In the case of PCA, there exist a lot of heuristics to make that choice. For example, We can tune the number of principal components using empirical methods such as cross-validation based some criteria such as MSE between the posterior predicted (e.g. mean predictions) data matrix and the original data matrix or the percentage of variation explained [3].\nFor p-PCA, this can be done in an elegant and principled way, using a technique called Automatic Relevance Determination (ARD). ARD can help pick the correct number of principal directions by regularizing the solution space using a parameterized, data-dependent prior distribution that effectively prunes away redundant or superfluous features [4]. Essentially, we are using a specific prior over the factor loadings \\(\\mathbf{W}\\) that allows us to prune away dimensions in the latent space. The prior is determined by a precision hyperparameter \\(\\alpha\\). Here, smaller values of \\(\\alpha\\) correspond to more important components. You can find more details about this in e.g. [5].\n\n@model function pPCA_ARD(X)\n    # Dimensionality of the problem.\n    N, D = size(X)\n\n    # latent variable Z\n    Z ~ filldist(Normal(), D, N)\n\n    # weights/loadings w with Automatic Relevance Determination part\n    α ~ filldist(Gamma(1.0, 1.0), D)\n    W ~ filldist(MvNormal(zeros(D), 1.0 ./ sqrt.(α)), D)\n\n    mu = (W' * Z)'\n\n    tau ~ Gamma(1.0, 1.0)\n    return X ~ arraydist([MvNormal(m, 1.0 / sqrt(tau)) for m in eachcol(mu)])\nend;\n\nInstead of drawing samples of each entry in \\(\\mathbf{W}\\) from a standard normal, this time we repeatedly draw \\(D\\) samples from the \\(D\\)-dimensional MND, forming a \\(D \\times D\\) matrix \\(\\mathbf{W}\\). This matrix is a function of \\(\\alpha\\) as the samples are drawn from the MND parameterized by \\(\\alpha\\). We also introduce a hyper-parameter \\(\\tau\\) which is the precision in the sampling distribution. We also re-paramterise the sampling distribution, i.e. each dimension across all instances is a 60-dimensional multivariate normal distribution. Re-parameterisation can sometimes accelrate the sampling process.\nWe instantiate the model and ask Turing to sample from it using NUTS sampler. The sample trajectories of \\(\\alpha\\) is plotted using the plot function from the package StatsPlots.\n\nppca_ARD = pPCA_ARD(mat_exp') # instantiate the probabilistic model\nchain_ppcaARD = sample(ppca_ARD, NUTS(;adtype=AutoReverseDiff()), 500) # sampling\nplot(group(chain_ppcaARD, :α); margin=6.0mm)\n\n┌ Info: Found initial step size\n└   ϵ = 0.05\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAgain, we do some inference diagnostics. Here we look at the convergence of the chains for the \\(α\\) parameter. This parameter determines the relevance of individual components. We see that the chains have converged and the posterior of the \\(\\alpha\\) parameters is centered around much smaller values in two instances. In the following, we will use the mean of the small values to select the relevant dimensions (remember that, smaller values of \\(\\alpha\\) correspond to more important components.). We can clearly see from the values of \\(\\alpha\\) that there should be two dimensions (corresponding to \\(\\bar{\\alpha}_3=\\bar{\\alpha}_5≈0.05\\)) for this dataset.\n\n# Extract parameter mean estimates of the posterior\nW = permutedims(reshape(mean(group(chain_ppcaARD, :W))[:, 2], (n_genes, n_genes)))\nZ = permutedims(reshape(mean(group(chain_ppcaARD, :Z))[:, 2], (n_genes, n_cells)))'\nα = mean(group(chain_ppcaARD, :α))[:, 2]\nplot(α; label=\"α\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can inspect α to see which elements are small (i.e. high relevance). To do this, we first sort α using sortperm() (in ascending order by default), and record the indices of the first two smallest values (among the \\(D=9\\) \\(\\alpha\\) values). After picking the desired principal directions, we extract the corresponding subset loading vectors from \\(\\mathbf{W}\\), and the corresponding dimensions of \\(\\mathbf{Z}\\). We obtain a posterior predicted matrix \\(\\mathbf{X} \\in \\mathbb{R}^{2 \\times 60}\\) as the product of the two sub-matrices, and compare the recovered info with the original matrix.\n\nα_indices = sortperm(α)[1:2]\nk = size(α_indices)[1]\nX_rec = W[:, α_indices] * Z[α_indices, :]\n\ndf_rec = DataFrame(X_rec', :auto)\nheatmap(\n    X_rec;\n    c=:summer,\n    colors=:value,\n    xlabel=\"cell number\",\n    yflip=true,\n    ylabel=\"gene feature\",\n    yticks=1:9,\n    colorbar_title=\"expression\",\n)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nWe observe that, the data in the original space is recovered with key information, the distinct feature values in the first and last three genes for the two cell groups, are preserved. We can also examine the data in the dimension-reduced space, i.e. the selected components (rows) in \\(\\mathbf{Z}\\).\n\ndf_pro = DataFrame(Z[α_indices, :]', :auto)\nrename!(df_pro, Symbol.([\"z\" * string(i) for i in collect(1:k)]))\ndf_pro[!, :type] = repeat([1, 2]; inner=n_cells ÷ 2)\nscatter(\n    df_pro[:, 1], df_pro[:, 2]; xlabel=\"z1\", ylabel=\"z2\", color=df_pro[:, \"type\"], label=\"\"\n)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis plot is very similar to the low-dimensional plot above, with the relevant dimensions chosen based on the values of \\(α\\) via ARD. When you are in doubt about the number of dimensions to project onto, ARD might provide an answer to that question.",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Probabilistic PCA"
    ]
  },
  {
    "objectID": "tutorials/11-probabilistic-pca/index.html#final-comments.",
    "href": "tutorials/11-probabilistic-pca/index.html#final-comments.",
    "title": "Probabilistic Principal Component Analysis (p-PCA)",
    "section": "Final comments.",
    "text": "Final comments.\np-PCA is a linear map which linearly transforms the data between the original and projected spaces. It can also thought as a matrix factorisation method, in which \\(\\mathbf{X}=(\\mathbf{W} \\times \\mathbf{Z})^T\\). The projection matrix can be understood as a new basis in the projected space, and \\(\\mathbf{Z}\\) are the new coordinates.",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Probabilistic PCA"
    ]
  },
  {
    "objectID": "tutorials/11-probabilistic-pca/index.html#footnotes",
    "href": "tutorials/11-probabilistic-pca/index.html#footnotes",
    "title": "Probabilistic Principal Component Analysis (p-PCA)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nGilbert Strang, Introduction to Linear Algebra, 5th Ed., Wellesley-Cambridge Press, 2016.↩︎\nGareth M. James, Daniela Witten, Trevor Hastie, Robert Tibshirani, An Introduction to Statistical Learning, Springer, 2013.↩︎\nProbabilistic PCA by TensorFlow, “https://www.tensorflow.org/probability/examples/Probabilistic_PCA”.↩︎\nProbabilistic PCA by TensorFlow, “https://www.tensorflow.org/probability/examples/Probabilistic_PCA”.↩︎",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Probabilistic PCA"
    ]
  },
  {
    "objectID": "tutorials/05-linear-regression/index.html",
    "href": "tutorials/05-linear-regression/index.html",
    "title": "Linear Regression",
    "section": "",
    "text": "Turing is powerful when applied to complex hierarchical models, but it can also be put to task at common statistical procedures, like linear regression. This tutorial covers how to implement a linear regression model in Turing.",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Linear Regression"
    ]
  },
  {
    "objectID": "tutorials/05-linear-regression/index.html#set-up",
    "href": "tutorials/05-linear-regression/index.html#set-up",
    "title": "Linear Regression",
    "section": "Set Up",
    "text": "Set Up\nWe begin by importing all the necessary libraries.\n\n# Import Turing.\nusing Turing\n\n# Package for loading the data set.\nusing RDatasets\n\n# Package for visualization.\nusing StatsPlots\n\n# Functionality for splitting the data.\nusing MLUtils: splitobs\n\n# Functionality for constructing arrays with identical elements efficiently.\nusing FillArrays\n\n# Functionality for normalizing the data and evaluating the model predictions.\nusing StatsBase\n\n# Functionality for working with scaled identity matrices.\nusing LinearAlgebra\n\n# Set a seed for reproducibility.\nusing Random\nRandom.seed!(0);\n\n\nsetprogress!(false)\n\nWe will use the mtcars dataset from the RDatasets package. mtcars contains a variety of statistics on different car models, including their miles per gallon, number of cylinders, and horsepower, among others.\nWe want to know if we can construct a Bayesian linear regression model to predict the miles per gallon of a car, given the other statistics it has. Let us take a look at the data we have.\n\n# Load the dataset.\ndata = RDatasets.dataset(\"datasets\", \"mtcars\")\n\n# Show the first six rows of the dataset.\nfirst(data, 6)\n\n6×12 DataFrame\n\n\n\nRow\nModel\nMPG\nCyl\nDisp\nHP\nDRat\nWT\nQSec\nVS\nAM\nGear\nCarb\n\n\n\nString31\nFloat64\nInt64\nFloat64\nInt64\nFloat64\nFloat64\nFloat64\nInt64\nInt64\nInt64\nInt64\n\n\n\n\n1\nMazda RX4\n21.0\n6\n160.0\n110\n3.9\n2.62\n16.46\n0\n1\n4\n4\n\n\n2\nMazda RX4 Wag\n21.0\n6\n160.0\n110\n3.9\n2.875\n17.02\n0\n1\n4\n4\n\n\n3\nDatsun 710\n22.8\n4\n108.0\n93\n3.85\n2.32\n18.61\n1\n1\n4\n1\n\n\n4\nHornet 4 Drive\n21.4\n6\n258.0\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\n5\nHornet Sportabout\n18.7\n8\n360.0\n175\n3.15\n3.44\n17.02\n0\n0\n3\n2\n\n\n6\nValiant\n18.1\n6\n225.0\n105\n2.76\n3.46\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\n\nsize(data)\n\n(32, 12)\n\n\nThe next step is to get our data ready for testing. We’ll split the mtcars dataset into two subsets, one for training our model and one for evaluating our model. Then, we separate the targets we want to learn (MPG, in this case) and standardize the datasets by subtracting each column’s means and dividing by the standard deviation of that column. The resulting data is not very familiar looking, but this standardization process helps the sampler converge far easier.\n\n# Remove the model column.\nselect!(data, Not(:Model))\n\n# Split our dataset 70%/30% into training/test sets.\ntrainset, testset = map(DataFrame, splitobs(data; at=0.7, shuffle=true))\n\n# Turing requires data in matrix form.\ntarget = :MPG\ntrain = Matrix(select(trainset, Not(target)))\ntest = Matrix(select(testset, Not(target)))\ntrain_target = trainset[:, target]\ntest_target = testset[:, target]\n\n# Standardize the features.\ndt_features = fit(ZScoreTransform, train; dims=1)\nStatsBase.transform!(dt_features, train)\nStatsBase.transform!(dt_features, test)\n\n# Standardize the targets.\ndt_targets = fit(ZScoreTransform, train_target)\nStatsBase.transform!(dt_targets, train_target)\nStatsBase.transform!(dt_targets, test_target);",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Linear Regression"
    ]
  },
  {
    "objectID": "tutorials/05-linear-regression/index.html#model-specification",
    "href": "tutorials/05-linear-regression/index.html#model-specification",
    "title": "Linear Regression",
    "section": "Model Specification",
    "text": "Model Specification\nIn a traditional frequentist model using OLS, our model might look like:\n\\[\n\\mathrm{MPG}_i = \\alpha + \\boldsymbol{\\beta}^\\mathsf{T}\\boldsymbol{X_i}\n\\]\nwhere \\(\\boldsymbol{\\beta}\\) is a vector of coefficients and \\(\\boldsymbol{X}\\) is a vector of inputs for observation \\(i\\). The Bayesian model we are more concerned with is the following:\n\\[\n\\mathrm{MPG}_i \\sim \\mathcal{N}(\\alpha + \\boldsymbol{\\beta}^\\mathsf{T}\\boldsymbol{X_i}, \\sigma^2)\n\\]\nwhere \\(\\alpha\\) is an intercept term common to all observations, \\(\\boldsymbol{\\beta}\\) is a coefficient vector, \\(\\boldsymbol{X_i}\\) is the observed data for car \\(i\\), and \\(\\sigma^2\\) is a common variance term.\nFor \\(\\sigma^2\\), we assign a prior of truncated(Normal(0, 100); lower=0). This is consistent with Andrew Gelman’s recommendations on noninformative priors for variance. The intercept term (\\(\\alpha\\)) is assumed to be normally distributed with a mean of zero and a variance of three. This represents our assumptions that miles per gallon can be explained mostly by our assorted variables, but a high variance term indicates our uncertainty about that. Each coefficient is assumed to be normally distributed with a mean of zero and a variance of 10. We do not know that our coefficients are different from zero, and we don’t know which ones are likely to be the most important, so the variance term is quite high. Lastly, each observation \\(y_i\\) is distributed according to the calculated mu term given by \\(\\alpha + \\boldsymbol{\\beta}^\\mathsf{T}\\boldsymbol{X_i}\\).\n\n# Bayesian linear regression.\n@model function linear_regression(x, y)\n    # Set variance prior.\n    σ² ~ truncated(Normal(0, 100); lower=0)\n\n    # Set intercept prior.\n    intercept ~ Normal(0, sqrt(3))\n\n    # Set the priors on our coefficients.\n    nfeatures = size(x, 2)\n    coefficients ~ MvNormal(Zeros(nfeatures), 10.0 * I)\n\n    # Calculate all the mu terms.\n    mu = intercept .+ x * coefficients\n    return y ~ MvNormal(mu, σ² * I)\nend\n\nlinear_regression (generic function with 2 methods)\n\n\nWith our model specified, we can call the sampler. We will use the No U-Turn Sampler (NUTS) here.\n\nmodel = linear_regression(train, train_target)\nchain = sample(model, NUTS(), 5_000)\n\n┌ Info: Found initial step size\n└   ϵ = 0.025\n\n\nChains MCMC chain (5000×24×1 Array{Float64, 3}):\n\nIterations        = 1001:1:6000\nNumber of chains  = 1\nSamples per chain = 5000\nWall duration     = 12.58 seconds\nCompute duration  = 12.58 seconds\nparameters        = σ², intercept, coefficients[1], coefficients[2], coefficients[3], coefficients[4], coefficients[5], coefficients[6], coefficients[7], coefficients[8], coefficients[9], coefficients[10]\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n        parameters      mean       std      mcse    ess_bulk    ess_tail       ⋯\n            Symbol   Float64   Float64   Float64     Float64     Float64   Flo ⋯\n\n                σ²    0.2796    0.1611    0.0046    947.1937    666.9609    1. ⋯\n         intercept    0.0014    0.1142    0.0019   3827.2801   2476.7595    1. ⋯\n   coefficients[1]    1.0454    1.0354    0.0252   1670.8999   2237.4162    1. ⋯\n   coefficients[2]    0.5897    0.6520    0.0142   2127.6172   2502.9274    1. ⋯\n   coefficients[3]   -0.1076    0.5758    0.0133   1870.7740   2472.2350    1. ⋯\n   coefficients[4]    0.5589    0.4210    0.0088   2286.0816   2828.5264    1. ⋯\n   coefficients[5]   -0.6139    0.5307    0.0119   1977.1701   2185.5220    1. ⋯\n   coefficients[6]    0.5877    0.4103    0.0101   1641.7678   2205.2682    1. ⋯\n   coefficients[7]    0.2251    0.3999    0.0097   1675.9797   2362.6577    1. ⋯\n   coefficients[8]    0.5644    0.4304    0.0109   1532.7568   2469.3487    1. ⋯\n   coefficients[9]    0.2846    0.7224    0.0189   1455.9662   2449.7272    1. ⋯\n  coefficients[10]   -0.2992    0.3905    0.0084   2162.4706   2448.2993    1. ⋯\n                                                               2 columns omitted\n\nQuantiles\n        parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n            Symbol   Float64   Float64   Float64   Float64   Float64\n\n                σ²    0.1040    0.1751    0.2399    0.3354    0.6984\n         intercept   -0.2289   -0.0694    0.0028    0.0723    0.2323\n   coefficients[1]   -1.0672    0.3772    1.0678    1.7215    3.0482\n   coefficients[2]   -0.7246    0.1875    0.5847    1.0001    1.8815\n   coefficients[3]   -1.2732   -0.4716   -0.1045    0.2573    1.0122\n   coefficients[4]   -0.2665    0.2934    0.5475    0.8205    1.4177\n   coefficients[5]   -1.6475   -0.9659   -0.6180   -0.2688    0.4633\n   coefficients[6]   -0.2644    0.3209    0.5945    0.8554    1.3833\n   coefficients[7]   -0.6001   -0.0328    0.2279    0.4890    1.0006\n   coefficients[8]   -0.3293    0.2888    0.5670    0.8465    1.4123\n   coefficients[9]   -1.1786   -0.1837    0.2911    0.7601    1.7052\n  coefficients[10]   -1.0984   -0.5448   -0.3072   -0.0466    0.4641\n\n\nWe can also check the densities and traces of the parameters visually using the plot functionality.\n\nplot(chain)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt looks like all parameters have converged.\n\n\nAssertionError: AssertionError(\"Mean ESS: 1931.3298059617682 - not &gt; 2000\")\nAssertionError: Mean ESS: 1931.3298059617682 - not &gt; 2000\nStacktrace:\n [1] top-level scope\n   @ ~/work/docs/docs/tutorials/05-linear-regression/index.qmd:202",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Linear Regression"
    ]
  },
  {
    "objectID": "tutorials/05-linear-regression/index.html#comparing-to-ols",
    "href": "tutorials/05-linear-regression/index.html#comparing-to-ols",
    "title": "Linear Regression",
    "section": "Comparing to OLS",
    "text": "Comparing to OLS\nA satisfactory test of our model is to evaluate how well it predicts. Importantly, we want to compare our model to existing tools like OLS. The code below uses the GLM.jl package to generate a traditional OLS multiple regression model on the same data as our probabilistic model.\n\n# Import the GLM package.\nusing GLM\n\n# Perform multiple regression OLS.\ntrain_with_intercept = hcat(ones(size(train, 1)), train)\nols = lm(train_with_intercept, train_target)\n\n# Compute predictions on the training data set and unstandardize them.\ntrain_prediction_ols = GLM.predict(ols)\nStatsBase.reconstruct!(dt_targets, train_prediction_ols)\n\n# Compute predictions on the test data set and unstandardize them.\ntest_with_intercept = hcat(ones(size(test, 1)), test)\ntest_prediction_ols = GLM.predict(ols, test_with_intercept)\nStatsBase.reconstruct!(dt_targets, test_prediction_ols);\n\nThe function below accepts a chain and an input matrix and calculates predictions. We use the samples of the model parameters in the chain starting with sample 200.\n\n# Make a prediction given an input vector.\nfunction prediction(chain, x)\n    p = get_params(chain[200:end, :, :])\n    targets = p.intercept' .+ x * reduce(hcat, p.coefficients)'\n    return vec(mean(targets; dims=2))\nend\n\nprediction (generic function with 1 method)\n\n\nWhen we make predictions, we unstandardize them so they are more understandable.\n\n# Calculate the predictions for the training and testing sets and unstandardize them.\ntrain_prediction_bayes = prediction(chain, train)\nStatsBase.reconstruct!(dt_targets, train_prediction_bayes)\ntest_prediction_bayes = prediction(chain, test)\nStatsBase.reconstruct!(dt_targets, test_prediction_bayes)\n\n# Show the predictions on the test data set.\nDataFrame(; MPG=testset[!, target], Bayes=test_prediction_bayes, OLS=test_prediction_ols)\n\n10×3 DataFrame\n\n\n\nRow\nMPG\nBayes\nOLS\n\n\n\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n16.4\n13.4096\n13.0968\n\n\n2\n10.4\n12.9191\n13.1145\n\n\n3\n15.0\n16.8731\n19.9659\n\n\n4\n30.4\n32.9521\n32.7209\n\n\n5\n21.0\n21.3095\n21.2455\n\n\n6\n15.8\n30.5442\n33.6484\n\n\n7\n30.4\n25.2817\n26.4409\n\n\n8\n19.7\n15.7025\n16.7259\n\n\n9\n24.4\n16.8931\n15.9203\n\n\n10\n21.5\n17.3149\n15.6334\n\n\n\n\n\n\nNow let’s evaluate the loss for each method, and each prediction set. We will use the mean squared error to evaluate loss, given by \\[\n\\mathrm{MSE} = \\frac{1}{n} \\sum_{i=1}^n {(y_i - \\hat{y_i})^2}\n\\] where \\(y_i\\) is the actual value (true MPG) and \\(\\hat{y_i}\\) is the predicted value using either OLS or Bayesian linear regression. A lower SSE indicates a closer fit to the data.\n\nprintln(\n    \"Training set:\",\n    \"\\n\\tBayes loss: \",\n    msd(train_prediction_bayes, trainset[!, target]),\n    \"\\n\\tOLS loss: \",\n    msd(train_prediction_ols, trainset[!, target]),\n)\n\nprintln(\n    \"Test set:\",\n    \"\\n\\tBayes loss: \",\n    msd(test_prediction_bayes, testset[!, target]),\n    \"\\n\\tOLS loss: \",\n    msd(test_prediction_ols, testset[!, target]),\n)\n\nTraining set:\n    Bayes loss: 3.3099305758516793\n    OLS loss: 3.2911562431554633\nTest set:\n    Bayes loss: 35.884444066503434\n    OLS loss: 49.77948044641477\n\n\n\n\nAssertionError: AssertionError(\"Difference between Bayesian test loss (35.884444066503434) and OLS test loss (49.77948044641477) unexpectedly large!\")\nAssertionError: Difference between Bayesian test loss (35.884444066503434) and OLS test loss (49.77948044641477) unexpectedly large!\nStacktrace:\n [1] top-level scope\n   @ ~/work/docs/docs/tutorials/05-linear-regression/index.qmd:311\n\n\nAs we can see above, OLS and our Bayesian model fit our training and test data set about the same.",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Linear Regression"
    ]
  },
  {
    "objectID": "tutorials/docs-17-mode-estimation/index.html",
    "href": "tutorials/docs-17-mode-estimation/index.html",
    "title": "Mode Estimation",
    "section": "",
    "text": "After defining a statistical model, in addition to sampling from its distributions, one may be interested in finding the parameter values that maximise for instance the posterior distribution density function or the likelihood. This is called mode estimation. Turing provides support for two mode estimation techniques, maximum likelihood estimation (MLE) and maximum a posterior (MAP) estimation.\nTo demonstrate mode estimation, let us load Turing and declare a model:\nusing Turing\n\n@model function gdemo(x)\n    s² ~ InverseGamma(2, 3)\n    m ~ Normal(0, sqrt(s²))\n\n    for i in eachindex(x)\n        x[i] ~ Normal(m, sqrt(s²))\n    end\nend\n\ngdemo (generic function with 2 methods)\nOnce the model is defined, we can construct a model instance as we normally would:\n# Instantiate the gdemo model with our data.\ndata = [1.5, 2.0]\nmodel = gdemo(data)\n\nDynamicPPL.Model{typeof(gdemo), (:x,), (), (), Tuple{Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}(Main.Notebook.gdemo, (x = [1.5, 2.0],), NamedTuple(), DynamicPPL.DefaultContext())\nFinding the maximum aposteriori or maximum likelihood parameters is as simple as\n# Generate a MLE estimate.\nmle_estimate = maximum_likelihood(model)\n\n# Generate a MAP estimate.\nmap_estimate = maximum_a_posteriori(model)\n\nModeResult with maximized lp of -4.62\n[0.907407407370442, 1.1666666667569312]\nThe estimates are returned as instances of the ModeResult type. It has the fields values for the parameter values found and lp for the log probability at the optimum, as well as f for the objective function and optim_result for more detailed results of the optimisation procedure.\n@show mle_estimate.values\n@show mle_estimate.lp;\n\nmle_estimate.values = [0.06250000000000064, 1.7499999999999993]\nmle_estimate.lp = -0.06528834416956464",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Mode Estimation"
    ]
  },
  {
    "objectID": "tutorials/docs-17-mode-estimation/index.html#controlling-the-optimisation-process",
    "href": "tutorials/docs-17-mode-estimation/index.html#controlling-the-optimisation-process",
    "title": "Mode Estimation",
    "section": "Controlling the optimisation process",
    "text": "Controlling the optimisation process\nUnder the hood maximum_likelihood and maximum_a_posteriori use the Optimization.jl package, which provides a unified interface to many other optimisation packages. By default Turing typically uses the LBFGS method from Optim.jl to find the mode estimate, but we can easily change that:\n\nusing OptimizationOptimJL: NelderMead\n@show maximum_likelihood(model, NelderMead())\n\nusing OptimizationNLopt: NLopt.LD_TNEWTON_PRECOND_RESTART\n@show maximum_likelihood(model, LD_TNEWTON_PRECOND_RESTART());\n\nmaximum_likelihood(model, NelderMead()) = [0.06250218655262568, 1.7500060419729637]\nmaximum_likelihood(model, LD_TNEWTON_PRECOND_RESTART()) = [0.0625, 1.75]\n\n\nThe above are just two examples, Optimization.jl supports many more.\nWe can also help the optimisation by giving it a starting point we know is close to the final solution, or by specifying an automatic differentiation method\n\nusing ADTypes: AutoReverseDiff\nimport ReverseDiff\nmaximum_likelihood(\n    model, NelderMead(); initial_params=[0.1, 2], adtype=AutoReverseDiff()\n)\n\nModeResult with maximized lp of -0.07\n[0.062494553692639856, 1.7500042095865365]\n\n\nWhen providing values to arguments like initial_params the parameters are typically specified in the order in which they appear in the code of the model, so in this case first s² then m. More precisely it’s the order returned by Turing.Inference.getparams(model, Turing.VarInfo(model)).\nWe can also do constrained optimisation, by providing either intervals within which the parameters must stay, or costraint functions that they need to respect. For instance, here’s how one can find the MLE with the constraint that the variance must be less than 0.01 and the mean must be between -1 and 1.:\n\nmaximum_likelihood(model; lb=[0.0, -1.0], ub=[0.01, 1.0])\n\nModeResult with maximized lp of -59.73\n[0.009999999767873307, 0.9999999904828051]\n\n\nThe arguments for lower (lb) and upper (ub) bounds follow the arguments of Optimization.OptimizationProblem, as do other parameters for providing constraints, such as cons. Any extraneous keyword arguments given to maximum_likelihood or maximum_a_posteriori are passed to Optimization.solve. Some often useful ones are maxiters for controlling the maximum number of iterations and abstol and reltol for the absolute and relative convergence tolerances:\n\nbadly_converged_mle = maximum_likelihood(\n    model, NelderMead(); maxiters=10, reltol=1e-9\n)\n\nModeResult with maximized lp of -1.60\n[0.7067814190723006, 1.8796550897619242]\n\n\nWe can check whether the optimisation converged using the optim_result field of the result:\n\n@show badly_converged_mle.optim_result;\n\nbadly_converged_mle.optim_result = retcode: Failure\nu: [-0.3470338276876128, 1.8796550897619242]\nFinal objective value:     1.6030567748462012\n\n\n\nFor more details, such as a full list of possible arguments, we encourage the reader to read the docstring of the function Turing.Optimisation.estimate_mode, which is what maximum_likelihood and maximum_a_posteriori call, and the documentation of Optimization.jl.",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Mode Estimation"
    ]
  },
  {
    "objectID": "tutorials/docs-17-mode-estimation/index.html#analyzing-your-mode-estimate",
    "href": "tutorials/docs-17-mode-estimation/index.html#analyzing-your-mode-estimate",
    "title": "Mode Estimation",
    "section": "Analyzing your mode estimate",
    "text": "Analyzing your mode estimate\nTuring extends several methods from StatsBase that can be used to analyze your mode estimation results. Methods implemented include vcov, informationmatrix, coeftable, params, and coef, among others.\nFor example, let’s examine our ML estimate from above using coeftable:\n\nusing StatsBase: coeftable\ncoeftable(mle_estimate)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoef.\nStd. Error\nz\nPr(&gt;\nz\n)\n\n\n\n\ns²\n0.0625\n0.0625\n1.0\n0.317311\n-0.0599977\n0.184998\n\n\nm\n1.75\n0.176777\n9.89949\n4.18383e-23\n1.40352\n2.09648\n\n\n\n\n\nStandard errors are calculated from the Fisher information matrix (inverse Hessian of the log likelihood or log joint). Note that standard errors calculated in this way may not always be appropriate for MAP estimates, so please be cautious in interpreting them.",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Mode Estimation"
    ]
  },
  {
    "objectID": "tutorials/docs-17-mode-estimation/index.html#sampling-with-the-mapmle-as-initial-states",
    "href": "tutorials/docs-17-mode-estimation/index.html#sampling-with-the-mapmle-as-initial-states",
    "title": "Mode Estimation",
    "section": "Sampling with the MAP/MLE as initial states",
    "text": "Sampling with the MAP/MLE as initial states\nYou can begin sampling your chain from an MLE/MAP estimate by extracting the vector of parameter values and providing it to the sample function with the keyword initial_params. For example, here is how to sample from the full posterior using the MAP estimate as the starting point:\n\nmap_estimate = maximum_a_posteriori(model)\nchain = sample(model, NUTS(), 1_000; initial_params=map_estimate.values.array)",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Mode Estimation"
    ]
  },
  {
    "objectID": "tutorials/docs-10-using-turing-autodiff/index.html",
    "href": "tutorials/docs-10-using-turing-autodiff/index.html",
    "title": "Automatic Differentiation",
    "section": "",
    "text": "Turing currently supports four automatic differentiation (AD) backends for sampling: ForwardDiff for forward-mode AD; and ReverseDiff, Zygote, and Tracker for reverse-mode AD. While Tracker is still available, its use is discouraged due to a lack of active maintenance. ForwardDiff is automatically imported by Turing. To utilize Zygote or ReverseDiff for AD, users must explicitly import them with using Zygote or using ReverseDiff, alongside using Turing.\nAs of Turing version v0.30, the global configuration flag for the AD backend has been removed in favour of AdTypes.jl, allowing users to specify the AD backend for individual samplers independently. Users can pass the adtype keyword argument to the sampler constructor to select the desired AD backend, with the default being AutoForwardDiff(; chunksize=0).\nFor ForwardDiff, pass adtype=AutoForwardDiff(; chunksize) to the sampler constructor. A chunksize of 0 permits the chunk size to be automatically determined. For more information regarding the selection of chunksize, please refer to related section of ForwardDiff’s documentation. For ReverseDiff, pass adtype=AutoReverseDiff() to the sampler constructor. An additional argument can be provided to AutoReverseDiff to specify whether to to compile the tape only once and cache it for later use (false by default, which means no caching tape). Be aware that the use of caching in certain types of models can lead to incorrect results and/or errors.\nCompiled tapes should only be used if you are absolutely certain that the computation doesn’t change between different executions of your model. Thus, e.g., in the model definition and all im- and explicitly called functions in the model all loops should be of fixed size, and if-statements should consistently execute the same branches. For instance, if-statements with conditions that can be determined at compile time or conditions that depend only on the data will always execute the same branches during sampling (if the data is constant throughout sampling and, e.g., no mini-batching is used). However, if-statements that depend on the model parameters can take different branches during sampling; hence, the compiled tape might be incorrect. Thus you must not use compiled tapes when your model makes decisions based on the model parameters, and you should be careful if you compute functions of parameters that those functions do not have branching which might cause them to execute different code for different values of the parameter.\nFor Zygote, pass adtype=AutoZygote() to the sampler constructor.\nAnd the previously used interface functions including ADBackend, setadbackend, setsafe, setchunksize, and setrdcache are deprecated and removed.",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Automatic Differentiation"
    ]
  },
  {
    "objectID": "tutorials/docs-10-using-turing-autodiff/index.html#switching-ad-modes",
    "href": "tutorials/docs-10-using-turing-autodiff/index.html#switching-ad-modes",
    "title": "Automatic Differentiation",
    "section": "",
    "text": "Turing currently supports four automatic differentiation (AD) backends for sampling: ForwardDiff for forward-mode AD; and ReverseDiff, Zygote, and Tracker for reverse-mode AD. While Tracker is still available, its use is discouraged due to a lack of active maintenance. ForwardDiff is automatically imported by Turing. To utilize Zygote or ReverseDiff for AD, users must explicitly import them with using Zygote or using ReverseDiff, alongside using Turing.\nAs of Turing version v0.30, the global configuration flag for the AD backend has been removed in favour of AdTypes.jl, allowing users to specify the AD backend for individual samplers independently. Users can pass the adtype keyword argument to the sampler constructor to select the desired AD backend, with the default being AutoForwardDiff(; chunksize=0).\nFor ForwardDiff, pass adtype=AutoForwardDiff(; chunksize) to the sampler constructor. A chunksize of 0 permits the chunk size to be automatically determined. For more information regarding the selection of chunksize, please refer to related section of ForwardDiff’s documentation. For ReverseDiff, pass adtype=AutoReverseDiff() to the sampler constructor. An additional argument can be provided to AutoReverseDiff to specify whether to to compile the tape only once and cache it for later use (false by default, which means no caching tape). Be aware that the use of caching in certain types of models can lead to incorrect results and/or errors.\nCompiled tapes should only be used if you are absolutely certain that the computation doesn’t change between different executions of your model. Thus, e.g., in the model definition and all im- and explicitly called functions in the model all loops should be of fixed size, and if-statements should consistently execute the same branches. For instance, if-statements with conditions that can be determined at compile time or conditions that depend only on the data will always execute the same branches during sampling (if the data is constant throughout sampling and, e.g., no mini-batching is used). However, if-statements that depend on the model parameters can take different branches during sampling; hence, the compiled tape might be incorrect. Thus you must not use compiled tapes when your model makes decisions based on the model parameters, and you should be careful if you compute functions of parameters that those functions do not have branching which might cause them to execute different code for different values of the parameter.\nFor Zygote, pass adtype=AutoZygote() to the sampler constructor.\nAnd the previously used interface functions including ADBackend, setadbackend, setsafe, setchunksize, and setrdcache are deprecated and removed.",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Automatic Differentiation"
    ]
  },
  {
    "objectID": "tutorials/docs-10-using-turing-autodiff/index.html#compositional-sampling-with-differing-ad-modes",
    "href": "tutorials/docs-10-using-turing-autodiff/index.html#compositional-sampling-with-differing-ad-modes",
    "title": "Automatic Differentiation",
    "section": "Compositional Sampling with Differing AD Modes",
    "text": "Compositional Sampling with Differing AD Modes\nTuring supports intermixed automatic differentiation methods for different variable spaces. The snippet below shows using ForwardDiff to sample the mean (m) parameter, and using ReverseDiff for the variance (s) parameter:\n\nusing Turing\nusing ReverseDiff\n\n# Define a simple Normal model with unknown mean and variance.\n@model function gdemo(x, y)\n    s² ~ InverseGamma(2, 3)\n    m ~ Normal(0, sqrt(s²))\n    x ~ Normal(m, sqrt(s²))\n    return y ~ Normal(m, sqrt(s²))\nend\n\n# Sample using Gibbs and varying autodiff backends.\nc = sample(\n    gdemo(1.5, 2),\n    Gibbs(\n        HMC(0.1, 5, :m; adtype=AutoForwardDiff(; chunksize=0)),\n        HMC(0.1, 5, :s²; adtype=AutoReverseDiff(false)),\n    ),\n    1000,\n    progress=false,\n)\n\nChains MCMC chain (1000×3×1 Array{Float64, 3}):\n\nIterations        = 1:1:1000\nNumber of chains  = 1\nSamples per chain = 1000\nWall duration     = 9.41 seconds\nCompute duration  = 9.41 seconds\nparameters        = s², m\ninternals         = lp\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n          s²    2.1530    3.0560    0.2660   138.2387   171.9678    1.0006     ⋯\n           m    1.1106    0.7948    0.1041    74.2186    47.6366    1.0212     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n          s²    0.5298    0.9358    1.3654    2.2197    9.2090\n           m   -0.4223    0.6392    1.0667    1.5179    2.9079\n\n\nGenerally, reverse-mode AD, for instance ReverseDiff, is faster when sampling from variables of high dimensionality (greater than 20), while forward-mode AD, for instance ForwardDiff, is more efficient for lower-dimension variables. This functionality allows those who are performance sensitive to fine tune their automatic differentiation for their specific models.\nIf the differentiation method is not specified in this way, Turing will default to using whatever the global AD backend is. Currently, this defaults to ForwardDiff.",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Automatic Differentiation"
    ]
  },
  {
    "objectID": "tutorials/04-hidden-markov-model/index.html",
    "href": "tutorials/04-hidden-markov-model/index.html",
    "title": "Bayesian Hidden Markov Models",
    "section": "",
    "text": "This tutorial illustrates training Bayesian Hidden Markov Models (HMM) using Turing. The main goals are learning the transition matrix, emission parameter, and hidden states. For a more rigorous academic overview on Hidden Markov Models, see An introduction to Hidden Markov Models and Bayesian Networks (Ghahramani, 2001).\nIn this tutorial, we assume there are \\(k\\) discrete hidden states; the observations are continuous and normally distributed - centered around the hidden states. This assumption reduces the number of parameters to be estimated in the emission matrix.\nLet’s load the libraries we’ll need. We also set a random seed (for reproducibility) and the automatic differentiation backend to forward mode (more here on why this is useful).\n# Load libraries.\nusing Turing, StatsPlots, Random\n\n# Set a random seed and use the forward_diff AD mode.\nRandom.seed!(12345678);",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Hidden Markov Models"
    ]
  },
  {
    "objectID": "tutorials/04-hidden-markov-model/index.html#simple-state-detection",
    "href": "tutorials/04-hidden-markov-model/index.html#simple-state-detection",
    "title": "Bayesian Hidden Markov Models",
    "section": "Simple State Detection",
    "text": "Simple State Detection\nIn this example, we’ll use something where the states and emission parameters are straightforward.\n\n# Define the emission parameter.\ny = [\n    1.0,\n    1.0,\n    1.0,\n    1.0,\n    1.0,\n    1.0,\n    2.0,\n    2.0,\n    2.0,\n    2.0,\n    2.0,\n    2.0,\n    3.0,\n    3.0,\n    3.0,\n    3.0,\n    3.0,\n    3.0,\n    3.0,\n    2.0,\n    2.0,\n    2.0,\n    2.0,\n    1.0,\n    1.0,\n    1.0,\n    1.0,\n    1.0,\n    1.0,\n    1.0,\n];\nN = length(y);\nK = 3;\n\n# Plot the data we just made.\nplot(y; xlim=(0, 30), ylim=(-1, 5), size=(500, 250))\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can see that we have three states, one for each height of the plot (1, 2, 3). This height is also our emission parameter, so state one produces a value of one, state two produces a value of two, and so on.\nUltimately, we would like to understand three major parameters:\n\nThe transition matrix. This is a matrix that assigns a probability of switching from one state to any other state, including the state that we are already in.\nThe emission matrix, which describes a typical value emitted by some state. In the plot above, the emission parameter for state one is simply one.\nThe state sequence is our understanding of what state we were actually in when we observed some data. This is very important in more sophisticated HMM models, where the emission value does not equal our state.\n\nWith this in mind, let’s set up our model. We are going to use some of our knowledge as modelers to provide additional information about our system. This takes the form of the prior on our emission parameter.\n\\[\nm_i \\sim \\mathrm{Normal}(i, 0.5) \\quad \\text{where} \\quad m = \\{1,2,3\\}\n\\]\nSimply put, this says that we expect state one to emit values in a Normally distributed manner, where the mean of each state’s emissions is that state’s value. The variance of 0.5 helps the model converge more quickly — consider the case where we have a variance of 1 or 2. In this case, the likelihood of observing a 2 when we are in state 1 is actually quite high, as it is within a standard deviation of the true emission value. Applying the prior that we are likely to be tightly centered around the mean prevents our model from being too confused about the state that is generating our observations.\nThe priors on our transition matrix are noninformative, using T[i] ~ Dirichlet(ones(K)/K). The Dirichlet prior used in this way assumes that the state is likely to change to any other state with equal probability. As we’ll see, this transition matrix prior will be overwritten as we observe data.\n\n# Turing model definition.\n@model function BayesHmm(y, K)\n    # Get observation length.\n    N = length(y)\n\n    # State sequence.\n    s = tzeros(Int, N)\n\n    # Emission matrix.\n    m = Vector(undef, K)\n\n    # Transition matrix.\n    T = Vector{Vector}(undef, K)\n\n    # Assign distributions to each element\n    # of the transition matrix and the\n    # emission matrix.\n    for i in 1:K\n        T[i] ~ Dirichlet(ones(K) / K)\n        m[i] ~ Normal(i, 0.5)\n    end\n\n    # Observe each point of the input.\n    s[1] ~ Categorical(K)\n    y[1] ~ Normal(m[s[1]], 0.1)\n\n    for i in 2:N\n        s[i] ~ Categorical(vec(T[s[i - 1]]))\n        y[i] ~ Normal(m[s[i]], 0.1)\n    end\nend;\n\nWe will use a combination of two samplers (HMC and Particle Gibbs) by passing them to the Gibbs sampler. The Gibbs sampler allows for compositional inference, where we can utilize different samplers on different parameters.\nIn this case, we use HMC for m and T, representing the emission and transition matrices respectively. We use the Particle Gibbs sampler for s, the state sequence. You may wonder why it is that we are not assigning s to the HMC sampler, and why it is that we need compositional Gibbs sampling at all.\nThe parameter s is not a continuous variable. It is a vector of integers, and thus Hamiltonian methods like HMC and NUTS won’t work correctly. Gibbs allows us to apply the right tools to the best effect. If you are a particularly advanced user interested in higher performance, you may benefit from setting up your Gibbs sampler to use different automatic differentiation backends for each parameter space.\nTime to run our sampler.\n\nsetprogress!(false)\n\n\ng = Gibbs(HMC(0.01, 50, :m, :T), PG(120, :s))\nchn = sample(BayesHmm(y, 3), g, 1000);\n\nLet’s see how well our chain performed. Ordinarily, using display(chn) would be a good first step, but we have generated a lot of parameters here (s[1], s[2], m[1], and so on). It’s a bit easier to show how our model performed graphically.\nThe code below generates an animation showing the graph of the data above, and the data our model generates in each sample.\n\n# Extract our m and s parameters from the chain.\nm_set = MCMCChains.group(chn, :m).value\ns_set = MCMCChains.group(chn, :s).value\n\n# Iterate through the MCMC samples.\nNs = 1:length(chn)\n\n# Make an animation.\nanimation = @gif for i in Ns\n    m = m_set[i, :]\n    s = Int.(s_set[i, :])\n    emissions = m[s]\n\n    p = plot(\n        y;\n        chn=:red,\n        size=(500, 250),\n        xlabel=\"Time\",\n        ylabel=\"State\",\n        legend=:topright,\n        label=\"True data\",\n        xlim=(0, 30),\n        ylim=(-1, 5),\n    )\n    plot!(emissions; color=:blue, label=\"Sample $i\")\nend every 3\n\n[ Info: Saved animation to /tmp/jl_fiXI3g92hQ.gif\n\n\n\n\n\nLooks like our model did a pretty good job, but we should also check to make sure our chain converges. A quick check is to examine whether the diagonal (representing the probability of remaining in the current state) of the transition matrix appears to be stationary. The code below extracts the diagonal and shows a traceplot of each persistence probability.\n\n# Index the chain with the persistence probabilities.\nsubchain = chn[[\"T[1][1]\", \"T[2][2]\", \"T[3][3]\"]]\n\nplot(subchain; seriestype=:traceplot, title=\"Persistence Probability\", legend=false)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA cursory examination of the traceplot above indicates that all three chains converged to something resembling stationary. We can use the diagnostic functions provided by MCMCChains to engage in some more formal tests, like the Heidelberg and Welch diagnostic:\n\nheideldiag(MCMCChains.group(chn, :T))[1]\n\nHeidelberger and Welch diagnostic - Chain 1\n  parameters     burnin   stationarity    pvalue      mean   halfwidth     tes ⋯\n      Symbol      Int64           Bool   Float64   Float64     Float64     Boo ⋯\n\n     T[1][1]     0.0000         1.0000    0.7177    0.7874      0.0256   1.000 ⋯\n     T[1][2]     0.0000         1.0000    0.6144    0.1576      0.0325   0.000 ⋯\n     T[1][3]     0.0000         1.0000    0.4103    0.0550      0.0247   0.000 ⋯\n     T[2][1]   100.0000         1.0000    0.1292    0.1168      0.0246   0.000 ⋯\n     T[2][2]     0.0000         1.0000    0.2970    0.7508      0.0327   1.000 ⋯\n     T[2][3]     0.0000         1.0000    0.0829    0.1221      0.0231   0.000 ⋯\n     T[3][1]     0.0000         1.0000    0.1454    0.0424      0.0182   0.000 ⋯\n     T[3][2]     0.0000         1.0000    0.3906    0.1068      0.0200   0.000 ⋯\n     T[3][3]     0.0000         1.0000    0.2030    0.8508      0.0278   1.000 ⋯\n                                                                1 column omitted\n\n\nThe p-values on the test suggest that we cannot reject the hypothesis that the observed sequence comes from a stationary distribution, so we can be reasonably confident that our transition matrix has converged to something reasonable.",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Hidden Markov Models"
    ]
  },
  {
    "objectID": "tutorials/10-bayesian-differential-equations/index.html",
    "href": "tutorials/10-bayesian-differential-equations/index.html",
    "title": "Bayesian Estimation of Differential Equations",
    "section": "",
    "text": "Most of the scientific community deals with the basic problem of trying to mathematically model the reality around them and this often involves dynamical systems. The general trend to model these complex dynamical systems is through the use of differential equations. Differential equation models often have non-measurable parameters. The popular “forward-problem” of simulation consists of solving the differential equations for a given set of parameters, the “inverse problem” to simulation, known as parameter estimation, is the process of utilizing data to determine these model parameters. Bayesian inference provides a robust approach to parameter estimation with quantified uncertainty.\nusing Turing\nusing DifferentialEquations\n\n# Load StatsPlots for visualizations and diagnostics.\nusing StatsPlots\n\nusing LinearAlgebra\n\n# Set a seed for reproducibility.\nusing Random\nRandom.seed!(14);",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Bayesian Differential Equations"
    ]
  },
  {
    "objectID": "tutorials/10-bayesian-differential-equations/index.html#the-lotka-volterra-model",
    "href": "tutorials/10-bayesian-differential-equations/index.html#the-lotka-volterra-model",
    "title": "Bayesian Estimation of Differential Equations",
    "section": "The Lotka-Volterra Model",
    "text": "The Lotka-Volterra Model\nThe Lotka–Volterra equations, also known as the predator–prey equations, are a pair of first-order nonlinear differential equations. These differential equations are frequently used to describe the dynamics of biological systems in which two species interact, one as a predator and the other as prey. The populations change through time according to the pair of equations\n\\[\n\\begin{aligned}\n\\frac{\\mathrm{d}x}{\\mathrm{d}t} &= (\\alpha - \\beta y(t))x(t), \\\\\n\\frac{\\mathrm{d}y}{\\mathrm{d}t} &= (\\delta x(t) - \\gamma)y(t)\n\\end{aligned}\n\\]\nwhere \\(x(t)\\) and \\(y(t)\\) denote the populations of prey and predator at time \\(t\\), respectively, and \\(\\alpha, \\beta, \\gamma, \\delta\\) are positive parameters.\nWe implement the Lotka-Volterra model and simulate it with parameters \\(\\alpha = 1.5\\), \\(\\beta = 1\\), \\(\\gamma = 3\\), and \\(\\delta = 1\\) and initial conditions \\(x(0) = y(0) = 1\\).\n\n# Define Lotka-Volterra model.\nfunction lotka_volterra(du, u, p, t)\n    # Model parameters.\n    α, β, γ, δ = p\n    # Current state.\n    x, y = u\n\n    # Evaluate differential equations.\n    du[1] = (α - β * y) * x # prey\n    du[2] = (δ * x - γ) * y # predator\n\n    return nothing\nend\n\n# Define initial-value problem.\nu0 = [1.0, 1.0]\np = [1.5, 1.0, 3.0, 1.0]\ntspan = (0.0, 10.0)\nprob = ODEProblem(lotka_volterra, u0, tspan, p)\n\n# Plot simulation.\nplot(solve(prob, Tsit5()))\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe generate noisy observations to use for the parameter estimation tasks in this tutorial. With the saveat argument we specify that the solution is stored only at 0.1 time units. To make the example more realistic we add random normally distributed noise to the simulation.\n\nsol = solve(prob, Tsit5(); saveat=0.1)\nodedata = Array(sol) + 0.8 * randn(size(Array(sol)))\n\n# Plot simulation and noisy observations.\nplot(sol; alpha=0.3)\nscatter!(sol.t, odedata'; color=[1 2], label=\"\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlternatively, we can use real-world data from Hudson’s Bay Company records (an Stan implementation with slightly different priors can be found here: https://mc-stan.org/users/documentation/case-studies/lotka-volterra-predator-prey.html).",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Bayesian Differential Equations"
    ]
  },
  {
    "objectID": "tutorials/10-bayesian-differential-equations/index.html#direct-handling-of-bayesian-estimation-with-turing",
    "href": "tutorials/10-bayesian-differential-equations/index.html#direct-handling-of-bayesian-estimation-with-turing",
    "title": "Bayesian Estimation of Differential Equations",
    "section": "Direct Handling of Bayesian Estimation with Turing",
    "text": "Direct Handling of Bayesian Estimation with Turing\nPreviously, functions in Turing and DifferentialEquations were not inter-composable, so Bayesian inference of differential equations needed to be handled by another package called DiffEqBayes.jl (note that DiffEqBayes works also with CmdStan.jl, Turing.jl, DynamicHMC.jl and ApproxBayes.jl - see the DiffEqBayes docs for more info).\nNowadays, however, Turing and DifferentialEquations are completely composable and we can just simulate differential equations inside a Turing @model. Therefore, we write the Lotka-Volterra parameter estimation problem using the Turing @model macro as below:\n\n@model function fitlv(data, prob)\n    # Prior distributions.\n    σ ~ InverseGamma(2, 3)\n    α ~ truncated(Normal(1.5, 0.5); lower=0.5, upper=2.5)\n    β ~ truncated(Normal(1.2, 0.5); lower=0, upper=2)\n    γ ~ truncated(Normal(3.0, 0.5); lower=1, upper=4)\n    δ ~ truncated(Normal(1.0, 0.5); lower=0, upper=2)\n\n    # Simulate Lotka-Volterra model. \n    p = [α, β, γ, δ]\n    predicted = solve(prob, Tsit5(); p=p, saveat=0.1)\n\n    # Observations.\n    for i in 1:length(predicted)\n        data[:, i] ~ MvNormal(predicted[i], σ^2 * I)\n    end\n\n    return nothing\nend\n\nmodel = fitlv(odedata, prob)\n\n# Sample 3 independent chains with forward-mode automatic differentiation (the default).\nchain = sample(model, NUTS(), MCMCSerial(), 1000, 3; progress=false)\n\n┌ Info: Found initial step size\n└   ϵ = 0.0125\n┌ Info: Found initial step size\n└   ϵ = 0.003125\n┌ Info: Found initial step size\n└   ϵ = 0.00625\n\n\nChains MCMC chain (1000×17×3 Array{Float64, 3}):\n\nIterations        = 501:1:1500\nNumber of chains  = 3\nSamples per chain = 1000\nWall duration     = 58.28 seconds\nCompute duration  = 55.73 seconds\nparameters        = σ, α, β, γ, δ\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n  parameters      mean       std      mcse    ess_bulk    ess_tail      rhat   ⋯\n      Symbol   Float64   Float64   Float64     Float64     Float64   Float64   ⋯\n\n           σ    0.7813    0.0391    0.0009   1729.3117   1628.9096    0.9997   ⋯\n           α    1.5719    0.0486    0.0018    706.2931    945.4389    1.0024   ⋯\n           β    1.0534    0.0475    0.0015    959.2037   1226.3676    1.0012   ⋯\n           γ    2.8456    0.1257    0.0047    729.7780    945.7870    1.0022   ⋯\n           δ    0.9275    0.0446    0.0017    726.2614   1021.9235    1.0030   ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n           σ    0.7111    0.7538    0.7790    0.8062    0.8626\n           α    1.4814    1.5384    1.5697    1.6044    1.6715\n           β    0.9682    1.0206    1.0507    1.0842    1.1535\n           γ    2.6063    2.7609    2.8461    2.9305    3.0859\n           δ    0.8440    0.8960    0.9271    0.9570    1.0170\n\n\nThe estimated parameters are close to the parameter values the observations were generated with. We can also check visually that the chains have converged.\n\nplot(chain)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData retrodiction\nIn Bayesian analysis it is often useful to retrodict the data, i.e. generate simulated data using samples from the posterior distribution, and compare to the original data (see for instance section 3.3.2 - model checking of McElreath’s book “Statistical Rethinking”). Here, we solve the ODE for 300 randomly picked posterior samples in the chain. We plot the ensemble of solutions to check if the solution resembles the data. The 300 retrodicted time courses from the posterior are plotted in gray, the noisy observations are shown as blue and red dots, and the green and purple lines are the ODE solution that was used to generate the data.\n\nplot(; legend=false)\nposterior_samples = sample(chain[[:α, :β, :γ, :δ]], 300; replace=false)\nfor p in eachrow(Array(posterior_samples))\n    sol_p = solve(prob, Tsit5(); p=p, saveat=0.1)\n    plot!(sol_p; alpha=0.1, color=\"#BBBBBB\")\nend\n\n# Plot simulation and noisy observations.\nplot!(sol; color=[1 2], linewidth=1)\nscatter!(sol.t, odedata'; color=[1 2])\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can see that, even though we added quite a bit of noise to the data the posterior distribution reproduces quite accurately the “true” ODE solution.",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Bayesian Differential Equations"
    ]
  },
  {
    "objectID": "tutorials/10-bayesian-differential-equations/index.html#lotka-volterra-model-without-data-of-prey",
    "href": "tutorials/10-bayesian-differential-equations/index.html#lotka-volterra-model-without-data-of-prey",
    "title": "Bayesian Estimation of Differential Equations",
    "section": "Lotka-Volterra model without data of prey",
    "text": "Lotka-Volterra model without data of prey\nOne can also perform parameter inference for a Lotka-Volterra model with incomplete data. For instance, let us suppose we have only observations of the predators but not of the prey. I.e., we fit the model only to the \\(y\\) variable of the system without providing any data for \\(x\\):\n\n@model function fitlv2(data::AbstractVector, prob)\n    # Prior distributions.\n    σ ~ InverseGamma(2, 3)\n    α ~ truncated(Normal(1.5, 0.5); lower=0.5, upper=2.5)\n    β ~ truncated(Normal(1.2, 0.5); lower=0, upper=2)\n    γ ~ truncated(Normal(3.0, 0.5); lower=1, upper=4)\n    δ ~ truncated(Normal(1.0, 0.5); lower=0, upper=2)\n\n    # Simulate Lotka-Volterra model but save only the second state of the system (predators).\n    p = [α, β, γ, δ]\n    predicted = solve(prob, Tsit5(); p=p, saveat=0.1, save_idxs=2)\n\n    # Observations of the predators.\n    data ~ MvNormal(predicted.u, σ^2 * I)\n\n    return nothing\nend\n\nmodel2 = fitlv2(odedata[2, :], prob)\n\n# Sample 3 independent chains.\nchain2 = sample(model2, NUTS(0.45), MCMCSerial(), 5000, 3; progress=false)\n\n┌ Info: Found initial step size\n└   ϵ = 0.0125\n┌ Info: Found initial step size\n└   ϵ = 0.025\n┌ Info: Found initial step size\n└   ϵ = 0.2\n\n\nChains MCMC chain (5000×17×3 Array{Float64, 3}):\n\nIterations        = 1001:1:6000\nNumber of chains  = 3\nSamples per chain = 5000\nWall duration     = 35.2 seconds\nCompute duration  = 34.63 seconds\nparameters        = σ, α, β, γ, δ\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n           σ    0.7854    0.0636    0.0065    90.8687   109.8482    1.0418     ⋯\n           α    1.4888    0.1848    0.0197    89.1286   173.6519    1.0422     ⋯\n           β    0.9847    0.1334    0.0140    90.5260   196.3729    1.0380     ⋯\n           γ    2.9398    0.3119    0.0317    97.7061   205.8431    1.0391     ⋯\n           δ    1.1022    0.2714    0.0289    89.0788   163.0496    1.0420     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n           σ    0.6748    0.7375    0.7810    0.8306    0.9133\n           α    1.1662    1.3591    1.4617    1.5975    1.8881\n           β    0.7558    0.8897    0.9653    1.0663    1.2808\n           γ    2.3638    2.7227    2.9445    3.1589    3.5720\n           δ    0.6165    0.9130    1.1048    1.2734    1.7132\n\n\nAgain we inspect the trajectories of 300 randomly selected posterior samples.\n\nplot(; legend=false)\nposterior_samples = sample(chain2[[:α, :β, :γ, :δ]], 300; replace=false)\nfor p in eachrow(Array(posterior_samples))\n    sol_p = solve(prob, Tsit5(); p=p, saveat=0.1)\n    plot!(sol_p; alpha=0.1, color=\"#BBBBBB\")\nend\n\n# Plot simulation and noisy observations.\nplot!(sol; color=[1 2], linewidth=1)\nscatter!(sol.t, odedata'; color=[1 2])\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote that here the observations of the prey (blue dots) were not used in the parameter estimation! Yet, the model can predict the values of \\(x\\) relatively accurately, albeit with a wider distribution of solutions, reflecting the greater uncertainty in the prediction of the \\(x\\) values.",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Bayesian Differential Equations"
    ]
  },
  {
    "objectID": "tutorials/10-bayesian-differential-equations/index.html#inference-of-delay-differential-equations",
    "href": "tutorials/10-bayesian-differential-equations/index.html#inference-of-delay-differential-equations",
    "title": "Bayesian Estimation of Differential Equations",
    "section": "Inference of Delay Differential Equations",
    "text": "Inference of Delay Differential Equations\nHere we show an example of inference with another type of differential equation: a Delay Differential Equation (DDE). DDEs are differential equations where derivatives are function of values at an earlier point in time. This is useful to model a delayed effect, like incubation time of a virus for instance.\nHere is a delayed version of the Lokta-Voltera system:\n\\[\n\\begin{aligned}\n\\frac{\\mathrm{d}x}{\\mathrm{d}t} &= \\alpha x(t-\\tau) - \\beta y(t) x(t),\\\\\n\\frac{\\mathrm{d}y}{\\mathrm{d}t} &= - \\gamma y(t) + \\delta x(t) y(t),\n\\end{aligned}\n\\]\nwhere \\(\\tau\\) is a (positive) delay and \\(x(t-\\tau)\\) is the variable \\(x\\) at an earlier time point \\(t - \\tau\\).\nThe initial-value problem of the delayed system can be implemented as a DDEProblem. As described in the DDE example, here the function h is the history function that can be used to obtain a state at an earlier time point. Again we use parameters \\(\\alpha = 1.5\\), \\(\\beta = 1\\), \\(\\gamma = 3\\), and \\(\\delta = 1\\) and initial conditions \\(x(0) = y(0) = 1\\). Moreover, we assume \\(x(t) = 1\\) for \\(t &lt; 0\\).\n\nfunction delay_lotka_volterra(du, u, h, p, t)\n    # Model parameters.\n    α, β, γ, δ = p\n\n    # Current state.\n    x, y = u\n    # Evaluate differential equations\n    du[1] = α * h(p, t - 1; idxs=1) - β * x * y\n    du[2] = -γ * y + δ * x * y\n\n    return nothing\nend\n\n# Define initial-value problem.\np = (1.5, 1.0, 3.0, 1.0)\nu0 = [1.0; 1.0]\ntspan = (0.0, 10.0)\nh(p, t; idxs::Int) = 1.0\nprob_dde = DDEProblem(delay_lotka_volterra, u0, h, tspan, p);\n\nWe generate observations by adding normally distributed noise to the results of our simulations.\n\nsol_dde = solve(prob_dde; saveat=0.1)\nddedata = Array(sol_dde) + 0.5 * randn(size(sol_dde))\n\n# Plot simulation and noisy observations.\nplot(sol_dde)\nscatter!(sol_dde.t, ddedata'; color=[1 2], label=\"\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow we define the Turing model for the Lotka-Volterra model with delay and sample 3 independent chains.\n\n@model function fitlv_dde(data, prob)\n    # Prior distributions.\n    σ ~ InverseGamma(2, 3)\n    α ~ truncated(Normal(1.5, 0.5); lower=0.5, upper=2.5)\n    β ~ truncated(Normal(1.2, 0.5); lower=0, upper=2)\n    γ ~ truncated(Normal(3.0, 0.5); lower=1, upper=4)\n    δ ~ truncated(Normal(1.0, 0.5); lower=0, upper=2)\n\n    # Simulate Lotka-Volterra model.\n    p = [α, β, γ, δ]\n    predicted = solve(prob, MethodOfSteps(Tsit5()); p=p, saveat=0.1)\n\n    # Observations.\n    for i in 1:length(predicted)\n        data[:, i] ~ MvNormal(predicted[i], σ^2 * I)\n    end\nend\n\nmodel_dde = fitlv_dde(ddedata, prob_dde)\n\n# Sample 3 independent chains.\nchain_dde = sample(model_dde, NUTS(), MCMCSerial(), 300, 3; progress=false)\n\n┌ Info: Found initial step size\n└   ϵ = 0.2\n┌ Info: Found initial step size\n└   ϵ = 0.00625\n┌ Info: Found initial step size\n└   ϵ = 0.4\n\n\nChains MCMC chain (300×17×3 Array{Float64, 3}):\n\nIterations        = 151:1:450\nNumber of chains  = 3\nSamples per chain = 300\nWall duration     = 16.15 seconds\nCompute duration  = 15.76 seconds\nparameters        = σ, α, β, γ, δ\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n           σ    0.4570    0.0232    0.0010   521.3150   596.4227    1.0105     ⋯\n           α    1.5148    0.0618    0.0048   178.7667   188.8637    1.0166     ⋯\n           β    1.0071    0.0471    0.0036   201.0449   114.6764    1.0100     ⋯\n           γ    2.9918    0.1363    0.0093   214.9657   360.4828    1.0117     ⋯\n           δ    1.0055    0.0479    0.0033   212.2450   369.4137    1.0109     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n           σ    0.4177    0.4396    0.4568    0.4734    0.5027\n           α    1.4045    1.4713    1.5087    1.5561    1.6455\n           β    0.9226    0.9744    1.0019    1.0361    1.1032\n           γ    2.7414    2.8967    2.9922    3.0841    3.2628\n           δ    0.9193    0.9719    1.0068    1.0370    1.1085\n\n\n\nplot(chain_dde)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinally, plot trajectories of 300 randomly selected samples from the posterior. Again, the dots indicate our observations, the colored lines are the “true” simulations without noise, and the gray lines are trajectories from the posterior samples.\n\nplot(; legend=false)\nposterior_samples = sample(chain_dde[[:α, :β, :γ, :δ]], 300; replace=false)\nfor p in eachrow(Array(posterior_samples))\n    sol_p = solve(prob_dde, MethodOfSteps(Tsit5()); p=p, saveat=0.1)\n    plot!(sol_p; alpha=0.1, color=\"#BBBBBB\")\nend\n\n# Plot simulation and noisy observations.\nplot!(sol_dde; color=[1 2], linewidth=1)\nscatter!(sol_dde.t, ddedata'; color=[1 2])\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe fit is pretty good even though the data was quite noisy to start.",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Bayesian Differential Equations"
    ]
  },
  {
    "objectID": "tutorials/10-bayesian-differential-equations/index.html#scaling-to-large-models-adjoint-sensitivities",
    "href": "tutorials/10-bayesian-differential-equations/index.html#scaling-to-large-models-adjoint-sensitivities",
    "title": "Bayesian Estimation of Differential Equations",
    "section": "Scaling to Large Models: Adjoint Sensitivities",
    "text": "Scaling to Large Models: Adjoint Sensitivities\nDifferentialEquations.jl’s efficiency for large stiff models has been shown in multiple benchmarks. To learn more about how to optimize solving performance for stiff problems you can take a look at the docs.\nSensitivity analysis, or automatic differentiation (AD) of the solver, is provided by the DiffEq suite. The model sensitivities are the derivatives of the solution with respect to the parameters. Specifically, the local sensitivity of the solution to a parameter is defined by how much the solution would change by changes in the parameter. Sensitivity analysis provides a cheap way to calculate the gradient of the solution which can be used in parameter estimation and other optimization tasks.\nThe AD ecosystem in Julia allows you to switch between forward mode, reverse mode, source to source and other choices of AD and have it work with any Julia code. For a user to make use of this within SciML, high level interactions in solve automatically plug into those AD systems to allow for choosing advanced sensitivity analysis (derivative calculation) methods.\nMore theoretical details on these methods can be found at: https://docs.sciml.ai/latest/extras/sensitivity_math/.\nWhile these sensitivity analysis methods may seem complicated, using them is dead simple. Here is a version of the Lotka-Volterra model using adjoint sensitivities.\nAll we have to do is switch the AD backend to one of the adjoint-compatible backends (ReverseDiff, Tracker, or Zygote)! Notice that on this model adjoints are slower. This is because adjoints have a higher overhead on small parameter models and therefore we suggest using these methods only for models with around 100 parameters or more. For more details, see https://arxiv.org/abs/1812.01892.\n\nusing Zygote, SciMLSensitivity\n\n# Sample a single chain with 1000 samples using Zygote.\nsample(model, NUTS(;adtype=AutoZygote()), 1000; progress=false)\n\n┌ Info: Found initial step size\n└   ϵ = 0.2\n\n\nChains MCMC chain (1000×17×1 Array{Float64, 3}):\n\nIterations        = 501:1:1500\nNumber of chains  = 1\nSamples per chain = 1000\nWall duration     = 806.77 seconds\nCompute duration  = 806.77 seconds\nparameters        = σ, α, β, γ, δ\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n           σ    0.7836    0.0386    0.0016   632.0958   660.7247    0.9991     ⋯\n           α    1.5748    0.0467    0.0035   174.5157   440.8143    1.0123     ⋯\n           β    1.0542    0.0439    0.0025   326.2660   456.9696    1.0021     ⋯\n           γ    2.8372    0.1218    0.0092   178.3343   415.2192    1.0134     ⋯\n           δ    0.9244    0.0429    0.0032   182.3141   442.9656    1.0121     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n           σ    0.7158    0.7558    0.7815    0.8083    0.8691\n           α    1.4853    1.5425    1.5751    1.6049    1.6695\n           β    0.9744    1.0242    1.0538    1.0840    1.1385\n           γ    2.6025    2.7562    2.8303    2.9184    3.0749\n           δ    0.8456    0.8948    0.9212    0.9523    1.0156\n\n\nIf desired, we can control the sensitivity analysis method that is used by providing the sensealg keyword argument to solve. Here we will not choose a sensealg and let it use the default choice:\n\n@model function fitlv_sensealg(data, prob)\n    # Prior distributions.\n    σ ~ InverseGamma(2, 3)\n    α ~ truncated(Normal(1.5, 0.5); lower=0.5, upper=2.5)\n    β ~ truncated(Normal(1.2, 0.5); lower=0, upper=2)\n    γ ~ truncated(Normal(3.0, 0.5); lower=1, upper=4)\n    δ ~ truncated(Normal(1.0, 0.5); lower=0, upper=2)\n\n    # Simulate Lotka-Volterra model and use a specific algorithm for computing sensitivities.\n    p = [α, β, γ, δ]\n    predicted = solve(prob; p=p, saveat=0.1)\n\n    # Observations.\n    for i in 1:length(predicted)\n        data[:, i] ~ MvNormal(predicted[i], σ^2 * I)\n    end\n\n    return nothing\nend;\n\nmodel_sensealg = fitlv_sensealg(odedata, prob)\n\n# Sample a single chain with 1000 samples using Zygote.\nsample(model_sensealg, NUTS(;adtype=AutoZygote()), 1000; progress=false)\n\n┌ Info: Found initial step size\n└   ϵ = 0.025\n\n\nChains MCMC chain (1000×17×1 Array{Float64, 3}):\n\nIterations        = 501:1:1500\nNumber of chains  = 1\nSamples per chain = 1000\nWall duration     = 399.14 seconds\nCompute duration  = 399.14 seconds\nparameters        = σ, α, β, γ, δ\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n           σ    2.0680    0.0972    0.0046   459.0357   465.8591    1.0045     ⋯\n           α    1.2490    0.1064    0.0122   126.7419    50.9685    1.0010     ⋯\n           β    0.8494    0.1092    0.0069   240.3773   133.0866    0.9998     ⋯\n           γ    1.1117    0.1344    0.0170   113.7367    65.0497    1.0058     ⋯\n           δ    0.5567    0.0829    0.0100   133.9614    52.5477    1.0014     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n           σ    1.8912    2.0015    2.0605    2.1328    2.2531\n           α    0.9591    1.2022    1.2711    1.3215    1.3998\n           β    0.6471    0.7791    0.8472    0.9133    1.0943\n           γ    1.0014    1.0279    1.0692    1.1418    1.5421\n           δ    0.4560    0.5019    0.5400    0.5837    0.7970\n\n\nFor more examples of adjoint usage on large parameter models, consult the DiffEqFlux documentation.",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Bayesian Differential Equations"
    ]
  },
  {
    "objectID": "tutorials/docs-16-using-turing-external-samplers/index.html",
    "href": "tutorials/docs-16-using-turing-external-samplers/index.html",
    "title": "Using External Samplers",
    "section": "",
    "text": "Turing provides several wrapped samplers from external sampling libraries, e.g., HMC samplers from AdvancedHMC. These wrappers allow new users to seamlessly sample statistical models without leaving Turing However, these wrappers might only sometimes be complete, missing some functionality from the wrapped sampling library. Moreover, users might want to use samplers currently not wrapped within Turing.\nFor these reasons, Turing also makes running external samplers on Turing models easy without any necessary modifications or wrapping! Throughout, we will use a 10-dimensional Neal’s funnel as a running example::\n\n# Import libraries.\nusing Turing, Random, LinearAlgebra\n\nd = 10\n@model function funnel()\n    θ ~ Truncated(Normal(0, 3), -3, 3)\n    z ~ MvNormal(zeros(d - 1), exp(θ) * I)\n    return x ~ MvNormal(z, I)\nend\n\nfunnel (generic function with 2 methods)\n\n\nNow we sample the model to generate some observations, which we can then condition on.\n\n(; x) = rand(funnel() | (θ=0,))\nmodel = funnel() | (; x);\n\nUsers can use any sampler algorithm to sample this model if it follows the AbstractMCMC API. Before discussing how this is done in practice, giving a high-level description of the process is interesting. Imagine that we created an instance of an external sampler that we will call spl such that typeof(spl)&lt;:AbstractMCMC.AbstractSampler. In order to avoid type ambiguity within Turing, at the moment it is necessary to declare spl as an external sampler to Turing espl = externalsampler(spl), where externalsampler(s::AbstractMCMC.AbstractSampler) is a Turing function that types our external sampler adequately.\nAn excellent point to start to show how this is done in practice is by looking at the sampling library AdvancedMH (AdvancedMH’s GitHub) for Metropolis-Hastings (MH) methods. Let’s say we want to use a random walk Metropolis-Hastings sampler without specifying the proposal distributions. The code below constructs an MH sampler using a multivariate Gaussian distribution with zero mean and unit variance in d dimensions as a random walk proposal.\n\n# Importing the sampling library\nusing AdvancedMH\nrwmh = AdvancedMH.RWMH(d)\n\nMetropolisHastings{RandomWalkProposal{false, ZeroMeanIsoNormal{Tuple{Base.OneTo{Int64}}}}}(RandomWalkProposal{false, ZeroMeanIsoNormal{Tuple{Base.OneTo{Int64}}}}(ZeroMeanIsoNormal(\ndim: 10\nμ: Zeros(10)\nΣ: [1.0 0.0 … 0.0 0.0; 0.0 1.0 … 0.0 0.0; … ; 0.0 0.0 … 1.0 0.0; 0.0 0.0 … 0.0 1.0]\n)\n))\n\n\n\nsetprogress!(false)\n\nSampling is then as easy as:\n\nchain = sample(model, externalsampler(rwmh), 10_000)\n\nChains MCMC chain (10000×11×1 Array{Float64, 3}):\n\nIterations        = 1:1:10000\nNumber of chains  = 1\nSamples per chain = 10000\nWall duration     = 3.76 seconds\nCompute duration  = 3.76 seconds\nparameters        = θ, z[1], z[2], z[3], z[4], z[5], z[6], z[7], z[8], z[9]\ninternals         = lp\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n           θ    0.5234    0.8161    0.1225    45.6718    39.4070    1.0601     ⋯\n        z[1]    1.5512    0.9086    0.1151    62.5734   103.5878    1.0567     ⋯\n        z[2]   -1.7318    0.8860    0.1009    77.0182   241.1333    1.0204     ⋯\n        z[3]   -0.0734    0.7876    0.0699   121.7084   266.2758    1.0017     ⋯\n        z[4]   -0.4326    0.8324    0.0691   153.1964   149.2640    1.0043     ⋯\n        z[5]   -0.4379    0.8722    0.0785   123.5220   181.7847    1.0046     ⋯\n        z[6]   -0.6760    0.8390    0.0772   113.5189   188.0430    1.0165     ⋯\n        z[7]    0.6547    0.8592    0.0888    98.3289   178.5913    1.0003     ⋯\n        z[8]   -1.2699    0.9652    0.1127    73.5993   108.9489    1.0675     ⋯\n        z[9]   -1.0901    0.8824    0.1179    56.7559   132.1585    1.0897     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n           θ   -1.1705   -0.0563    0.5828    1.1003    2.0172\n        z[1]   -0.1404    0.8790    1.6223    2.1419    3.2596\n        z[2]   -3.4479   -2.3557   -1.7176   -0.9642   -0.2351\n        z[3]   -1.6348   -0.5624   -0.0462    0.4521    1.5153\n        z[4]   -2.4113   -0.9040   -0.3262    0.1331    1.0501\n        z[5]   -2.2257   -1.0130   -0.3923    0.1301    1.4142\n        z[6]   -2.4247   -1.2443   -0.6016   -0.0853    0.8392\n        z[7]   -1.0256    0.0071    0.5568    1.1784    2.5663\n        z[8]   -3.1719   -1.8811   -1.2689   -0.6823    0.5433\n        z[9]   -2.8005   -1.7326   -1.0598   -0.4916    0.5753",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Using External Samplers"
    ]
  },
  {
    "objectID": "tutorials/docs-16-using-turing-external-samplers/index.html#using-external-samplers-on-turing-models",
    "href": "tutorials/docs-16-using-turing-external-samplers/index.html#using-external-samplers-on-turing-models",
    "title": "Using External Samplers",
    "section": "",
    "text": "Turing provides several wrapped samplers from external sampling libraries, e.g., HMC samplers from AdvancedHMC. These wrappers allow new users to seamlessly sample statistical models without leaving Turing However, these wrappers might only sometimes be complete, missing some functionality from the wrapped sampling library. Moreover, users might want to use samplers currently not wrapped within Turing.\nFor these reasons, Turing also makes running external samplers on Turing models easy without any necessary modifications or wrapping! Throughout, we will use a 10-dimensional Neal’s funnel as a running example::\n\n# Import libraries.\nusing Turing, Random, LinearAlgebra\n\nd = 10\n@model function funnel()\n    θ ~ Truncated(Normal(0, 3), -3, 3)\n    z ~ MvNormal(zeros(d - 1), exp(θ) * I)\n    return x ~ MvNormal(z, I)\nend\n\nfunnel (generic function with 2 methods)\n\n\nNow we sample the model to generate some observations, which we can then condition on.\n\n(; x) = rand(funnel() | (θ=0,))\nmodel = funnel() | (; x);\n\nUsers can use any sampler algorithm to sample this model if it follows the AbstractMCMC API. Before discussing how this is done in practice, giving a high-level description of the process is interesting. Imagine that we created an instance of an external sampler that we will call spl such that typeof(spl)&lt;:AbstractMCMC.AbstractSampler. In order to avoid type ambiguity within Turing, at the moment it is necessary to declare spl as an external sampler to Turing espl = externalsampler(spl), where externalsampler(s::AbstractMCMC.AbstractSampler) is a Turing function that types our external sampler adequately.\nAn excellent point to start to show how this is done in practice is by looking at the sampling library AdvancedMH (AdvancedMH’s GitHub) for Metropolis-Hastings (MH) methods. Let’s say we want to use a random walk Metropolis-Hastings sampler without specifying the proposal distributions. The code below constructs an MH sampler using a multivariate Gaussian distribution with zero mean and unit variance in d dimensions as a random walk proposal.\n\n# Importing the sampling library\nusing AdvancedMH\nrwmh = AdvancedMH.RWMH(d)\n\nMetropolisHastings{RandomWalkProposal{false, ZeroMeanIsoNormal{Tuple{Base.OneTo{Int64}}}}}(RandomWalkProposal{false, ZeroMeanIsoNormal{Tuple{Base.OneTo{Int64}}}}(ZeroMeanIsoNormal(\ndim: 10\nμ: Zeros(10)\nΣ: [1.0 0.0 … 0.0 0.0; 0.0 1.0 … 0.0 0.0; … ; 0.0 0.0 … 1.0 0.0; 0.0 0.0 … 0.0 1.0]\n)\n))\n\n\n\nsetprogress!(false)\n\nSampling is then as easy as:\n\nchain = sample(model, externalsampler(rwmh), 10_000)\n\nChains MCMC chain (10000×11×1 Array{Float64, 3}):\n\nIterations        = 1:1:10000\nNumber of chains  = 1\nSamples per chain = 10000\nWall duration     = 3.76 seconds\nCompute duration  = 3.76 seconds\nparameters        = θ, z[1], z[2], z[3], z[4], z[5], z[6], z[7], z[8], z[9]\ninternals         = lp\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n           θ    0.5234    0.8161    0.1225    45.6718    39.4070    1.0601     ⋯\n        z[1]    1.5512    0.9086    0.1151    62.5734   103.5878    1.0567     ⋯\n        z[2]   -1.7318    0.8860    0.1009    77.0182   241.1333    1.0204     ⋯\n        z[3]   -0.0734    0.7876    0.0699   121.7084   266.2758    1.0017     ⋯\n        z[4]   -0.4326    0.8324    0.0691   153.1964   149.2640    1.0043     ⋯\n        z[5]   -0.4379    0.8722    0.0785   123.5220   181.7847    1.0046     ⋯\n        z[6]   -0.6760    0.8390    0.0772   113.5189   188.0430    1.0165     ⋯\n        z[7]    0.6547    0.8592    0.0888    98.3289   178.5913    1.0003     ⋯\n        z[8]   -1.2699    0.9652    0.1127    73.5993   108.9489    1.0675     ⋯\n        z[9]   -1.0901    0.8824    0.1179    56.7559   132.1585    1.0897     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n           θ   -1.1705   -0.0563    0.5828    1.1003    2.0172\n        z[1]   -0.1404    0.8790    1.6223    2.1419    3.2596\n        z[2]   -3.4479   -2.3557   -1.7176   -0.9642   -0.2351\n        z[3]   -1.6348   -0.5624   -0.0462    0.4521    1.5153\n        z[4]   -2.4113   -0.9040   -0.3262    0.1331    1.0501\n        z[5]   -2.2257   -1.0130   -0.3923    0.1301    1.4142\n        z[6]   -2.4247   -1.2443   -0.6016   -0.0853    0.8392\n        z[7]   -1.0256    0.0071    0.5568    1.1784    2.5663\n        z[8]   -3.1719   -1.8811   -1.2689   -0.6823    0.5433\n        z[9]   -2.8005   -1.7326   -1.0598   -0.4916    0.5753",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Using External Samplers"
    ]
  },
  {
    "objectID": "tutorials/docs-16-using-turing-external-samplers/index.html#going-beyond-the-turing-api",
    "href": "tutorials/docs-16-using-turing-external-samplers/index.html#going-beyond-the-turing-api",
    "title": "Using External Samplers",
    "section": "Going beyond the Turing API",
    "text": "Going beyond the Turing API\nAs previously mentioned, the Turing wrappers can often limit the capabilities of the sampling libraries they wrap. AdvancedHMC1 (AdvancedHMC’s GitHub) is a clear example of this. A common practice when performing HMC is to provide an initial guess for the mass matrix. However, the native HMC sampler within Turing only allows the user to specify the type of the mass matrix despite the two options being possible within AdvancedHMC. Thankfully, we can use Turing’s support for external samplers to define an HMC sampler with a custom mass matrix in AdvancedHMC and then use it to sample our Turing model.\nWe will use the library Pathfinder2 ((Pathfinder’s GitHub)[https://github.com/mlcolab/Pathfinder.jl]) to construct our estimate of mass matrix. Pathfinder is a variational inference algorithm that first finds the maximum a posteriori (MAP) estimate of a target posterior distribution and then uses the trace of the optimization to construct a sequence of multivariate normal approximations to the target distribution. In this process, Pathfinder computes an estimate of the mass matrix the user can access.\nThe code below shows this can be done in practice.\n\nusing AdvancedHMC, Pathfinder\n# Running pathfinder\ndraws = 1_000\nresult_multi = multipathfinder(model, draws; nruns=8)\n\n# Estimating the metric\ninv_metric = result_multi.pathfinder_results[1].fit_distribution.Σ\nmetric = DenseEuclideanMetric(Matrix(inv_metric))\n\n# Creating an AdvancedHMC NUTS sampler with the custom metric.\nn_adapts = 1000 # Number of adaptation steps\ntap = 0.9 # Large target acceptance probability to deal with the funnel structure of the posterior\nnuts = AdvancedHMC.NUTS(tap; metric=metric)\n\n# Sample\nchain = sample(model, externalsampler(nuts), 10_000; n_adapts=1_000)\n\nWARNING: Method definition size(Transducers.ProgressLoggingFoldable{T} where T) in module Transducers at /home/runner/.julia/packages/Transducers/txnl6/src/progress.jl:63 overwritten in module Pathfinder at /home/runner/.julia/packages/Pathfinder/02iSv/src/transducers.jl:15.\nERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\n\n\nUndefVarError: UndefVarError(:optim_function)\nUndefVarError: `optim_function` not defined\nStacktrace:\n [1] multipathfinder(model::DynamicPPL.Model{typeof(funnel), (), (), (), Tuple{}, Tuple{}, DynamicPPL.ConditionContext{@NamedTuple{x::Vector{Float64}}, DynamicPPL.DefaultContext}}, ndraws::Int64; rng::Random._GLOBAL_RNG, init_scale::Int64, init_sampler::Pathfinder.UniformSampler{Int64}, nruns::Int64, kwargs::@Kwargs{})\n   @ Pathfinder ~/.julia/packages/Pathfinder/02iSv/src/integration/turing.jl:150\n [2] top-level scope\n   @ ~/work/docs/docs/tutorials/docs-16-using-turing-external-samplers/index.qmd:116",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Using External Samplers"
    ]
  },
  {
    "objectID": "tutorials/docs-16-using-turing-external-samplers/index.html#using-new-inference-methods",
    "href": "tutorials/docs-16-using-turing-external-samplers/index.html#using-new-inference-methods",
    "title": "Using External Samplers",
    "section": "Using new inference methods",
    "text": "Using new inference methods\nSo far we have used Turing’s support for external samplers to go beyond the capabilities of the wrappers. We want to use this support to employ a sampler not supported within Turing’s ecosystem yet. We will use the recently developed Micro-Cannoncial Hamiltonian Monte Carlo (MCHMC) sampler to showcase this. MCHMC[3,4] ((MCHMC’s GitHub)[https://github.com/JaimeRZP/MicroCanonicalHMC.jl]) is HMC sampler that uses one single Hamiltonian energy level to explore the whole parameter space. This is achieved by simulating the dynamics of a microcanonical Hamiltonian with an additional noise term to ensure ergodicity.\nUsing this as well as other inference methods outside the Turing ecosystem is as simple as executing the code shown below:\n\nusing MicroCanonicalHMC\n# Create MCHMC sampler\nn_adapts = 1_000 # adaptation steps\ntev = 0.01 # target energy variance\nmchmc = MCHMC(n_adapts, tev; adaptive=true)\n\n# Sample\nchain = sample(model, externalsampler(mchmc), 10_000)\n\n[ Info: Tuning eps ⏳\n[ Info: Tuning L ⏳\n[ Info: Tuning sigma ⏳\nTuning:   0%|▏                                          |  ETA: 0:08:16\n  ϵ:     0.7599296113830811\n  L:     3.1622776601683795\n  dE/d:  0.05696099833007793\n\n\nTuning:   1%|▍                                          |  ETA: 0:04:31\n  ϵ:     0.7892202836777088\n  L:     3.472569248181919\n  dE/d:  0.0005709871775422925\n\n\nTuning: 100%|███████████████████████████████████████████| Time: 0:00:03\n  ϵ:     1.8208681623067464\n  L:     752.6277151865037\n  dE/d:  -0.0032239496011669646\n\n\nChains MCMC chain (10000×11×1 Array{Float64, 3}):\n\nIterations        = 1:1:10000\nNumber of chains  = 1\nSamples per chain = 10000\nWall duration     = 6.92 seconds\nCompute duration  = 6.92 seconds\nparameters        = θ, z[1], z[2], z[3], z[4], z[5], z[6], z[7], z[8], z[9]\ninternals         = lp\n\nSummary Statistics\n  parameters      mean       std      mcse    ess_bulk    ess_tail      rhat   ⋯\n      Symbol   Float64   Float64   Float64     Float64     Float64   Float64   ⋯\n\n           θ    0.3265    0.9787    0.0277   1346.4194    961.0076    1.0035   ⋯\n        z[1]    1.4640    0.8869    0.0197   2059.1015   2590.9493    1.0014   ⋯\n        z[2]   -1.5918    0.9225    0.0204   2057.7038   2903.3933    1.0014   ⋯\n        z[3]   -0.0113    0.7595    0.0119   4068.3888   5330.5603    1.0088   ⋯\n        z[4]   -0.3022    0.6398    0.0107   3610.3846   4300.9132    1.0002   ⋯\n        z[5]   -0.3571    0.8282    0.0171   2351.3949   3187.3943    1.0050   ⋯\n        z[6]   -0.5638    0.8715    0.0185   2239.3251   2942.3836    1.0003   ⋯\n        z[7]    0.5773    0.7381    0.0140   2820.7454   3441.6893    1.0004   ⋯\n        z[8]   -1.2526    0.9010    0.0177   2640.2880   3435.1834    1.0015   ⋯\n        z[9]   -0.9865    0.8693    0.0187   2205.5788   2987.2339    1.0021   ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n           θ   -2.0082   -0.2154    0.4270    0.9676    2.0641\n        z[1]   -0.0783    0.8180    1.4276    2.0409    3.3507\n        z[2]   -3.5312   -2.1998   -1.5455   -0.9369    0.0618\n        z[3]   -1.5073   -0.5221   -0.0117    0.4932    1.4901\n        z[4]   -1.5925   -0.7033   -0.2835    0.0997    0.9541\n        z[5]   -2.0501   -0.9006   -0.3262    0.2048    1.2168\n        z[6]   -2.3723   -1.1387   -0.5142    0.0284    1.0700\n        z[7]   -0.7986    0.0780    0.5463    1.0305    2.1392\n        z[8]   -3.1486   -1.8620   -1.1807   -0.5928    0.2949\n        z[9]   -2.7766   -1.5604   -0.9223   -0.3609    0.5413\n\n\nThe only requirement to work with externalsampler is that the provided sampler must implement the AbstractMCMC.jl-interface [INSERT LINK] for a model of type AbstractMCMC.LogDensityModel [INSERT LINK].\nAs previously stated, in order to use external sampling libraries within Turing they must follow the AbstractMCMC API. In this section, we will briefly dwell on what this entails. First and foremost, the sampler should be a subtype of AbstractMCMC.AbstractSampler. Second, the stepping function of the MCMC algorithm must be made defined using AbstractMCMC.step and follow the structure below:\n\n# First step\nfunction AbstractMCMC.step{T&lt;:AbstractMCMC.AbstractSampler}(\n    rng::Random.AbstractRNG,\n    model::AbstractMCMC.LogDensityModel,\n    spl::T;\n    kwargs...,\n)\n    [...]\n    return transition, sample\nend\n\n# N+1 step\nfunction AbstractMCMC.step{T&lt;:AbstractMCMC.AbstractSampler}(\n    rng::Random.AbstractRNG,\n    model::AbstractMCMC.LogDensityModel,\n    sampler::T,\n    state;\n    kwargs...,\n) \n    [...]\n    return transition, sample\nend\n\nThere are several characteristics to note in these functions:\n\nThere must be two step functions:\n\nA function that performs the first step and initializes the sampler.\nA function that performs the following steps and takes an extra input, state, which carries the initialization information.\n\nThe functions must follow the displayed signatures.\nThe output of the functions must be a transition, the current state of the sampler, and a sample, what is saved to the MCMC chain.\n\nThe last requirement is that the transition must be structured with a field θ, which contains the values of the parameters of the model for said transition. This allows Turing to seamlessly extract the parameter values at each step of the chain when bundling the chains. Note that if the external sampler produces transitions that Turing cannot parse, the bundling of the samples will be different or fail.\nFor practical examples of how to adapt a sampling library to the AbstractMCMC interface, the readers can consult the following libraries:\n\nAdvancedMH\nAdvancedHMC\nMicroCanonicalHMC",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Using External Samplers"
    ]
  },
  {
    "objectID": "tutorials/docs-16-using-turing-external-samplers/index.html#footnotes",
    "href": "tutorials/docs-16-using-turing-external-samplers/index.html#footnotes",
    "title": "Using External Samplers",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nXu et al., AdvancedHMC.jl: A robust, modular and efficient implementation of advanced HMC algorithms, 2019↩︎\nZhang et al., Pathfinder: Parallel quasi-Newton variational inference, 2021↩︎\nRobnik et al, Microcanonical Hamiltonian Monte Carlo, 2022↩︎\nRobnik and Seljak, Langevine Hamiltonian Monte Carlo, 2023↩︎",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Using External Samplers"
    ]
  },
  {
    "objectID": "tutorials/docs-05-for-developers-compiler/index.html",
    "href": "tutorials/docs-05-for-developers-compiler/index.html",
    "title": "Turing Compiler Design",
    "section": "",
    "text": "In this section, the current design of Turing’s model “compiler” is described which enables Turing to perform various types of Bayesian inference without changing the model definition. The “compiler” is essentially just a macro that rewrites the user’s model definition to a function that generates a Model struct that Julia’s dispatch can operate on and that Julia’s compiler can successfully do type inference on for efficient machine code generation.",
    "crumbs": [
      "Get Started",
      "Developers",
      "DynamicPPL in Depth",
      "Turing Compiler Design"
    ]
  },
  {
    "objectID": "tutorials/docs-05-for-developers-compiler/index.html#the-model",
    "href": "tutorials/docs-05-for-developers-compiler/index.html#the-model",
    "title": "Turing Compiler Design",
    "section": "The model",
    "text": "The model\nA model::Model is a callable struct that one can sample from by calling\n\n(model::Model)([rng, varinfo, sampler, context])\n\nwhere rng is a random number generator (default: Random.default_rng()), varinfo is a data structure that stores information about the random variables (default: DynamicPPL.VarInfo()), sampler is a sampling algorithm (default: DynamicPPL.SampleFromPrior()), and context is a sampling context that can, e.g., modify how the log probability is accumulated (default: DynamicPPL.DefaultContext()).\nSampling resets the log joint probability of varinfo and increases the evaluation counter of sampler. If context is a LikelihoodContext, only the log likelihood of D will be accumulated, whereas with PriorContext only the log prior probability of P is. With the DefaultContext the log joint probability of both P and D is accumulated.\nThe Model struct contains the four internal fields f, args, defaults, and context. When model::Model is called, then the internal function model.f is called as model.f(rng, varinfo, sampler, context, model.args...) (for multithreaded sampling, instead of varinfo a threadsafe wrapper is passed to model.f). The positional and keyword arguments that were passed to the user-defined model function when the model was created are saved as a NamedTuple in model.args. The default values of the positional and keyword arguments of the user-defined model functions, if any, are saved as a NamedTuple in model.defaults. They are used for constructing model instances with different arguments by the logprob and prob string macros. The context variable sets an evaluation context that can be used to control for instance whether log probabilities should be evaluated for the prior, likelihood, or joint probability. By default it is set to evaluate the log joint.",
    "crumbs": [
      "Get Started",
      "Developers",
      "DynamicPPL in Depth",
      "Turing Compiler Design"
    ]
  },
  {
    "objectID": "tutorials/docs-05-for-developers-compiler/index.html#step-1-break-up-the-model-definition",
    "href": "tutorials/docs-05-for-developers-compiler/index.html#step-1-break-up-the-model-definition",
    "title": "Turing Compiler Design",
    "section": "Step 1: Break up the model definition",
    "text": "Step 1: Break up the model definition\nFirst, the @model macro breaks up the user-provided function definition using DynamicPPL.build_model_info. This function returns a dictionary consisting of:\n\nallargs_exprs: The expressions of the positional and keyword arguments, without default values.\nallargs_syms: The names of the positional and keyword arguments, e.g., [:x, :y, :TV] above.\nallargs_namedtuple: An expression that constructs a NamedTuple of the positional and keyword arguments, e.g., :((x = x, y = y, TV = TV)) above.\ndefaults_namedtuple: An expression that constructs a NamedTuple of the default positional and keyword arguments, if any, e.g., :((x = missing, y = 1, TV = Vector{Float64})) above.\nmodeldef: A dictionary with the name, arguments, and function body of the model definition, as returned by MacroTools.splitdef.",
    "crumbs": [
      "Get Started",
      "Developers",
      "DynamicPPL in Depth",
      "Turing Compiler Design"
    ]
  },
  {
    "objectID": "tutorials/docs-05-for-developers-compiler/index.html#step-2-generate-the-body-of-the-internal-model-function",
    "href": "tutorials/docs-05-for-developers-compiler/index.html#step-2-generate-the-body-of-the-internal-model-function",
    "title": "Turing Compiler Design",
    "section": "Step 2: Generate the body of the internal model function",
    "text": "Step 2: Generate the body of the internal model function\nIn a second step, DynamicPPL.generate_mainbody generates the main part of the transformed function body using the user-provided function body and the provided function arguments, without default values, for figuring out if a variable denotes an observation or a random variable. Hereby the function DynamicPPL.generate_tilde replaces the L ~ R lines in the model and the function DynamicPPL.generate_dot_tilde replaces the @. L ~ R and L .~ R lines in the model.\nIn the above example, p[1] ~ InverseGamma(2, 3) is replaced with something similar to\n\n#= REPL[25]:6 =#\nbegin\n    var\"##tmpright#323\" = InverseGamma(2, 3)\n    var\"##tmpright#323\" isa Union{Distribution,AbstractVector{&lt;:Distribution}} || throw(\n        ArgumentError(\n            \"Right-hand side of a ~ must be subtype of Distribution or a vector of Distributions.\",\n        ),\n    )\n    var\"##vn#325\" = (DynamicPPL.VarName)(:p, ((1,),))\n    var\"##inds#326\" = ((1,),)\n    p[1] = (DynamicPPL.tilde_assume)(\n        _rng,\n        _context,\n        _sampler,\n        var\"##tmpright#323\",\n        var\"##vn#325\",\n        var\"##inds#326\",\n        _varinfo,\n    )\nend\n\nHere the first line is a so-called line number node that enables more helpful error messages by providing users with the exact location of the error in their model definition. Then the right hand side (RHS) of the ~ is assigned to a variable (with an automatically generated name). We check that the RHS is a distribution or an array of distributions, otherwise an error is thrown. Next we extract a compact representation of the variable with its name and index (or indices). Finally, the ~ expression is replaced with a call to DynamicPPL.tilde_assume since the compiler figured out that p[1] is a random variable using the following heuristic:\n\nIf the symbol on the LHS of ~, :p in this case, is not among the arguments to the model, (:x, :y, :T) in this case, it is a random variable.\nIf the symbol on the LHS of ~, :p in this case, is among the arguments to the model but has a value of missing, it is a random variable.\nIf the value of the LHS of ~, p[1] in this case, is missing, then it is a random variable.\nOtherwise, it is treated as an observation.\n\nThe DynamicPPL.tilde_assume function takes care of sampling the random variable, if needed, and updating its value and the accumulated log joint probability in the _varinfo object. If L ~ R is an observation, DynamicPPL.tilde_observe is called with the same arguments except the random number generator _rng (since observations are never sampled).\nA similar transformation is performed for expressions of the form @. L ~ R and L .~ R. For instance, @. x[1:2] ~ Normal(p[2], sqrt(p[1])) is replaced with\n\n#= REPL[25]:8 =#\nbegin\n    var\"##tmpright#331\" = Normal.(p[2], sqrt.(p[1]))\n    var\"##tmpright#331\" isa Union{Distribution,AbstractVector{&lt;:Distribution}} || throw(\n        ArgumentError(\n            \"Right-hand side of a ~ must be subtype of Distribution or a vector of Distributions.\",\n        ),\n    )\n    var\"##vn#333\" = (DynamicPPL.VarName)(:x, ((1:2,),))\n    var\"##inds#334\" = ((1:2,),)\n    var\"##isassumption#335\" = begin\n        let var\"##vn#336\" = (DynamicPPL.VarName)(:x, ((1:2,),))\n            if !((DynamicPPL.inargnames)(var\"##vn#336\", _model)) ||\n                (DynamicPPL.inmissings)(var\"##vn#336\", _model)\n                true\n            else\n                x[1:2] === missing\n            end\n        end\n    end\n    if var\"##isassumption#335\"\n        x[1:2] .= (DynamicPPL.dot_tilde_assume)(\n            _rng,\n            _context,\n            _sampler,\n            var\"##tmpright#331\",\n            x[1:2],\n            var\"##vn#333\",\n            var\"##inds#334\",\n            _varinfo,\n        )\n    else\n        (DynamicPPL.dot_tilde_observe)(\n            _context,\n            _sampler,\n            var\"##tmpright#331\",\n            x[1:2],\n            var\"##vn#333\",\n            var\"##inds#334\",\n            _varinfo,\n        )\n    end\nend\n\nThe main difference in the expanded code between L ~ R and @. L ~ R is that the former doesn’t assume L to be defined, it can be a new Julia variable in the scope, while the latter assumes L already exists. Moreover, DynamicPPL.dot_tilde_assume and DynamicPPL.dot_tilde_observe are called instead of DynamicPPL.tilde_assume and DynamicPPL.tilde_observe.",
    "crumbs": [
      "Get Started",
      "Developers",
      "DynamicPPL in Depth",
      "Turing Compiler Design"
    ]
  },
  {
    "objectID": "tutorials/docs-05-for-developers-compiler/index.html#step-3-replace-the-user-provided-function-body",
    "href": "tutorials/docs-05-for-developers-compiler/index.html#step-3-replace-the-user-provided-function-body",
    "title": "Turing Compiler Design",
    "section": "Step 3: Replace the user-provided function body",
    "text": "Step 3: Replace the user-provided function body\nFinally, we replace the user-provided function body using DynamicPPL.build_output. This function uses MacroTools.combinedef to reassemble the user-provided function with a new function body. In the modified function body an anonymous function is created whose function body was generated in step 2 above and whose arguments are\n\na random number generator _rng,\na model _model,\na datastructure _varinfo,\na sampler _sampler,\na sampling context _context,\nand all positional and keyword arguments of the user-provided model function as positional arguments without any default values. Finally, in the new function body a model::Model with this anonymous function as internal function is returned.",
    "crumbs": [
      "Get Started",
      "Developers",
      "DynamicPPL in Depth",
      "Turing Compiler Design"
    ]
  },
  {
    "objectID": "tutorials/docs-05-for-developers-compiler/index.html#overview-1",
    "href": "tutorials/docs-05-for-developers-compiler/index.html#overview-1",
    "title": "Turing Compiler Design",
    "section": "Overview",
    "text": "Overview\nVarInfo is the data structure in Turing that facilitates tracking random variables and certain metadata about them that are required for sampling. For instance, the distribution of every random variable is stored in VarInfo because we need to know the support of every random variable when sampling using HMC for example. Random variables whose distributions have a constrained support are transformed using a bijector from Bijectors.jl so that the sampling happens in the unconstrained space. Different samplers require different metadata about the random variables.\nThe definition of VarInfo in Turing is:\n\nstruct VarInfo{Tmeta, Tlogp} &lt;: AbstractVarInfo\n    metadata::Tmeta\n    logp::Base.RefValue{Tlogp}\n    num_produce::Base.RefValue{Int}\nend\n\nBased on the type of metadata, the VarInfo is either aliased UntypedVarInfo or TypedVarInfo. metadata can be either a subtype of the union type Metadata or a NamedTuple of multiple such subtypes. Let vi be an instance of VarInfo. If vi isa VarInfo{&lt;:Metadata}, then it is called an UntypedVarInfo. If vi isa VarInfo{&lt;:NamedTuple}, then vi.metadata would be a NamedTuple mapping each symbol in P to an instance of Metadata. vi would then be called a TypedVarInfo. The other fields of VarInfo include logp which is used to accumulate the log probability or log probability density of the variables in P and D. num_produce keeps track of how many observations have been made in the model so far. This is incremented when running a ~ statement when the symbol on the LHS is in D.",
    "crumbs": [
      "Get Started",
      "Developers",
      "DynamicPPL in Depth",
      "Turing Compiler Design"
    ]
  },
  {
    "objectID": "tutorials/docs-05-for-developers-compiler/index.html#metadata",
    "href": "tutorials/docs-05-for-developers-compiler/index.html#metadata",
    "title": "Turing Compiler Design",
    "section": "Metadata",
    "text": "Metadata\nThe Metadata struct stores some metadata about the random variables sampled. This helps query certain information about a variable such as: its distribution, which samplers sample this variable, its value and whether this value is transformed to real space or not. Let md be an instance of Metadata:\n\nmd.vns is the vector of all VarName instances. Let vn be an arbitrary element of md.vns\nmd.idcs is the dictionary that maps each VarName instance to its index in md.vns, md.ranges, md.dists, md.orders and md.flags.\nmd.vns[md.idcs[vn]] == vn.\nmd.dists[md.idcs[vn]] is the distribution of vn.\nmd.gids[md.idcs[vn]] is the set of algorithms used to sample vn. This is used in the Gibbs sampling process.\nmd.orders[md.idcs[vn]] is the number of observe statements before vn is sampled.\nmd.ranges[md.idcs[vn]] is the index range of vn in md.vals.\nmd.vals[md.ranges[md.idcs[vn]]] is the linearized vector of values of corresponding to vn.\nmd.flags is a dictionary of true/false flags. md.flags[flag][md.idcs[vn]] is the value of flag corresponding to vn.\n\nNote that in order to make md::Metadata type stable, all the md.vns must have the same symbol and distribution type. However, one can have a single Julia variable, e.g. x, that is a matrix or a hierarchical array sampled in partitions, e.g. x[1][:] ~ MvNormal(zeros(2), I); x[2][:] ~ MvNormal(ones(2), I). The symbol x can still be managed by a single md::Metadata without hurting the type stability since all the distributions on the RHS of ~ are of the same type.\nHowever, in Turing models one cannot have this restriction, so we must use a type unstable Metadata if we want to use one Metadata instance for the whole model. This is what UntypedVarInfo does. A type unstable Metadata will still work but will have inferior performance.\nTo strike a balance between flexibility and performance when constructing the spl::Sampler instance, the model is first run by sampling the parameters in P from their priors using an UntypedVarInfo, i.e. a type unstable Metadata is used for all the variables. Then once all the symbols and distribution types have been identified, a vi::TypedVarInfo is constructed where vi.metadata is a NamedTuple mapping each symbol in P to a specialized instance of Metadata. So as long as each symbol in P is sampled from only one type of distributions, vi::TypedVarInfo will have fully concretely typed fields which brings out the peak performance of Julia.",
    "crumbs": [
      "Get Started",
      "Developers",
      "DynamicPPL in Depth",
      "Turing Compiler Design"
    ]
  },
  {
    "objectID": "tutorials/00-introduction/index.html",
    "href": "tutorials/00-introduction/index.html",
    "title": "Introduction: Coin Flipping",
    "section": "",
    "text": "This is the first of a series of guided tutorials on the Turing language. In this tutorial, we will use Bayesian inference to estimate the probability that a coin flip will result in heads, given a series of observations.\n\nSetup\nFirst, let us load some packages that we need to simulate a coin flip:\n\nusing Distributions\n\nusing Random\nRandom.seed!(12); # Set seed for reproducibility\n\nand to visualize our results.\n\nusing StatsPlots\n\nNote that Turing is not loaded here — we do not use it in this example. Next, we configure the data generating model. Let us set the true probability that a coin flip turns up heads\n\np_true = 0.5;\n\nand set the number of coin flips we will show our model.\n\nN = 100;\n\nWe simulate N coin flips by drawing N random samples from the Bernoulli distribution with success probability p_true. The draws are collected in a variable called data:\n\ndata = rand(Bernoulli(p_true), N);\n\nHere are the first five coin flips:\n\ndata[1:5]\n\n5-element Vector{Bool}:\n 0\n 0\n 1\n 0\n 0\n\n\n\n\nCoin Flipping Without Turing\nThe following example illustrates the effect of updating our beliefs with every piece of new evidence we observe.\nAssume that we are unsure about the probability of heads in a coin flip. To get an intuitive understanding of what “updating our beliefs” is, we will visualize the probability of heads in a coin flip after each observed evidence.\nWe begin by specifying a prior belief about the distribution of heads and tails in a coin toss. Here we choose a Beta distribution as prior distribution for the probability of heads. Before any coin flip is observed, we assume a uniform distribution \\(\\operatorname{U}(0, 1) = \\operatorname{Beta}(1, 1)\\) of the probability of heads. I.e., every probability is equally likely initially.\n\nprior_belief = Beta(1, 1);\n\nWith our priors set and our data at hand, we can perform Bayesian inference.\nThis is a fairly simple process. We expose one additional coin flip to our model every iteration, such that the first run only sees the first coin flip, while the last iteration sees all the coin flips. In each iteration we update our belief to an updated version of the original Beta distribution that accounts for the new proportion of heads and tails. The update is particularly simple since our prior distribution is a conjugate prior. Note that a closed-form expression for the posterior (implemented in the updated_belief expression below) is not accessible in general and usually does not exist for more interesting models.\n\nfunction updated_belief(prior_belief::Beta, data::AbstractArray{Bool})\n    # Count the number of heads and tails.\n    heads = sum(data)\n    tails = length(data) - heads\n\n    # Update our prior belief in closed form (this is possible because we use a conjugate prior).\n    return Beta(prior_belief.α + heads, prior_belief.β + tails)\nend\n\n# Show updated belief for increasing number of observations\n@gif for n in 0:N\n    plot(\n        updated_belief(prior_belief, data[1:n]);\n        size=(500, 250),\n        title=\"Updated belief after $n observations\",\n        xlabel=\"probability of heads\",\n        ylabel=\"\",\n        legend=nothing,\n        xlim=(0, 1),\n        fill=0,\n        α=0.3,\n        w=3,\n    )\n    vline!([p_true])\nend\n\nGKS: cannot open display - headless operation mode active\n[ Info: Saved animation to /tmp/jl_RuPGrkhkrg.gif\n\n\n\n\n\nThe animation above shows that with increasing evidence our belief about the probability of heads in a coin flip slowly adjusts towards the true value. The orange line in the animation represents the true probability of seeing heads on a single coin flip, while the mode of the distribution shows what the model believes the probability of a heads is given the evidence it has seen.\nFor the mathematically inclined, the \\(\\operatorname{Beta}\\) distribution is updated by adding each coin flip to the parameters \\(\\alpha\\) and \\(\\beta\\) of the distribution. Initially, the parameters are defined as \\(\\alpha = 1\\) and \\(\\beta = 1\\). Over time, with more and more coin flips, \\(\\alpha\\) and \\(\\beta\\) will be approximately equal to each other as we are equally likely to flip a heads or a tails.\nThe mean of the \\(\\operatorname{Beta}(\\alpha, \\beta)\\) distribution is\n\\[\\operatorname{E}[X] = \\dfrac{\\alpha}{\\alpha+\\beta}.\\]\nThis implies that the plot of the distribution will become centered around 0.5 for a large enough number of coin flips, as we expect \\(\\alpha \\approx \\beta\\).\nThe variance of the \\(\\operatorname{Beta}(\\alpha, \\beta)\\) distribution is\n\\[\\operatorname{var}[X] = \\dfrac{\\alpha\\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}.\\]\nThus the variance of the distribution will approach 0 with more and more samples, as the denominator will grow faster than will the numerator. More samples means less variance. This implies that the distribution will reflect less uncertainty about the probability of receiving a heads and the plot will become more tightly centered around 0.5 for a large enough number of coin flips.\n\n\nCoin Flipping With Turing\nWe now move away from the closed-form expression above. We use Turing to specify the same model and to approximate the posterior distribution with samples. To do so, we first need to load Turing.\n\nusing Turing\n\nAdditionally, we load MCMCChains, a library for analyzing and visualizing the samples with which we approximate the posterior distribution.\n\nusing MCMCChains\n\nFirst, we define the coin-flip model using Turing.\n\n# Unconditioned coinflip model with `N` observations.\n@model function coinflip(; N::Int)\n    # Our prior belief about the probability of heads in a coin toss.\n    p ~ Beta(1, 1)\n\n    # Heads or tails of a coin are drawn from `N` independent and identically\n    # distributed Bernoulli distributions with success rate `p`.\n    y ~ filldist(Bernoulli(p), N)\n\n    return y\nend;\n\nIn the Turing model the prior distribution of the variable p, the probability of heads in a coin toss, and the distribution of the observations y are specified on the right-hand side of the ~ expressions. The @model macro modifies the body of the Julia function coinflip and, e.g., replaces the ~ statements with internal function calls that are used for sampling.\nHere we defined a model that is not conditioned on any specific observations as this allows us to easily obtain samples of both p and y with\n\nrand(coinflip(; N))\n\n(p = 0.04773338237532602, y = Bool[0, 0, 0, 0, 0, 0, 0, 0, 0, 0  …  0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n\n\nThe model can be conditioned on some observations with |. See the documentation of the condition syntax in DynamicPPL.jl for more details. In the conditioned model the observations y are fixed to data.\n\ncoinflip(y::AbstractVector{&lt;:Real}) = coinflip(; N=length(y)) | (; y)\n\nmodel = coinflip(data);\n\nAfter defining the model, we can approximate the posterior distribution by drawing samples from the distribution. In this example, we use a Hamiltonian Monte Carlo sampler to draw these samples. Other tutorials give more information on the samplers available in Turing and discuss their use for different models.\n\nsampler = NUTS();\n\nWe approximate the posterior distribution with 1000 samples:\n\nchain = sample(model, sampler, 2_000, progress=false);\n\n┌ Info: Found initial step size\n└   ϵ = 0.4\n\n\nThe sample function and common keyword arguments are explained more extensively in the documentation of AbstractMCMC.jl.\nAfter finishing the sampling process, we can visually compare the closed-form posterior distribution with the approximation obtained with Turing.\n\nhistogram(chain)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow we can build our plot:\n\n# Visualize a blue density plot of the approximate posterior distribution using HMC (see Chain 1 in the legend).\ndensity(chain; xlim=(0, 1), legend=:best, w=2, c=:blue)\n\n# Visualize a green density plot of the posterior distribution in closed-form.\nplot!(\n    0:0.01:1,\n    pdf.(updated_belief(prior_belief, data), 0:0.01:1);\n    xlabel=\"probability of heads\",\n    ylabel=\"\",\n    title=\"\",\n    xlim=(0, 1),\n    label=\"Closed-form\",\n    fill=0,\n    α=0.3,\n    w=3,\n    c=:lightgreen,\n)\n\n# Visualize the true probability of heads in red.\nvline!([p_true]; label=\"True probability\", c=:red)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs we can see, the samples obtained with Turing closely approximate the true posterior distribution. Hopefully this tutorial has provided an easy-to-follow, yet informative introduction to Turing’s simpler applications. More advanced usage is demonstrated in other tutorials.\n\n\n\n\n Back to top",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Introduction: Coin Flipping"
    ]
  },
  {
    "objectID": "tutorials/08-multinomial-logistic-regression/index.html",
    "href": "tutorials/08-multinomial-logistic-regression/index.html",
    "title": "Bayesian Multinomial Logistic Regression",
    "section": "",
    "text": "Multinomial logistic regression is an extension of logistic regression. Logistic regression is used to model problems in which there are exactly two possible discrete outcomes. Multinomial logistic regression is used to model problems in which there are two or more possible discrete outcomes.\nIn our example, we’ll be using the iris dataset. The iris multiclass problem aims to predict the species of a flower given measurements (in centimeters) of sepal length and width and petal length and width. There are three possible species: Iris setosa, Iris versicolor, and Iris virginica.\nTo start, let’s import all the libraries we’ll need.\n# Load Turing.\nusing Turing\n\n# Load RDatasets.\nusing RDatasets\n\n# Load StatsPlots for visualizations and diagnostics.\nusing StatsPlots\n\n# Functionality for splitting and normalizing the data.\nusing MLDataUtils: shuffleobs, splitobs, rescale!\n\n# We need a softmax function which is provided by NNlib.\nusing NNlib: softmax\n\n# Functionality for constructing arrays with identical elements efficiently.\nusing FillArrays\n\n# Functionality for working with scaled identity matrices.\nusing LinearAlgebra\n\n# Set a seed for reproducibility.\nusing Random\nRandom.seed!(0);",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Multinomial Logistic Regression"
    ]
  },
  {
    "objectID": "tutorials/08-multinomial-logistic-regression/index.html#data-cleaning-set-up",
    "href": "tutorials/08-multinomial-logistic-regression/index.html#data-cleaning-set-up",
    "title": "Bayesian Multinomial Logistic Regression",
    "section": "Data Cleaning & Set Up",
    "text": "Data Cleaning & Set Up\nNow we’re going to import our dataset. Twenty rows of the dataset are shown below so you can get a good feel for what kind of data we have.\n\n# Import the \"iris\" dataset.\ndata = RDatasets.dataset(\"datasets\", \"iris\");\n\n# Show twenty random rows.\ndata[rand(1:size(data, 1), 20), :]\n\n20×5 DataFrame\n\n\n\nRow\nSepalLength\nSepalWidth\nPetalLength\nPetalWidth\nSpecies\n\n\n\nFloat64\nFloat64\nFloat64\nFloat64\nCat…\n\n\n\n\n1\n7.9\n3.8\n6.4\n2.0\nvirginica\n\n\n2\n7.0\n3.2\n4.7\n1.4\nversicolor\n\n\n3\n6.4\n2.8\n5.6\n2.1\nvirginica\n\n\n4\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n5\n5.1\n2.5\n3.0\n1.1\nversicolor\n\n\n6\n6.7\n3.3\n5.7\n2.5\nvirginica\n\n\n7\n5.1\n3.8\n1.6\n0.2\nsetosa\n\n\n8\n5.2\n3.4\n1.4\n0.2\nsetosa\n\n\n9\n5.0\n3.2\n1.2\n0.2\nsetosa\n\n\n10\n6.3\n3.3\n6.0\n2.5\nvirginica\n\n\n11\n5.4\n3.9\n1.3\n0.4\nsetosa\n\n\n12\n6.3\n2.9\n5.6\n1.8\nvirginica\n\n\n13\n6.4\n2.9\n4.3\n1.3\nversicolor\n\n\n14\n5.7\n2.9\n4.2\n1.3\nversicolor\n\n\n15\n6.8\n3.0\n5.5\n2.1\nvirginica\n\n\n16\n5.6\n3.0\n4.5\n1.5\nversicolor\n\n\n17\n6.4\n2.8\n5.6\n2.2\nvirginica\n\n\n18\n6.2\n2.9\n4.3\n1.3\nversicolor\n\n\n19\n5.2\n4.1\n1.5\n0.1\nsetosa\n\n\n20\n6.7\n3.0\n5.2\n2.3\nvirginica\n\n\n\n\n\n\nIn this data set, the outcome Species is currently coded as a string. We convert it to a numerical value by using indices 1, 2, and 3 to indicate species setosa, versicolor, and virginica, respectively.\n\n# Recode the `Species` column.\nspecies = [\"setosa\", \"versicolor\", \"virginica\"]\ndata[!, :Species_index] = indexin(data[!, :Species], species)\n\n# Show twenty random rows of the new species columns\ndata[rand(1:size(data, 1), 20), [:Species, :Species_index]]\n\n20×2 DataFrame\n\n\n\nRow\nSpecies\nSpecies_index\n\n\n\nCat…\nUnion…\n\n\n\n\n1\nvirginica\n3\n\n\n2\nvirginica\n3\n\n\n3\nvirginica\n3\n\n\n4\nvirginica\n3\n\n\n5\nversicolor\n2\n\n\n6\nsetosa\n1\n\n\n7\nvirginica\n3\n\n\n8\nversicolor\n2\n\n\n9\nsetosa\n1\n\n\n10\nvirginica\n3\n\n\n11\nsetosa\n1\n\n\n12\nsetosa\n1\n\n\n13\nsetosa\n1\n\n\n14\nvirginica\n3\n\n\n15\nvirginica\n3\n\n\n16\nsetosa\n1\n\n\n17\nsetosa\n1\n\n\n18\nversicolor\n2\n\n\n19\nvirginica\n3\n\n\n20\nsetosa\n1\n\n\n\n\n\n\nAfter we’ve done that tidying, it’s time to split our dataset into training and testing sets, and separate the features and target from the data. Additionally, we must rescale our feature variables so that they are centered around zero by subtracting each column by the mean and dividing it by the standard deviation. Without this step, Turing’s sampler will have a hard time finding a place to start searching for parameter estimates.\n\n# Split our dataset 50%/50% into training/test sets.\ntrainset, testset = splitobs(shuffleobs(data), 0.5)\n\n# Define features and target.\nfeatures = [:SepalLength, :SepalWidth, :PetalLength, :PetalWidth]\ntarget = :Species_index\n\n# Turing requires data in matrix and vector form.\ntrain_features = Matrix(trainset[!, features])\ntest_features = Matrix(testset[!, features])\ntrain_target = trainset[!, target]\ntest_target = testset[!, target]\n\n# Standardize the features.\nμ, σ = rescale!(train_features; obsdim=1)\nrescale!(test_features, μ, σ; obsdim=1);",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Multinomial Logistic Regression"
    ]
  },
  {
    "objectID": "tutorials/08-multinomial-logistic-regression/index.html#model-declaration",
    "href": "tutorials/08-multinomial-logistic-regression/index.html#model-declaration",
    "title": "Bayesian Multinomial Logistic Regression",
    "section": "Model Declaration",
    "text": "Model Declaration\nFinally, we can define our model logistic_regression. It is a function that takes three arguments where\n\nx is our set of independent variables;\ny is the element we want to predict;\nσ is the standard deviation we want to assume for our priors.\n\nWe select the setosa species as the baseline class (the choice does not matter). Then we create the intercepts and vectors of coefficients for the other classes against that baseline. More concretely, we create scalar intercepts intercept_versicolor and intersept_virginica and coefficient vectors coefficients_versicolor and coefficients_virginica with four coefficients each for the features SepalLength, SepalWidth, PetalLength and PetalWidth. We assume a normal distribution with mean zero and standard deviation σ as prior for each scalar parameter. We want to find the posterior distribution of these, in total ten, parameters to be able to predict the species for any given set of features.\n\n# Bayesian multinomial logistic regression\n@model function logistic_regression(x, y, σ)\n    n = size(x, 1)\n    length(y) == n ||\n        throw(DimensionMismatch(\"number of observations in `x` and `y` is not equal\"))\n\n    # Priors of intercepts and coefficients.\n    intercept_versicolor ~ Normal(0, σ)\n    intercept_virginica ~ Normal(0, σ)\n    coefficients_versicolor ~ MvNormal(Zeros(4), σ^2 * I)\n    coefficients_virginica ~ MvNormal(Zeros(4), σ^2 * I)\n\n    # Compute the likelihood of the observations.\n    values_versicolor = intercept_versicolor .+ x * coefficients_versicolor\n    values_virginica = intercept_virginica .+ x * coefficients_virginica\n    for i in 1:n\n        # the 0 corresponds to the base category `setosa`\n        v = softmax([0, values_versicolor[i], values_virginica[i]])\n        y[i] ~ Categorical(v)\n    end\nend;",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Multinomial Logistic Regression"
    ]
  },
  {
    "objectID": "tutorials/08-multinomial-logistic-regression/index.html#sampling",
    "href": "tutorials/08-multinomial-logistic-regression/index.html#sampling",
    "title": "Bayesian Multinomial Logistic Regression",
    "section": "Sampling",
    "text": "Sampling\nNow we can run our sampler. This time we’ll use NUTS to sample from our posterior.\n\nsetprogress!(false)\n\n\nm = logistic_regression(train_features, train_target, 1)\nchain = sample(m, NUTS(), MCMCThreads(), 1_500, 3)\n\n\n\nChains MCMC chain (1500×22×3 Array{Float64, 3}):\n\nIterations        = 751:1:2250\nNumber of chains  = 3\nSamples per chain = 1500\nWall duration     = 18.39 seconds\nCompute duration  = 15.49 seconds\nparameters        = intercept_versicolor, intercept_virginica, coefficients_versicolor[1], coefficients_versicolor[2], coefficients_versicolor[3], coefficients_versicolor[4], coefficients_virginica[1], coefficients_virginica[2], coefficients_virginica[3], coefficients_virginica[4]\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n                  parameters      mean       std      mcse    ess_bulk    ess_ ⋯\n                      Symbol   Float64   Float64   Float64     Float64     Flo ⋯\n\n        intercept_versicolor    0.7188    0.5246    0.0084   3946.0971   3019. ⋯\n         intercept_virginica   -0.4454    0.6639    0.0099   4447.7598   3142. ⋯\n  coefficients_versicolor[1]    0.9114    0.6472    0.0099   4287.1367   3400. ⋯\n  coefficients_versicolor[2]   -1.5776    0.5510    0.0086   4180.1332   3188. ⋯\n  coefficients_versicolor[3]    1.1341    0.7608    0.0116   4284.4563   3467. ⋯\n  coefficients_versicolor[4]    0.0906    0.7321    0.0115   4056.3741   3231. ⋯\n   coefficients_virginica[1]    1.1800    0.7098    0.0107   4412.5868   3086. ⋯\n   coefficients_virginica[2]   -0.6193    0.6411    0.0099   4250.0497   2976. ⋯\n   coefficients_virginica[3]    1.9486    0.8566    0.0121   5013.9753   3127. ⋯\n   coefficients_virginica[4]    2.7117    0.7929    0.0111   5106.1227   3501. ⋯\n                                                               3 columns omitted\n\nQuantiles\n                  parameters      2.5%     25.0%     50.0%     75.0%     97.5% ⋯\n                      Symbol   Float64   Float64   Float64   Float64   Float64 ⋯\n\n        intercept_versicolor   -0.2720    0.3610    0.7047    1.0666    1.7679 ⋯\n         intercept_virginica   -1.7501   -0.8805   -0.4417    0.0009    0.8480 ⋯\n  coefficients_versicolor[1]   -0.3454    0.4760    0.9053    1.3505    2.1488 ⋯\n  coefficients_versicolor[2]   -2.7013   -1.9335   -1.5710   -1.1974   -0.5268 ⋯\n  coefficients_versicolor[3]   -0.3557    0.6101    1.1397    1.6604    2.6115 ⋯\n  coefficients_versicolor[4]   -1.3363   -0.4039    0.0962    0.5751    1.5070 ⋯\n   coefficients_virginica[1]   -0.2223    0.6927    1.1752    1.6485    2.6302 ⋯\n   coefficients_virginica[2]   -1.9313   -1.0343   -0.6244   -0.1839    0.6276 ⋯\n   coefficients_virginica[3]    0.2510    1.3685    1.9418    2.4982    3.6444 ⋯\n   coefficients_virginica[4]    1.1605    2.1705    2.7056    3.2581    4.2518 ⋯\n\n\n\n\n\n\n\n\nSampling With Multiple Threads\n\n\n\n\n\nThe sample() call above assumes that you have at least nchains threads available in your Julia instance. If you do not, the multiple chains will run sequentially, and you may notice a warning. For more information, see the Turing documentation on sampling multiple chains.\n\n\n\nSince we ran multiple chains, we may as well do a spot check to make sure each chain converges around similar points.\n\nplot(chain)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLooks good!\nWe can also use the corner function from MCMCChains to show the distributions of the various parameters of our multinomial logistic regression. The corner function requires MCMCChains and StatsPlots.\n\n# Only plotting the first 3 coefficients due to a bug in Plots.jl\ncorner(\n    chain,\n    MCMCChains.namesingroup(chain, :coefficients_versicolor)[1:3];\n)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Only plotting the first 3 coefficients due to a bug in Plots.jl\ncorner(\n    chain,\n    MCMCChains.namesingroup(chain, :coefficients_virginica)[1:3];\n)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFortunately the corner plots appear to demonstrate unimodal distributions for each of our parameters, so it should be straightforward to take the means of each parameter’s sampled values to estimate our model to make predictions.",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Multinomial Logistic Regression"
    ]
  },
  {
    "objectID": "tutorials/08-multinomial-logistic-regression/index.html#making-predictions",
    "href": "tutorials/08-multinomial-logistic-regression/index.html#making-predictions",
    "title": "Bayesian Multinomial Logistic Regression",
    "section": "Making Predictions",
    "text": "Making Predictions\nHow do we test how well the model actually predicts which of the three classes an iris flower belongs to? We need to build a prediction function that takes the test dataset and runs it through the average parameter calculated during sampling.\nThe prediction function below takes a Matrix and a Chains object. It computes the mean of the sampled parameters and calculates the species with the highest probability for each observation. Note that we do not have to evaluate the softmax function since it does not affect the order of its inputs.\n\nfunction prediction(x::Matrix, chain)\n    # Pull the means from each parameter's sampled values in the chain.\n    intercept_versicolor = mean(chain, :intercept_versicolor)\n    intercept_virginica = mean(chain, :intercept_virginica)\n    coefficients_versicolor = [\n        mean(chain, k) for k in MCMCChains.namesingroup(chain, :coefficients_versicolor)\n    ]\n    coefficients_virginica = [\n        mean(chain, k) for k in MCMCChains.namesingroup(chain, :coefficients_virginica)\n    ]\n\n    # Compute the index of the species with the highest probability for each observation.\n    values_versicolor = intercept_versicolor .+ x * coefficients_versicolor\n    values_virginica = intercept_virginica .+ x * coefficients_virginica\n    species_indices = [\n        argmax((0, x, y)) for (x, y) in zip(values_versicolor, values_virginica)\n    ]\n\n    return species_indices\nend;\n\nLet’s see how we did! We run the test matrix through the prediction function, and compute the accuracy for our prediction.\n\n# Make the predictions.\npredictions = prediction(test_features, chain)\n\n# Calculate accuracy for our test set.\nmean(predictions .== testset[!, :Species_index])\n\n0.84\n\n\nPerhaps more important is to see the accuracy per class.\n\nfor s in 1:3\n    rows = testset[!, :Species_index] .== s\n    println(\"Number of `\", species[s], \"`: \", count(rows))\n    println(\n        \"Percentage of `\",\n        species[s],\n        \"` predicted correctly: \",\n        mean(predictions[rows] .== testset[rows, :Species_index]),\n    )\nend\n\nNumber of `setosa`: 24\nPercentage of `setosa` predicted correctly: 0.9583333333333334\nNumber of `versicolor`: 29\nPercentage of `versicolor` predicted correctly: 0.7586206896551724\nNumber of `virginica`: 22\nPercentage of `virginica` predicted correctly: 0.8181818181818182\n\n\nThis tutorial has demonstrated how to use Turing to perform Bayesian multinomial logistic regression.",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Multinomial Logistic Regression"
    ]
  },
  {
    "objectID": "tutorials/03-bayesian-neural-network/index.html",
    "href": "tutorials/03-bayesian-neural-network/index.html",
    "title": "Bayesian Neural Networks",
    "section": "",
    "text": "In this tutorial, we demonstrate how one can implement a Bayesian Neural Network using a combination of Turing and Lux, a suite of machine learning tools. We will use Lux to specify the neural network’s layers and Turing to implement the probabilistic inference, with the goal of implementing a classification algorithm.\nWe will begin with importing the relevant libraries.\nusing Turing\nusing FillArrays\nusing Lux\nusing Plots\nusing Tracker\nusing Functors\n\nusing LinearAlgebra\nusing Random\n\nWARNING: Method definition rrule(typeof(Base.merge), NamedTuple{F1, T} where T&lt;:Tuple, NamedTuple{F2, T} where T&lt;:Tuple) where {F1, F2} in module ChainRules at /home/runner/.julia/packages/ChainRules/hShjJ/src/rulesets/Base/base.jl:313 overwritten in module Lux at /home/runner/.julia/packages/Lux/5xfGO/src/chainrules.jl:16.\nERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\nOur goal here is to use a Bayesian neural network to classify points in an artificial dataset. The code below generates data points arranged in a box-like pattern and displays a graph of the dataset we will be working with.\n# Number of points to generate\nN = 80\nM = round(Int, N / 4)\nrng = Random.default_rng()\nRandom.seed!(rng, 1234)\n\n# Generate artificial data\nx1s = rand(rng, Float32, M) * 4.5f0;\nx2s = rand(rng, Float32, M) * 4.5f0;\nxt1s = Array([[x1s[i] + 0.5f0; x2s[i] + 0.5f0] for i in 1:M])\nx1s = rand(rng, Float32, M) * 4.5f0;\nx2s = rand(rng, Float32, M) * 4.5f0;\nappend!(xt1s, Array([[x1s[i] - 5.0f0; x2s[i] - 5.0f0] for i in 1:M]))\n\nx1s = rand(rng, Float32, M) * 4.5f0;\nx2s = rand(rng, Float32, M) * 4.5f0;\nxt0s = Array([[x1s[i] + 0.5f0; x2s[i] - 5.0f0] for i in 1:M])\nx1s = rand(rng, Float32, M) * 4.5f0;\nx2s = rand(rng, Float32, M) * 4.5f0;\nappend!(xt0s, Array([[x1s[i] - 5.0f0; x2s[i] + 0.5f0] for i in 1:M]))\n\n# Store all the data for later\nxs = [xt1s; xt0s]\nts = [ones(2 * M); zeros(2 * M)]\n\n# Plot data points.\nfunction plot_data()\n    x1 = map(e -&gt; e[1], xt1s)\n    y1 = map(e -&gt; e[2], xt1s)\n    x2 = map(e -&gt; e[1], xt0s)\n    y2 = map(e -&gt; e[2], xt0s)\n\n    Plots.scatter(x1, y1; color=\"red\", clim=(0, 1))\n    return Plots.scatter!(x2, y2; color=\"blue\", clim=(0, 1))\nend\n\nplot_data()",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Bayesian Neural Networks"
    ]
  },
  {
    "objectID": "tutorials/03-bayesian-neural-network/index.html#building-a-neural-network",
    "href": "tutorials/03-bayesian-neural-network/index.html#building-a-neural-network",
    "title": "Bayesian Neural Networks",
    "section": "Building a Neural Network",
    "text": "Building a Neural Network\nThe next step is to define a feedforward neural network where we express our parameters as distributions, and not single points as with traditional neural networks. For this we will use Dense to define liner layers and compose them via Chain, both are neural network primitives from Lux. The network nn_initial we created has two hidden layers with tanh activations and one output layer with sigmoid (σ) activation, as shown below.\n\n\n\n\n\n\n\nG\n\nInput layer                   Hidden layers                  Output layer\n\ncluster_hidden1\n\n\n\ncluster_hidden2\n\n\n\ncluster_output\n\n\n\ncluster_input\n\n\n\n\ninput1\n\n\n\n\nhidden11\n\n\n\n\ninput1--hidden11\n\n\n\n\nhidden12\n\n\n\n\ninput1--hidden12\n\n\n\n\nhidden13\n\n\n\n\ninput1--hidden13\n\n\n\n\ninput2\n\n\n\n\ninput2--hidden11\n\n\n\n\ninput2--hidden12\n\n\n\n\ninput2--hidden13\n\n\n\n\nhidden21\n\n\n\n\nhidden11--hidden21\n\n\n\n\nhidden22\n\n\n\n\nhidden11--hidden22\n\n\n\n\nhidden12--hidden21\n\n\n\n\nhidden12--hidden22\n\n\n\n\nhidden13--hidden21\n\n\n\n\nhidden13--hidden22\n\n\n\n\noutput1\n\n\n\n\nhidden21--output1\n\n\n\n\nhidden22--output1\n\n\n\n\n\n\n\n\n\nThe nn_initial is an instance that acts as a function and can take data as inputs and output predictions. We will define distributions on the neural network parameters. \n\n# Construct a neural network using Lux\nnn_initial = Chain(Dense(2 =&gt; 3, tanh), Dense(3 =&gt; 2, tanh), Dense(2 =&gt; 1, σ))\n\n# Initialize the model weights and state\nps, st = Lux.setup(rng, nn_initial)\n\nLux.parameterlength(nn_initial) # number of paraemters in NN\n\n20\n\n\nThe probabilistic model specification below creates a parameters variable, which has IID normal variables. The parameters vector represents all parameters of our neural net (weights and biases).\n\n# Create a regularization term and a Gaussian prior variance term.\nalpha = 0.09\nsigma = sqrt(1.0 / alpha)\n\n3.3333333333333335\n\n\nConstruct named tuple from a sampled parameter vector. We could also use ComponentArrays here and simply broadcast to avoid doing this. But let’s do it this way to avoid dependencies.\n\nfunction vector_to_parameters(ps_new::AbstractVector, ps::NamedTuple)\n    @assert length(ps_new) == Lux.parameterlength(ps)\n    i = 1\n    function get_ps(x)\n        z = reshape(view(ps_new, i:(i + length(x) - 1)), size(x))\n        i += length(x)\n        return z\n    end\n    return fmap(get_ps, ps)\nend\n\nvector_to_parameters (generic function with 1 method)\n\n\nTo interface with external libraries it is often desirable to use the StatefulLuxLayer to automatically handle the neural network states.\n\nconst nn = StatefulLuxLayer(nn_initial, st)\n\n# Specify the probabilistic model.\n@model function bayes_nn(xs, ts; sigma = sigma, ps = ps, nn = nn)\n    # Sample the parameters\n    nparameters = Lux.parameterlength(nn_initial)\n    parameters ~ MvNormal(zeros(nparameters), Diagonal(abs2.(sigma .* ones(nparameters))))\n\n    # Forward NN to make predictions\n    preds = Lux.apply(nn, xs, vector_to_parameters(parameters, ps))\n\n    # Observe each prediction.\n    for i in eachindex(ts)\n        ts[i] ~ Bernoulli(preds[i])\n    end\nend\n\nUndefVarError: UndefVarError(:StatefulLuxLayer)\nUndefVarError: `StatefulLuxLayer` not defined\nStacktrace:\n [1] top-level scope\n   @ ~/work/docs/docs/tutorials/03-bayesian-neural-network/index.qmd:226\n\n\nInference can now be performed by calling sample. We use the NUTS Hamiltonian Monte Carlo sampler here.\n\nsetprogress!(false)\n\n\n# Perform inference.\nN = 2_000\nch = sample(bayes_nn(reduce(hcat, xs), ts), NUTS(; adtype=AutoTracker()), N);\n\nUndefVarError: \nUndefVarError: `bayes_nn` not defined\nStacktrace:\n [1] top-level scope\n   @ ~/work/docs/docs/tutorials/03-bayesian-neural-network/index.qmd:259\n\n\nNow we extract the parameter samples from the sampled chain as θ (this is of size 5000 x 20 where 5000 is the number of iterations and 20 is the number of parameters). We’ll use these primarily to determine how good our model’s classifier is.\n\n# Extract all weight and bias parameters.\nθ = MCMCChains.group(ch, :parameters).value;\n\nUndefVarError: \nUndefVarError: `ch` not defined\nStacktrace:\n [1] top-level scope\n   @ ~/work/docs/docs/tutorials/03-bayesian-neural-network/index.qmd:273",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Bayesian Neural Networks"
    ]
  },
  {
    "objectID": "tutorials/03-bayesian-neural-network/index.html#prediction-visualization",
    "href": "tutorials/03-bayesian-neural-network/index.html#prediction-visualization",
    "title": "Bayesian Neural Networks",
    "section": "Prediction Visualization",
    "text": "Prediction Visualization\nWe can use MAP estimation to classify our population by using the set of weights that provided the highest log posterior.\n\n# A helper to run the nn through data `x` using parameters `θ`\nnn_forward(x, θ) = nn(x, vector_to_parameters(θ, ps))\n\n# Plot the data we have.\nfig = plot_data()\n\n# Find the index that provided the highest log posterior in the chain.\n_, i = findmax(ch[:lp])\n\n# Extract the max row value from i.\ni = i.I[1]\n\n# Plot the posterior distribution with a contour plot\nx1_range = collect(range(-6; stop=6, length=25))\nx2_range = collect(range(-6; stop=6, length=25))\nZ = [nn_forward([x1, x2], θ[i, :])[1] for x1 in x1_range, x2 in x2_range]\ncontour!(x1_range, x2_range, Z; linewidth=3, colormap=:seaborn_bright)\nfig\n\nUndefVarError: UndefVarError(:ch)\nUndefVarError: `ch` not defined\nStacktrace:\n [1] top-level scope\n   @ ~/work/docs/docs/tutorials/03-bayesian-neural-network/index.qmd:295\n\n\nThe contour plot above shows that the MAP method is not too bad at classifying our data.\nNow we can visualize our predictions.\n\\[\np(\\tilde{x} | X, \\alpha) = \\int_{\\theta} p(\\tilde{x} | \\theta) p(\\theta | X, \\alpha) \\approx \\sum_{\\theta \\sim p(\\theta | X, \\alpha)}f_{\\theta}(\\tilde{x})\n\\]\nThe nn_predict function takes the average predicted value from a network parameterized by weights drawn from the MCMC chain.\n\n# Return the average predicted value across\n# multiple weights.\nfunction nn_predict(x, θ, num)\n    num = min(num, size(θ, 1))  # make sure num does not exceed the number of samples\n    return mean([first(nn_forward(x, view(θ, i, :))) for i in 1:10:num])\nend\n\nnn_predict (generic function with 1 method)\n\n\nNext, we use the nn_predict function to predict the value at a sample of points where the x1 and x2 coordinates range between -6 and 6. As we can see below, we still have a satisfactory fit to our data, and more importantly, we can also see where the neural network is uncertain about its predictions much easier—those regions between cluster boundaries.\n\n# Plot the average prediction.\nfig = plot_data()\n\nn_end = 1500\nx1_range = collect(range(-6; stop=6, length=25))\nx2_range = collect(range(-6; stop=6, length=25))\nZ = [nn_predict([x1, x2], θ, n_end)[1] for x1 in x1_range, x2 in x2_range]\ncontour!(x1_range, x2_range, Z; linewidth=3, colormap=:seaborn_bright)\nfig\n\nUndefVarError: UndefVarError(:θ)\nUndefVarError: `θ` not defined\nStacktrace:\n [1] (::var\"#20#21\")(::Tuple{Float64, Float64})\n   @ Main.Notebook ./none:0\n [2] iterate\n   @ ./generator.jl:47 [inlined]\n [3] collect(itr::Base.Generator{Base.Iterators.ProductIterator{Tuple{Vector{Float64}, Vector{Float64}}}, var\"#20#21\"})\n   @ Base ./array.jl:834\n [4] top-level scope\n   @ ~/work/docs/docs/tutorials/03-bayesian-neural-network/index.qmd:348\n\n\nSuppose we are interested in how the predictive power of our Bayesian neural network evolved between samples. In that case, the following graph displays an animation of the contour plot generated from the network weights in samples 1 to 1,000.\n\n# Number of iterations to plot.\nn_end = 500\n\nanim = @gif for i in 1:n_end\n    plot_data()\n    Z = [nn_forward([x1, x2], θ[i, :])[1] for x1 in x1_range, x2 in x2_range]\n    contour!(x1_range, x2_range, Z; title=\"Iteration $i\", clim=(0, 1))\nend every 5\n\nUndefVarError: UndefVarError(:θ)\nUndefVarError: `θ` not defined\nStacktrace:\n [1] (::var\"#22#23\"{Int64})(::Tuple{Float64, Float64})\n   @ Main.Notebook ./none:0\n [2] iterate\n   @ ./generator.jl:47 [inlined]\n [3] collect(itr::Base.Generator{Base.Iterators.ProductIterator{Tuple{Vector{Float64}, Vector{Float64}}}, var\"#22#23\"{Int64}})\n   @ Base ./array.jl:834\n [4] macro expansion\n   @ ~/work/docs/docs/tutorials/03-bayesian-neural-network/index.qmd:367 [inlined]\n [5] top-level scope\n   @ ~/.julia/packages/Plots/kLeqV/src/animation.jl:251\n\n\nThis has been an introduction to the applications of Turing and Lux in defining Bayesian neural networks.",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Bayesian Neural Networks"
    ]
  },
  {
    "objectID": "tutorials/docs-09-using-turing-advanced/index.html",
    "href": "tutorials/docs-09-using-turing-advanced/index.html",
    "title": "Advanced Usage",
    "section": "",
    "text": "This page has been separated into new sections. Please update any bookmarks you might have:\n\nCustom Distributions\nModifying the Log Probability\nDefining a Model without @model\nReparametrization and Generated Quantities\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tutorials/docs-13-using-turing-performance-tips/index.html",
    "href": "tutorials/docs-13-using-turing-performance-tips/index.html",
    "title": "Performance Tips",
    "section": "",
    "text": "This section briefly summarises a few common techniques to ensure good performance when using Turing. We refer to the Julia documentation for general techniques to ensure good performance of Julia programs.",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Performance Tips"
    ]
  },
  {
    "objectID": "tutorials/docs-13-using-turing-performance-tips/index.html#use-multivariate-distributions",
    "href": "tutorials/docs-13-using-turing-performance-tips/index.html#use-multivariate-distributions",
    "title": "Performance Tips",
    "section": "Use multivariate distributions",
    "text": "Use multivariate distributions\nIt is generally preferable to use multivariate distributions if possible.\nThe following example:\n\nusing Turing\n@model function gmodel(x)\n    m ~ Normal()\n    for i in 1:length(x)\n        x[i] ~ Normal(m, 0.2)\n    end\nend\n\ngmodel (generic function with 2 methods)\n\n\ncan be directly expressed more efficiently using a simple transformation:\n\nusing FillArrays\n\n@model function gmodel(x)\n    m ~ Normal()\n    return x ~ MvNormal(Fill(m, length(x)), 0.04 * I)\nend\n\ngmodel (generic function with 2 methods)",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Performance Tips"
    ]
  },
  {
    "objectID": "tutorials/docs-13-using-turing-performance-tips/index.html#choose-your-ad-backend",
    "href": "tutorials/docs-13-using-turing-performance-tips/index.html#choose-your-ad-backend",
    "title": "Performance Tips",
    "section": "Choose your AD backend",
    "text": "Choose your AD backend\nAutomatic differentiation (AD) makes it possible to use modern, efficient gradient-based samplers like NUTS and HMC, and that means a good AD system is incredibly important. Turing currently supports several AD backends, including ForwardDiff (the default), Zygote, ReverseDiff, and Tracker. Experimental support is also available for Tapir.\nFor many common types of models, the default ForwardDiff backend performs great, and there is no need to worry about changing it. However, if you need more speed, you can try different backends via the standard ADTypes interface by passing an AbstractADType to the sampler with the optional adtype argument, e.g. NUTS(adtype = AutoZygote()). See Automatic Differentiation for details. Generally, adtype = AutoForwardDiff() is likely to be the fastest and most reliable for models with few parameters (say, less than 20 or so), while reverse-mode backends such as AutoZygote() or AutoReverseDiff() will perform better for models with many parameters or linear algebra operations. If in doubt, it’s easy to try a few different backends to see how they compare.\n\nSpecial care for Zygote and Tracker\nNote that Zygote and Tracker will not perform well if your model contains for-loops, due to the way reverse-mode AD is implemented in these packages. Zygote also cannot differentiate code that contains mutating operations. If you can’t implement your model without for-loops or mutation, ReverseDiff will be a better, more performant option. In general, though, vectorized operations are still likely to perform best.\nAvoiding loops can be done using filldist(dist, N) and arraydist(dists). filldist(dist, N) creates a multivariate distribution that is composed of N identical and independent copies of the univariate distribution dist if dist is univariate, or it creates a matrix-variate distribution composed of N identical and independent copies of the multivariate distribution dist if dist is multivariate. filldist(dist, N, M) can also be used to create a matrix-variate distribution from a univariate distribution dist. arraydist(dists) is similar to filldist but it takes an array of distributions dists as input. Writing a custom distribution with a custom adjoint is another option to avoid loops.\n\n\nSpecial care for ReverseDiff with a compiled tape\nFor large models, the fastest option is often ReverseDiff with a compiled tape, specified as adtype=AutoReverseDiff(true). However, it is important to note that if your model contains any branching code, such as if-else statements, the gradients from a compiled tape may be inaccurate, leading to erroneous results. If you use this option for the (considerable) speedup it can provide, make sure to check your code. It’s also a good idea to verify your gradients with another backend.",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Performance Tips"
    ]
  },
  {
    "objectID": "tutorials/docs-13-using-turing-performance-tips/index.html#ensure-that-types-in-your-model-can-be-inferred",
    "href": "tutorials/docs-13-using-turing-performance-tips/index.html#ensure-that-types-in-your-model-can-be-inferred",
    "title": "Performance Tips",
    "section": "Ensure that types in your model can be inferred",
    "text": "Ensure that types in your model can be inferred\nFor efficient gradient-based inference, e.g. using HMC, NUTS or ADVI, it is important to ensure the types in your model can be inferred.\nThe following example with abstract types\n\n@model function tmodel(x, y)\n    p, n = size(x)\n    params = Vector{Real}(undef, n)\n    for i in 1:n\n        params[i] ~ truncated(Normal(), 0, Inf)\n    end\n\n    a = x * params\n    return y ~ MvNormal(a, I)\nend\n\ntmodel (generic function with 2 methods)\n\n\ncan be transformed into the following representation with concrete types:\n\n@model function tmodel(x, y, ::Type{T}=Float64) where {T}\n    p, n = size(x)\n    params = Vector{T}(undef, n)\n    for i in 1:n\n        params[i] ~ truncated(Normal(), 0, Inf)\n    end\n\n    a = x * params\n    return y ~ MvNormal(a, I)\nend\n\ntmodel (generic function with 4 methods)\n\n\nAlternatively, you could use filldist in this example:\n\n@model function tmodel(x, y)\n    params ~ filldist(truncated(Normal(), 0, Inf), size(x, 2))\n    a = x * params\n    return y ~ MvNormal(a, I)\nend\n\ntmodel (generic function with 4 methods)\n\n\nNote that you can use @code_warntype to find types in your model definition that the compiler cannot infer. They are marked in red in the Julia REPL.\nFor example, consider the following simple program:\n\n@model function tmodel(x)\n    p = Vector{Real}(undef, 1)\n    p[1] ~ Normal()\n    p = p .+ 1\n    return x ~ Normal(p[1])\nend\n\ntmodel (generic function with 6 methods)\n\n\nWe can use\n\nusing Random\n\nmodel = tmodel(1.0)\n\n@code_warntype model.f(\n    model,\n    Turing.VarInfo(model),\n    Turing.SamplingContext(\n        Random.default_rng(), Turing.SampleFromPrior(), Turing.DefaultContext()\n    ),\n    model.args...,\n)\n\nto inspect type inference in the model.",
    "crumbs": [
      "Get Started",
      "Users",
      "Usage Tips",
      "Performance Tips"
    ]
  },
  {
    "objectID": "tutorials/15-gaussian-processes/index.html",
    "href": "tutorials/15-gaussian-processes/index.html",
    "title": "Gaussian Processes",
    "section": "",
    "text": "JuliaGPs packages integrate well with Turing.jl because they implement the Distributions.jl interface. You should be able to understand what is going on in this tutorial if you know what a GP is. For a more in-depth understanding of the JuliaGPs functionality used here, please consult the JuliaGPs docs.\nIn this tutorial, we will model the putting dataset discussed in Chapter 21 of Bayesian Data Analysis. The dataset comprises the result of measuring how often a golfer successfully gets the ball in the hole, depending on how far away from it they are. The goal of inference is to estimate the probability of any given shot being successful at a given distance.\n\nLet’s download the data and take a look at it:\n\nusing CSV, DataDeps, DataFrames\n\nENV[\"DATADEPS_ALWAYS_ACCEPT\"] = true\nregister(\n    DataDep(\n        \"putting\",\n        \"Putting data from BDA\",\n        \"http://www.stat.columbia.edu/~gelman/book/data/golf.dat\",\n        \"fc28d83896af7094d765789714524d5a389532279b64902866574079c1a977cc\",\n    ),\n)\n\nfname = joinpath(datadep\"putting\", \"golf.dat\")\ndf = CSV.read(fname, DataFrame; delim=' ', ignorerepeated=true)\ndf[1:5, :]\n\n5×3 DataFrame\n\n\n\nRow\ndistance\nn\ny\n\n\n\nInt64\nInt64\nInt64\n\n\n\n\n1\n2\n1443\n1346\n\n\n2\n3\n694\n577\n\n\n3\n4\n455\n337\n\n\n4\n5\n353\n208\n\n\n5\n6\n272\n149\n\n\n\n\n\n\nWe’ve printed the first 5 rows of the dataset (which comprises only 19 rows in total). Observe it has three columns:\n\ndistance – how far away from the hole. I’ll refer to distance as d throughout the rest of this tutorial\nn – how many shots were taken from a given distance\ny – how many shots were successful from a given distance\n\nWe will use a Binomial model for the data, whose success probability is parametrised by a transformation of a GP. Something along the lines of: \\[\n\\begin{aligned}\nf & \\sim \\operatorname{GP}(0, k) \\\\\ny_j \\mid f(d_j) & \\sim \\operatorname{Binomial}(n_j, g(f(d_j))) \\\\\ng(x) & := \\frac{1}{1 + e^{-x}}\n\\end{aligned}\n\\]\nTo do this, let’s define our Turing.jl model:\n\nusing AbstractGPs, LogExpFunctions, Turing\n\n@model function putting_model(d, n; jitter=1e-4)\n    v ~ Gamma(2, 1)\n    l ~ Gamma(4, 1)\n    f = GP(v * with_lengthscale(SEKernel(), l))\n    f_latent ~ f(d, jitter)\n    y ~ product_distribution(Binomial.(n, logistic.(f_latent)))\n    return (fx=f(d, jitter), f_latent=f_latent, y=y)\nend\n\nputting_model (generic function with 2 methods)\n\n\nWe first define an AbstractGPs.GP, which represents a distribution over functions, and is entirely separate from Turing.jl. We place a prior over its variance v and length-scale l. f(d, jitter) constructs the multivariate Gaussian comprising the random variables in f whose indices are in d (plus a bit of independent Gaussian noise with variance jitter – see the docs for more details). f(d, jitter) has the type AbstractMvNormal, and is the bit of AbstractGPs.jl that implements the Distributions.jl interface, so it’s legal to put it on the right-hand side of a ~. From this you should deduce that f_latent is distributed according to a multivariate Gaussian. The remaining lines comprise standard Turing.jl code that is encountered in other tutorials and Turing documentation.\nBefore performing inference, we might want to inspect the prior that our model places over the data, to see whether there is anything obviously wrong. These kinds of prior predictive checks are straightforward to perform using Turing.jl, since it is possible to sample from the prior easily by just calling the model:\n\nm = putting_model(Float64.(df.distance), df.n)\nm().y\n\n19-element Vector{Int64}:\n 919\n 257\n 123\n 197\n 213\n 129\n 156\n 154\n  36\n  54\n 131\n  67\n  98\n  80\n  50\n  68\n  80\n  61\n   7\n\n\nWe make use of this to see what kinds of datasets we simulate from the prior:\n\nusing Plots\n\nfunction plot_data(d, n, y, xticks, yticks)\n    ylims = (0, round(maximum(n), RoundUp; sigdigits=2))\n    margin = -0.5 * Plots.mm\n    plt = plot(; xticks=xticks, yticks=yticks, ylims=ylims, margin=margin, grid=false)\n    bar!(plt, d, n; color=:red, label=\"\", alpha=0.5)\n    bar!(plt, d, y; label=\"\", color=:blue, alpha=0.7)\n    return plt\nend\n\n# Construct model and run some prior predictive checks.\nm = putting_model(Float64.(df.distance), df.n)\nhists = map(1:20) do j\n    xticks = j &gt; 15 ? :auto : nothing\n    yticks = rem(j, 5) == 1 ? :auto : nothing\n    return plot_data(df.distance, df.n, m().y, xticks, yticks)\nend\nplot(hists...; layout=(4, 5))\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this case, the only prior knowledge I have is that the proportion of successful shots ought to decrease monotonically as the distance from the hole increases, which should show up in the data as the blue lines generally go down as we move from left to right on each graph. Unfortunately, there is not a simple way to enforce monotonicity in the samples from a GP, and we can see this in some of the plots above, so we must hope that we have enough data to ensure that this relationship holds approximately under the posterior. In any case, you can judge for yourself whether you think this is the most useful visualisation that we can perform – if you think there is something better to look at, please let us know!\nMoving on, we generate samples from the posterior using the default NUTS sampler. We’ll make use of ReverseDiff.jl, as it has better performance than ForwardDiff.jl on this example. See Turing.jl’s docs on Automatic Differentiation for more info.\n\nusing Random, ReverseDiff\n\nm_post = m | (y=df.y,)\nchn = sample(Xoshiro(123456), m_post, NUTS(; adtype=AutoReverseDiff()), 1_000, progress=false)\n\n┌ Info: Found initial step size\n└   ϵ = 0.2\n\n\nChains MCMC chain (1000×33×1 Array{Float64, 3}):\n\nIterations        = 501:1:1500\nNumber of chains  = 1\nSamples per chain = 1000\nWall duration     = 71.12 seconds\nCompute duration  = 71.12 seconds\nparameters        = v, l, f_latent[1], f_latent[2], f_latent[3], f_latent[4], f_latent[5], f_latent[6], f_latent[7], f_latent[8], f_latent[9], f_latent[10], f_latent[11], f_latent[12], f_latent[13], f_latent[14], f_latent[15], f_latent[16], f_latent[17], f_latent[18], f_latent[19]\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n    parameters      mean       std      mcse    ess_bulk   ess_tail      rhat  ⋯\n        Symbol   Float64   Float64   Float64     Float64    Float64   Float64  ⋯\n\n             v    2.8600    1.3028    0.0417    918.2550   717.5566    1.0001  ⋯\n             l    3.5798    0.8554    0.0631    177.0742   219.2957    1.0062  ⋯\n   f_latent[1]    2.5512    0.1017    0.0029   1213.8603   401.2582    1.0050  ⋯\n   f_latent[2]    1.7058    0.0718    0.0020   1318.8268   732.6694    1.0030  ⋯\n   f_latent[3]    0.9728    0.0787    0.0034    553.0865   583.8339    1.0019  ⋯\n   f_latent[4]    0.4751    0.0776    0.0032    582.2141   654.6469    1.0009  ⋯\n   f_latent[5]    0.1921    0.0745    0.0022   1135.7254   716.0834    1.0005  ⋯\n   f_latent[6]   -0.0086    0.0895    0.0044    409.7724   405.8487    0.9992  ⋯\n   f_latent[7]   -0.2392    0.0880    0.0033    694.7892   481.4659    0.9991  ⋯\n   f_latent[8]   -0.5027    0.0905    0.0033    743.6810   589.3439    0.9990  ⋯\n   f_latent[9]   -0.7235    0.0984    0.0042    530.8329   580.1962    1.0004  ⋯\n  f_latent[10]   -0.8647    0.0958    0.0035    742.7441   624.4842    1.0043  ⋯\n  f_latent[11]   -0.9459    0.0939    0.0028   1092.2843   739.5350    0.9994  ⋯\n  f_latent[12]   -1.0314    0.1077    0.0039    761.7264   691.7446    1.0020  ⋯\n  f_latent[13]   -1.1816    0.1131    0.0049    528.9246   675.1217    1.0030  ⋯\n  f_latent[14]   -1.3997    0.1131    0.0037    954.8557   813.1763    1.0015  ⋯\n  f_latent[15]   -1.6072    0.1233    0.0048    698.4308   561.3113    0.9997  ⋯\n       ⋮            ⋮         ⋮         ⋮          ⋮          ⋮          ⋮     ⋱\n                                                     1 column and 4 rows omitted\n\nQuantiles\n    parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n        Symbol   Float64   Float64   Float64   Float64   Float64\n\n             v    1.0788    1.8992    2.6231    3.5424    5.9576\n             l    2.2506    3.0621    3.4208    3.9185    5.8926\n   f_latent[1]    2.3614    2.4826    2.5493    2.6219    2.7460\n   f_latent[2]    1.5603    1.6552    1.7069    1.7547    1.8390\n   f_latent[3]    0.8258    0.9224    0.9721    1.0268    1.1242\n   f_latent[4]    0.3207    0.4197    0.4770    0.5263    0.6302\n   f_latent[5]    0.0543    0.1406    0.1907    0.2438    0.3468\n   f_latent[6]   -0.1785   -0.0730   -0.0085    0.0479    0.1721\n   f_latent[7]   -0.3943   -0.3020   -0.2452   -0.1789   -0.0654\n   f_latent[8]   -0.6816   -0.5592   -0.5040   -0.4419   -0.3314\n   f_latent[9]   -0.9291   -0.7900   -0.7182   -0.6559   -0.5371\n  f_latent[10]   -1.0533   -0.9350   -0.8625   -0.7985   -0.6830\n  f_latent[11]   -1.1241   -1.0075   -0.9468   -0.8839   -0.7615\n  f_latent[12]   -1.2389   -1.1050   -1.0347   -0.9639   -0.8068\n  f_latent[13]   -1.3859   -1.2615   -1.1862   -1.1076   -0.9674\n  f_latent[14]   -1.6098   -1.4756   -1.4042   -1.3222   -1.1762\n  f_latent[15]   -1.8550   -1.6856   -1.6030   -1.5216   -1.3780\n       ⋮            ⋮         ⋮         ⋮         ⋮         ⋮\n                                                    4 rows omitted\n\n\nWe can use these samples and the posterior function from AbstractGPs to sample from the posterior probability of success at any distance we choose:\n\nd_pred = 1:0.2:21\nsamples = map(generated_quantities(m_post, chn)[1:10:end]) do x\n    return logistic.(rand(posterior(x.fx, x.f_latent)(d_pred, 1e-4)))\nend\np = plot()\nplot!(d_pred, reduce(hcat, samples); label=\"\", color=:blue, alpha=0.2)\nscatter!(df.distance, df.y ./ df.n; label=\"\", color=:red)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can see that the general trend is indeed down as the distance from the hole increases, and that if we move away from the data, the posterior uncertainty quickly inflates. This suggests that the model is probably going to do a reasonable job of interpolating between observed data, but less good a job at extrapolating to larger distances.\n\n\n\n\n Back to top",
    "crumbs": [
      "Get Started",
      "Users",
      "Tutorials",
      "Introduction to Gaussian Processes"
    ]
  },
  {
    "objectID": "tutorials/docs-00-getting-started/index.html",
    "href": "tutorials/docs-00-getting-started/index.html",
    "title": "Getting Started",
    "section": "",
    "text": "Installation\nTo use Turing, you need to install Julia first and then install Turing.\nYou will need to install Julia 1.7 or greater, which you can get from the official Julia website.\nTuring is officially registered in the Julia General package registry, which means that you can install a stable version of Turing by running the following in the Julia REPL:\n\nusing Pkg\nPkg.add(\"Turing\")\n\n\n\nExample usage\nFirst, we load the Turing and StatsPlots modules. The latter is required for visualising the results.\n\nusing Turing\nusing StatsPlots\n\nWe then specify our model, which is a simple Gaussian model with unknown mean and variance. Models are defined as ordinary Julia functions, prefixed with the @model macro. Each statement inside closely resembles how the model would be defined with mathematical notation. Here, both x and y are observed values, and are therefore passed as function parameters. m and s² are the parameters to be inferred.\n\n@model function gdemo(x, y)\n    s² ~ InverseGamma(2, 3)\n    m ~ Normal(0, sqrt(s²))\n    x ~ Normal(m, sqrt(s²))\n    y ~ Normal(m, sqrt(s²))\nend\n\ngdemo (generic function with 2 methods)\n\n\nSuppose we observe x = 1.5 and y = 2, and want to infer the mean and variance. We can pass these data as arguments to the gdemo function, and run a sampler to collect the results. Here, we collect 1000 samples using the No U-Turn Sampler (NUTS) algorithm.\n\nchain = sample(gdemo(1.5, 2), NUTS(), 1000, progress=false)\n\n┌ Info: Found initial step size\n└   ϵ = 1.6\n\n\nChains MCMC chain (1000×14×1 Array{Float64, 3}):\n\nIterations        = 501:1:1500\nNumber of chains  = 1\nSamples per chain = 1000\nWall duration     = 6.65 seconds\nCompute duration  = 6.65 seconds\nparameters        = s², m\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n          s²    2.0128    1.7216    0.0737   555.1546   660.7247    1.0030     ⋯\n           m    1.1631    0.8472    0.0439   360.0101   383.9655    1.0074     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n          s²    0.5553    1.0862    1.5605    2.3355    5.8964\n           m   -0.4077    0.6376    1.1144    1.6792    2.7491\n\n\nWe can plot the results:\n\nplot(chain)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nand obtain summary statistics by indexing the chain:\n\nmean(chain[:m]), mean(chain[:s²])\n\n(1.1631449337355326, 2.0128379856425322)\n\n\n\n\nWhere to go next\n\n\n\n\n\n\nNote on prerequisites\n\n\n\nFamiliarity with Julia is assumed throughout the Turing documentation. If you are new to Julia, Learning Julia is a good starting point.\nThe underlying theory of Bayesian machine learning is not explained in detail in this documentation. A thorough introduction to the field is Pattern Recognition and Machine Learning (Bishop, 2006); an online version is available here (PDF, 18.1 MB).\n\n\nThe next page on Turing’s core functionality explains the basic features of the Turing language. From there, you can either look at worked examples of how different models are implemented in Turing, or specific tips and tricks that can help you get the most out of Turing.\n\n\n\n\n Back to top",
    "crumbs": [
      "Get Started",
      "Users",
      "Getting Started"
    ]
  },
  {
    "objectID": "tutorials/docs-06-for-developers-interface/index.html",
    "href": "tutorials/docs-06-for-developers-interface/index.html",
    "title": "Interface Guide",
    "section": "",
    "text": "Turing implements a sampling interface (hosted at AbstractMCMC) that is intended to provide a common framework for Markov chain Monte Carlo samplers. The interface presents several structures and functions that one needs to overload in order to implement an interface-compatible sampler.\nThis guide will demonstrate how to implement the interface without Turing.\n\n\nAny implementation of an inference method that uses the AbstractMCMC interface should implement a subset of the following types and functions:\n\nA subtype of AbstractSampler, defined as a mutable struct containing state information or sampler parameters.\nA function sample_init! which performs any necessary set-up (default: do not perform any set-up).\nA function step! which returns a transition that represents a single draw from the sampler.\nA function transitions_init which returns a container for the transitions obtained from the sampler (default: return a Vector{T} of length N where T is the type of the transition obtained in the first step and N is the number of requested samples).\nA function transitions_save! which saves transitions to the container (default: save the transition of iteration i at position i in the vector of transitions).\nA function sample_end! which handles any sampler wrap-up (default: do not perform any wrap-up).\nA function bundle_samples which accepts the container of transitions and returns a collection of samples (default: return the vector of transitions).\n\nThe interface methods with exclamation points are those that are intended to allow for state mutation. Any mutating function is meant to allow mutation where needed – you might use:\n\nsample_init! to run some kind of sampler preparation, before sampling begins. This could mutate a sampler’s state.\nstep! might mutate a sampler flag after each sample.\nsample_end! contains any wrap-up you might need to do. If you were sampling in a transformed space, this might be where you convert everything back to a constrained space.\n\n\n\n\nThe motivation for the interface is to allow Julia’s fantastic probabilistic programming language community to have a set of standards and common implementations so we can all thrive together. Markov chain Monte Carlo methods tend to have a very similar framework to one another, and so a common interface should help more great inference methods built in single-purpose packages to experience more use among the community.\n\n\n\nMetropolis-Hastings is often the first sampling method that people are exposed to. It is a very straightforward algorithm and is accordingly the easiest to implement, so it makes for a good example. In this section, you will learn how to use the types and functions listed above to implement the Metropolis-Hastings sampler using the MCMC interface.\nThe full code for this implementation is housed in AdvancedMH.jl.\n\n\nLet’s begin by importing the relevant libraries. We’ll import AbstractMCMC, which contains the interface framework we’ll fill out. We also need Distributions and Random.\n\n# Import the relevant libraries.\nusing AbstractMCMC: AbstractMCMC\nusing Distributions\nusing Random\n\nAn interface extension (like the one we’re writing right now) typically requires that you overload or implement several functions. Specifically, you should import the functions you intend to overload. This next code block accomplishes that.\nFrom Distributions, we need Sampleable, VariateForm, and ValueSupport, three abstract types that define a distribution. Models in the interface are assumed to be subtypes of Sampleable{VariateForm, ValueSupport}. In this section our model is going be be extremely simple, so we will not end up using these except to make sure that the inference functions are dispatching correctly.\n\n\n\nLet’s begin our sampler definition by defining a sampler called MetropolisHastings which is a subtype of AbstractSampler. Correct typing is very important for proper interface implementation – if you are missing a subtype, your method may not be dispatched to when you call sample.\n\n# Define a sampler type.\nstruct MetropolisHastings{T,D} &lt;: AbstractMCMC.AbstractSampler\n    init_θ::T\n    proposal::D\nend\n\n# Default constructors.\nMetropolisHastings(init_θ::Real) = MetropolisHastings(init_θ, Normal(0, 1))\nfunction MetropolisHastings(init_θ::Vector{&lt;:Real})\n    return MetropolisHastings(init_θ, MvNormal(zero(init_θ), I))\nend\n\nMetropolisHastings\n\n\nAbove, we have defined a sampler that stores the initial parameterization of the prior, and a distribution object from which proposals are drawn. You can have a struct that has no fields, and simply use it for dispatching onto the relevant functions, or you can store a large amount of state information in your sampler.\nThe general intuition for what to store in your sampler struct is that anything you may need to perform inference between samples but you don’t want to store in a transition should go into the sampler struct. It’s the only way you can carry non-sample related state information between step! calls.\n\n\n\nNext, we need to have a model of some kind. A model is a struct that’s a subtype of AbstractModel that contains whatever information is necessary to perform inference on your problem. In our case we want to know the mean and variance parameters for a standard Normal distribution, so we can keep our model to the log density of a Normal.\nNote that we only have to do this because we are not yet integrating the sampler with Turing – Turing has a very sophisticated modelling engine that removes the need to define custom model structs.\n\n# Define a model type. Stores the log density function.\nstruct DensityModel{F&lt;:Function} &lt;: AbstractMCMC.AbstractModel\n    ℓπ::F\nend\n\n\n\n\nThe next step is to define some transition which we will return from each step! call. We’ll keep it simple by just defining a wrapper struct that contains the parameter draws and the log density of that draw:\n\n# Create a very basic Transition type, only stores the \n# parameter draws and the log probability of the draw.\nstruct Transition{T,L}\n    θ::T\n    lp::L\nend\n\n# Store the new draw and its log density.\nTransition(model::DensityModel, θ) = Transition(θ, ℓπ(model, θ))\n\nTransition\n\n\nTransition can now store any type of parameter, whether it’s a vector of draws from multiple parameters or a single univariate draw.\n\n\n\nNow it’s time to get into the actual inference. We’ve defined all of the core pieces we need, but we need to implement the step! function which actually performs inference.\nAs a refresher, Metropolis-Hastings implements a very basic algorithm:\n\nPick some initial state, \\theta_0.\nFor t in [1,N], do\n\nGenerate a proposal parameterization \\theta^\\prime_t \\sim q(\\theta^\\prime_t \\mid \\theta_{t-1}).\nCalculate the acceptance probability, \\alpha = \\text{min}\\left[1,\\frac{\\pi(\\theta'_t)}{\\pi(\\theta_{t-1})} \\frac{q(\\theta_{t-1} \\mid \\theta'_t)}{q(\\theta'_t \\mid \\theta_{t-1})}) \\right].\nIf U \\le \\alpha where U \\sim [0,1], then \\theta_t = \\theta'_t. Otherwise, \\theta_t = \\theta_{t-1}.\n\n\nOf course, it’s much easier to do this in the log space, so the acceptance probability is more commonly written as\n\\log \\alpha = \\min\\left[0, \\log \\pi(\\theta'_t) - \\log \\pi(\\theta_{t-1}) + \\log q(\\theta_{t-1} \\mid \\theta^\\prime_t) - \\log q(\\theta\\prime_t \\mid \\theta_{t-1}) \\right].\nIn interface terms, we should do the following:\n\nMake a new transition containing a proposed sample.\nCalculate the acceptance probability.\nIf we accept, return the new transition, otherwise, return the old one.\n\n\n\n\nThe step! function is the function that performs the bulk of your inference. In our case, we will implement two step! functions – one for the very first iteration, and one for every subsequent iteration.\n\n# Define the first step! function, which is called at the \n# beginning of sampling. Return the initial parameter used\n# to define the sampler.\nfunction AbstractMCMC.step!(\n    rng::AbstractRNG,\n    model::DensityModel,\n    spl::MetropolisHastings,\n    N::Integer,\n    ::Nothing;\n    kwargs...,\n)\n    return Transition(model, spl.init_θ)\nend\n\nThe first step! function just packages up the initial parameterization inside the sampler, and returns it. We implicitly accept the very first parameterization.\nThe other step! function performs the usual steps from Metropolis-Hastings. Included are several helper functions, proposal and q, which are designed to replicate the functions in the pseudocode above.\n\nproposal generates a new proposal in the form of a Transition, which can be univariate if the value passed in is univariate, or it can be multivariate if the Transition given is multivariate. Proposals use a basic Normal or MvNormal proposal distribution.\nq returns the log density of one parameterization conditional on another, according to the proposal distribution.\nstep! generates a new proposal, checks the acceptance probability, and then returns either the previous transition or the proposed transition.\n\n\n# Define a function that makes a basic proposal depending on a univariate\n# parameterization or a multivariate parameterization.\nfunction propose(spl::MetropolisHastings, model::DensityModel, θ::Real)\n    return Transition(model, θ + rand(spl.proposal))\nend\nfunction propose(spl::MetropolisHastings, model::DensityModel, θ::Vector{&lt;:Real})\n    return Transition(model, θ + rand(spl.proposal))\nend\nfunction propose(spl::MetropolisHastings, model::DensityModel, t::Transition)\n    return propose(spl, model, t.θ)\nend\n\n# Calculates the probability `q(θ|θcond)`, using the proposal distribution `spl.proposal`.\nq(spl::MetropolisHastings, θ::Real, θcond::Real) = logpdf(spl.proposal, θ - θcond)\nfunction q(spl::MetropolisHastings, θ::Vector{&lt;:Real}, θcond::Vector{&lt;:Real})\n    return logpdf(spl.proposal, θ - θcond)\nend\nq(spl::MetropolisHastings, t1::Transition, t2::Transition) = q(spl, t1.θ, t2.θ)\n\n# Calculate the density of the model given some parameterization.\nℓπ(model::DensityModel, θ) = model.ℓπ(θ)\nℓπ(model::DensityModel, t::Transition) = t.lp\n\n# Define the other step function. Returns a Transition containing\n# either a new proposal (if accepted) or the previous proposal \n# (if not accepted).\nfunction AbstractMCMC.step!(\n    rng::AbstractRNG,\n    model::DensityModel,\n    spl::MetropolisHastings,\n    ::Integer,\n    θ_prev::Transition;\n    kwargs...,\n)\n    # Generate a new proposal.\n    θ = propose(spl, model, θ_prev)\n\n    # Calculate the log acceptance probability.\n    α = ℓπ(model, θ) - ℓπ(model, θ_prev) + q(spl, θ_prev, θ) - q(spl, θ, θ_prev)\n\n    # Decide whether to return the previous θ or the new one.\n    if log(rand(rng)) &lt; min(α, 0.0)\n        return θ\n    else\n        return θ_prev\n    end\nend\n\n\n\n\nIn the default implementation, sample just returns a vector of all transitions. If instead you would like to obtain a Chains object (e.g., to simplify downstream analysis), you have to implement the bundle_samples function as well. It accepts the vector of transitions and returns a collection of samples. Fortunately, our Transition is incredibly simple, and we only need to build a little bit of functionality to accept custom parameter names passed in by the user.\n\n# A basic chains constructor that works with the Transition struct we defined.\nfunction AbstractMCMC.bundle_samples(\n    rng::AbstractRNG,\n    ℓ::DensityModel,\n    s::MetropolisHastings,\n    N::Integer,\n    ts::Vector{&lt;:Transition},\n    chain_type::Type{Any};\n    param_names=missing,\n    kwargs...,\n)\n    # Turn all the transitions into a vector-of-vectors.\n    vals = copy(reduce(hcat, [vcat(t.θ, t.lp) for t in ts])')\n\n    # Check if we received any parameter names.\n    if ismissing(param_names)\n        param_names = [\"Parameter $i\" for i in 1:(length(first(vals)) - 1)]\n    end\n\n    # Add the log density field to the parameter names.\n    push!(param_names, \"lp\")\n\n    # Bundle everything up and return a Chains struct.\n    return Chains(vals, param_names, (internals=[\"lp\"],))\nend\n\nAll done!\nYou can even implement different output formats by implementing bundle_samples for different chain_types, which can be provided as keyword argument to sample. As default sample uses chain_type = Any.\n\n\n\nNow that we have all the pieces, we should test the implementation by defining a model to calculate the mean and variance parameters of a Normal distribution. We can do this by constructing a target density function, providing a sample of data, and then running the sampler with sample.\n\n# Generate a set of data from the posterior we want to estimate.\ndata = rand(Normal(5, 3), 30)\n\n# Define the components of a basic model.\ninsupport(θ) = θ[2] &gt;= 0\ndist(θ) = Normal(θ[1], θ[2])\ndensity(θ) = insupport(θ) ? sum(logpdf.(dist(θ), data)) : -Inf\n\n# Construct a DensityModel.\nmodel = DensityModel(density)\n\n# Set up our sampler with initial parameters.\nspl = MetropolisHastings([0.0, 0.0])\n\n# Sample from the posterior.\nchain = sample(model, spl, 100000; param_names=[\"μ\", \"σ\"])\n\nIf all the interface functions have been extended properly, you should get an output from display(chain) that looks something like this:\nObject of type Chains, with data of type 100000×3×1 Array{Float64,3}\n\nIterations        = 1:100000\nThinning interval = 1\nChains            = 1\nSamples per chain = 100000\ninternals         = lp\nparameters        = μ, σ\n\n2-element Array{ChainDataFrame,1}\n\nSummary Statistics\n\n│ Row │ parameters │ mean    │ std      │ naive_se   │ mcse       │ ess     │ r_hat   │\n│     │ Symbol     │ Float64 │ Float64  │ Float64    │ Float64    │ Any     │ Any     │\n├─────┼────────────┼─────────┼──────────┼────────────┼────────────┼─────────┼─────────┤\n│ 1   │ μ          │ 5.33157 │ 0.854193 │ 0.0027012  │ 0.00893069 │ 8344.75 │ 1.00009 │\n│ 2   │ σ          │ 4.54992 │ 0.632916 │ 0.00200146 │ 0.00534942 │ 14260.8 │ 1.00005 │\n\nQuantiles\n\n│ Row │ parameters │ 2.5%    │ 25.0%   │ 50.0%   │ 75.0%   │ 97.5%   │\n│     │ Symbol     │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │\n├─────┼────────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n│ 1   │ μ          │ 3.6595  │ 4.77754 │ 5.33182 │ 5.89509 │ 6.99651 │\n│ 2   │ σ          │ 3.5097  │ 4.09732 │ 4.47805 │ 4.93094 │ 5.96821 │\nIt looks like we’re extremely close to our true parameters of Normal(5,3), though with a fairly high variance due to the low sample size.\n\n\n\n\nWe’ve seen how to implement the sampling interface for general projects. Turing’s interface methods are ever-evolving, so please open an issue at AbstractMCMC with feature requests or problems.",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "Interface Guide"
    ]
  },
  {
    "objectID": "tutorials/docs-06-for-developers-interface/index.html#interface-overview",
    "href": "tutorials/docs-06-for-developers-interface/index.html#interface-overview",
    "title": "Interface Guide",
    "section": "",
    "text": "Any implementation of an inference method that uses the AbstractMCMC interface should implement a subset of the following types and functions:\n\nA subtype of AbstractSampler, defined as a mutable struct containing state information or sampler parameters.\nA function sample_init! which performs any necessary set-up (default: do not perform any set-up).\nA function step! which returns a transition that represents a single draw from the sampler.\nA function transitions_init which returns a container for the transitions obtained from the sampler (default: return a Vector{T} of length N where T is the type of the transition obtained in the first step and N is the number of requested samples).\nA function transitions_save! which saves transitions to the container (default: save the transition of iteration i at position i in the vector of transitions).\nA function sample_end! which handles any sampler wrap-up (default: do not perform any wrap-up).\nA function bundle_samples which accepts the container of transitions and returns a collection of samples (default: return the vector of transitions).\n\nThe interface methods with exclamation points are those that are intended to allow for state mutation. Any mutating function is meant to allow mutation where needed – you might use:\n\nsample_init! to run some kind of sampler preparation, before sampling begins. This could mutate a sampler’s state.\nstep! might mutate a sampler flag after each sample.\nsample_end! contains any wrap-up you might need to do. If you were sampling in a transformed space, this might be where you convert everything back to a constrained space.",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "Interface Guide"
    ]
  },
  {
    "objectID": "tutorials/docs-06-for-developers-interface/index.html#why-do-you-have-an-interface",
    "href": "tutorials/docs-06-for-developers-interface/index.html#why-do-you-have-an-interface",
    "title": "Interface Guide",
    "section": "",
    "text": "The motivation for the interface is to allow Julia’s fantastic probabilistic programming language community to have a set of standards and common implementations so we can all thrive together. Markov chain Monte Carlo methods tend to have a very similar framework to one another, and so a common interface should help more great inference methods built in single-purpose packages to experience more use among the community.",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "Interface Guide"
    ]
  },
  {
    "objectID": "tutorials/docs-06-for-developers-interface/index.html#implementing-metropolis-hastings-without-turing",
    "href": "tutorials/docs-06-for-developers-interface/index.html#implementing-metropolis-hastings-without-turing",
    "title": "Interface Guide",
    "section": "",
    "text": "Metropolis-Hastings is often the first sampling method that people are exposed to. It is a very straightforward algorithm and is accordingly the easiest to implement, so it makes for a good example. In this section, you will learn how to use the types and functions listed above to implement the Metropolis-Hastings sampler using the MCMC interface.\nThe full code for this implementation is housed in AdvancedMH.jl.\n\n\nLet’s begin by importing the relevant libraries. We’ll import AbstractMCMC, which contains the interface framework we’ll fill out. We also need Distributions and Random.\n\n# Import the relevant libraries.\nusing AbstractMCMC: AbstractMCMC\nusing Distributions\nusing Random\n\nAn interface extension (like the one we’re writing right now) typically requires that you overload or implement several functions. Specifically, you should import the functions you intend to overload. This next code block accomplishes that.\nFrom Distributions, we need Sampleable, VariateForm, and ValueSupport, three abstract types that define a distribution. Models in the interface are assumed to be subtypes of Sampleable{VariateForm, ValueSupport}. In this section our model is going be be extremely simple, so we will not end up using these except to make sure that the inference functions are dispatching correctly.\n\n\n\nLet’s begin our sampler definition by defining a sampler called MetropolisHastings which is a subtype of AbstractSampler. Correct typing is very important for proper interface implementation – if you are missing a subtype, your method may not be dispatched to when you call sample.\n\n# Define a sampler type.\nstruct MetropolisHastings{T,D} &lt;: AbstractMCMC.AbstractSampler\n    init_θ::T\n    proposal::D\nend\n\n# Default constructors.\nMetropolisHastings(init_θ::Real) = MetropolisHastings(init_θ, Normal(0, 1))\nfunction MetropolisHastings(init_θ::Vector{&lt;:Real})\n    return MetropolisHastings(init_θ, MvNormal(zero(init_θ), I))\nend\n\nMetropolisHastings\n\n\nAbove, we have defined a sampler that stores the initial parameterization of the prior, and a distribution object from which proposals are drawn. You can have a struct that has no fields, and simply use it for dispatching onto the relevant functions, or you can store a large amount of state information in your sampler.\nThe general intuition for what to store in your sampler struct is that anything you may need to perform inference between samples but you don’t want to store in a transition should go into the sampler struct. It’s the only way you can carry non-sample related state information between step! calls.\n\n\n\nNext, we need to have a model of some kind. A model is a struct that’s a subtype of AbstractModel that contains whatever information is necessary to perform inference on your problem. In our case we want to know the mean and variance parameters for a standard Normal distribution, so we can keep our model to the log density of a Normal.\nNote that we only have to do this because we are not yet integrating the sampler with Turing – Turing has a very sophisticated modelling engine that removes the need to define custom model structs.\n\n# Define a model type. Stores the log density function.\nstruct DensityModel{F&lt;:Function} &lt;: AbstractMCMC.AbstractModel\n    ℓπ::F\nend\n\n\n\n\nThe next step is to define some transition which we will return from each step! call. We’ll keep it simple by just defining a wrapper struct that contains the parameter draws and the log density of that draw:\n\n# Create a very basic Transition type, only stores the \n# parameter draws and the log probability of the draw.\nstruct Transition{T,L}\n    θ::T\n    lp::L\nend\n\n# Store the new draw and its log density.\nTransition(model::DensityModel, θ) = Transition(θ, ℓπ(model, θ))\n\nTransition\n\n\nTransition can now store any type of parameter, whether it’s a vector of draws from multiple parameters or a single univariate draw.\n\n\n\nNow it’s time to get into the actual inference. We’ve defined all of the core pieces we need, but we need to implement the step! function which actually performs inference.\nAs a refresher, Metropolis-Hastings implements a very basic algorithm:\n\nPick some initial state, \\theta_0.\nFor t in [1,N], do\n\nGenerate a proposal parameterization \\theta^\\prime_t \\sim q(\\theta^\\prime_t \\mid \\theta_{t-1}).\nCalculate the acceptance probability, \\alpha = \\text{min}\\left[1,\\frac{\\pi(\\theta'_t)}{\\pi(\\theta_{t-1})} \\frac{q(\\theta_{t-1} \\mid \\theta'_t)}{q(\\theta'_t \\mid \\theta_{t-1})}) \\right].\nIf U \\le \\alpha where U \\sim [0,1], then \\theta_t = \\theta'_t. Otherwise, \\theta_t = \\theta_{t-1}.\n\n\nOf course, it’s much easier to do this in the log space, so the acceptance probability is more commonly written as\n\\log \\alpha = \\min\\left[0, \\log \\pi(\\theta'_t) - \\log \\pi(\\theta_{t-1}) + \\log q(\\theta_{t-1} \\mid \\theta^\\prime_t) - \\log q(\\theta\\prime_t \\mid \\theta_{t-1}) \\right].\nIn interface terms, we should do the following:\n\nMake a new transition containing a proposed sample.\nCalculate the acceptance probability.\nIf we accept, return the new transition, otherwise, return the old one.\n\n\n\n\nThe step! function is the function that performs the bulk of your inference. In our case, we will implement two step! functions – one for the very first iteration, and one for every subsequent iteration.\n\n# Define the first step! function, which is called at the \n# beginning of sampling. Return the initial parameter used\n# to define the sampler.\nfunction AbstractMCMC.step!(\n    rng::AbstractRNG,\n    model::DensityModel,\n    spl::MetropolisHastings,\n    N::Integer,\n    ::Nothing;\n    kwargs...,\n)\n    return Transition(model, spl.init_θ)\nend\n\nThe first step! function just packages up the initial parameterization inside the sampler, and returns it. We implicitly accept the very first parameterization.\nThe other step! function performs the usual steps from Metropolis-Hastings. Included are several helper functions, proposal and q, which are designed to replicate the functions in the pseudocode above.\n\nproposal generates a new proposal in the form of a Transition, which can be univariate if the value passed in is univariate, or it can be multivariate if the Transition given is multivariate. Proposals use a basic Normal or MvNormal proposal distribution.\nq returns the log density of one parameterization conditional on another, according to the proposal distribution.\nstep! generates a new proposal, checks the acceptance probability, and then returns either the previous transition or the proposed transition.\n\n\n# Define a function that makes a basic proposal depending on a univariate\n# parameterization or a multivariate parameterization.\nfunction propose(spl::MetropolisHastings, model::DensityModel, θ::Real)\n    return Transition(model, θ + rand(spl.proposal))\nend\nfunction propose(spl::MetropolisHastings, model::DensityModel, θ::Vector{&lt;:Real})\n    return Transition(model, θ + rand(spl.proposal))\nend\nfunction propose(spl::MetropolisHastings, model::DensityModel, t::Transition)\n    return propose(spl, model, t.θ)\nend\n\n# Calculates the probability `q(θ|θcond)`, using the proposal distribution `spl.proposal`.\nq(spl::MetropolisHastings, θ::Real, θcond::Real) = logpdf(spl.proposal, θ - θcond)\nfunction q(spl::MetropolisHastings, θ::Vector{&lt;:Real}, θcond::Vector{&lt;:Real})\n    return logpdf(spl.proposal, θ - θcond)\nend\nq(spl::MetropolisHastings, t1::Transition, t2::Transition) = q(spl, t1.θ, t2.θ)\n\n# Calculate the density of the model given some parameterization.\nℓπ(model::DensityModel, θ) = model.ℓπ(θ)\nℓπ(model::DensityModel, t::Transition) = t.lp\n\n# Define the other step function. Returns a Transition containing\n# either a new proposal (if accepted) or the previous proposal \n# (if not accepted).\nfunction AbstractMCMC.step!(\n    rng::AbstractRNG,\n    model::DensityModel,\n    spl::MetropolisHastings,\n    ::Integer,\n    θ_prev::Transition;\n    kwargs...,\n)\n    # Generate a new proposal.\n    θ = propose(spl, model, θ_prev)\n\n    # Calculate the log acceptance probability.\n    α = ℓπ(model, θ) - ℓπ(model, θ_prev) + q(spl, θ_prev, θ) - q(spl, θ, θ_prev)\n\n    # Decide whether to return the previous θ or the new one.\n    if log(rand(rng)) &lt; min(α, 0.0)\n        return θ\n    else\n        return θ_prev\n    end\nend\n\n\n\n\nIn the default implementation, sample just returns a vector of all transitions. If instead you would like to obtain a Chains object (e.g., to simplify downstream analysis), you have to implement the bundle_samples function as well. It accepts the vector of transitions and returns a collection of samples. Fortunately, our Transition is incredibly simple, and we only need to build a little bit of functionality to accept custom parameter names passed in by the user.\n\n# A basic chains constructor that works with the Transition struct we defined.\nfunction AbstractMCMC.bundle_samples(\n    rng::AbstractRNG,\n    ℓ::DensityModel,\n    s::MetropolisHastings,\n    N::Integer,\n    ts::Vector{&lt;:Transition},\n    chain_type::Type{Any};\n    param_names=missing,\n    kwargs...,\n)\n    # Turn all the transitions into a vector-of-vectors.\n    vals = copy(reduce(hcat, [vcat(t.θ, t.lp) for t in ts])')\n\n    # Check if we received any parameter names.\n    if ismissing(param_names)\n        param_names = [\"Parameter $i\" for i in 1:(length(first(vals)) - 1)]\n    end\n\n    # Add the log density field to the parameter names.\n    push!(param_names, \"lp\")\n\n    # Bundle everything up and return a Chains struct.\n    return Chains(vals, param_names, (internals=[\"lp\"],))\nend\n\nAll done!\nYou can even implement different output formats by implementing bundle_samples for different chain_types, which can be provided as keyword argument to sample. As default sample uses chain_type = Any.\n\n\n\nNow that we have all the pieces, we should test the implementation by defining a model to calculate the mean and variance parameters of a Normal distribution. We can do this by constructing a target density function, providing a sample of data, and then running the sampler with sample.\n\n# Generate a set of data from the posterior we want to estimate.\ndata = rand(Normal(5, 3), 30)\n\n# Define the components of a basic model.\ninsupport(θ) = θ[2] &gt;= 0\ndist(θ) = Normal(θ[1], θ[2])\ndensity(θ) = insupport(θ) ? sum(logpdf.(dist(θ), data)) : -Inf\n\n# Construct a DensityModel.\nmodel = DensityModel(density)\n\n# Set up our sampler with initial parameters.\nspl = MetropolisHastings([0.0, 0.0])\n\n# Sample from the posterior.\nchain = sample(model, spl, 100000; param_names=[\"μ\", \"σ\"])\n\nIf all the interface functions have been extended properly, you should get an output from display(chain) that looks something like this:\nObject of type Chains, with data of type 100000×3×1 Array{Float64,3}\n\nIterations        = 1:100000\nThinning interval = 1\nChains            = 1\nSamples per chain = 100000\ninternals         = lp\nparameters        = μ, σ\n\n2-element Array{ChainDataFrame,1}\n\nSummary Statistics\n\n│ Row │ parameters │ mean    │ std      │ naive_se   │ mcse       │ ess     │ r_hat   │\n│     │ Symbol     │ Float64 │ Float64  │ Float64    │ Float64    │ Any     │ Any     │\n├─────┼────────────┼─────────┼──────────┼────────────┼────────────┼─────────┼─────────┤\n│ 1   │ μ          │ 5.33157 │ 0.854193 │ 0.0027012  │ 0.00893069 │ 8344.75 │ 1.00009 │\n│ 2   │ σ          │ 4.54992 │ 0.632916 │ 0.00200146 │ 0.00534942 │ 14260.8 │ 1.00005 │\n\nQuantiles\n\n│ Row │ parameters │ 2.5%    │ 25.0%   │ 50.0%   │ 75.0%   │ 97.5%   │\n│     │ Symbol     │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │\n├─────┼────────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n│ 1   │ μ          │ 3.6595  │ 4.77754 │ 5.33182 │ 5.89509 │ 6.99651 │\n│ 2   │ σ          │ 3.5097  │ 4.09732 │ 4.47805 │ 4.93094 │ 5.96821 │\nIt looks like we’re extremely close to our true parameters of Normal(5,3), though with a fairly high variance due to the low sample size.",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "Interface Guide"
    ]
  },
  {
    "objectID": "tutorials/docs-06-for-developers-interface/index.html#conclusion",
    "href": "tutorials/docs-06-for-developers-interface/index.html#conclusion",
    "title": "Interface Guide",
    "section": "",
    "text": "We’ve seen how to implement the sampling interface for general projects. Turing’s interface methods are ever-evolving, so please open an issue at AbstractMCMC with feature requests or problems.",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "Interface Guide"
    ]
  },
  {
    "objectID": "tutorials/docs-17-implementing-samplers/index.html",
    "href": "tutorials/docs-17-implementing-samplers/index.html",
    "title": "Implementing samplers",
    "section": "",
    "text": "In this tutorial, we’ll go through step-by-step how to implement a “simple” sampler in AbstractMCMC.jl in such a way that it can be easily applied to Turing.jl models.\nIn particular, we’re going to implement a version of Metropolis-adjusted Langevin (MALA).\nNote that we will implement this sampler in the AbstractMCMC.jl framework, completely “ignoring” Turing.jl until the very end of the tutorial, at which point we’ll use a single line of code to make the resulting sampler available to Turing.jl. This is to really drive home the point that one can implement samplers in a way that is accessible to all of Turing.jl’s users without having to use Turing.jl yourself.",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "Implementing Samplers"
    ]
  },
  {
    "objectID": "tutorials/docs-17-implementing-samplers/index.html#quick-overview-of-mala",
    "href": "tutorials/docs-17-implementing-samplers/index.html#quick-overview-of-mala",
    "title": "Implementing samplers",
    "section": "Quick overview of MALA",
    "text": "Quick overview of MALA\nWe can view MALA as a single step of the leapfrog intergrator with resampling of momentum \\(p\\) at every step.1 To make that statement a bit more concrete, we first define the extended target \\(\\bar{\\gamma}(x, p)\\) as\n\\[\\begin{equation*}\n\\log \\bar{\\gamma}(x, p) \\propto \\log \\gamma(x) + \\log \\gamma_{\\mathcal{N}(0, M)}(p)\n\\end{equation*}\\]\nwhere \\(\\gamma_{\\mathcal{N}(0, M)}\\) denotes the density for a zero-centered Gaussian with covariance matrix \\(M\\). We then consider targeting this joint distribution over both \\(x\\) and \\(p\\) as follows. First we define the map\n\\[\\begin{equation*}\n\\begin{split}\n  L_{\\epsilon}: \\quad & \\mathbb{R}^d \\times \\mathbb{R}^d \\to \\mathbb{R}^d \\times \\mathbb{R}^d \\\\\n  & (x, p) \\mapsto (\\tilde{x}, \\tilde{p}) := L_{\\epsilon}(x, p)\n\\end{split}\n\\end{equation*}\\]\nas\n\\[\\begin{equation*}\n\\begin{split}\n  p_{1 / 2} &:= p + \\frac{\\epsilon}{2} \\nabla \\log \\gamma(x) \\\\\n  \\tilde{x} &:= x + \\epsilon M^{-1} p_{1 /2 } \\\\\n  p_1 &:= p_{1 / 2} + \\frac{\\epsilon}{2} \\nabla \\log \\gamma(\\tilde{x}) \\\\\n  \\tilde{p} &:= - p_1\n\\end{split}\n\\end{equation*}\\]\nThis might be familiar for some readers as a single step of the Leapfrog integrator. We then define the MALA kernel as follows: given the current iterate \\(x_i\\), we sample the next iterate \\(x_{i + 1}\\) as\n\\[\\begin{equation*}\n\\begin{split}\n  p &\\sim \\mathcal{N}(0, M) \\\\\n  (\\tilde{x}, \\tilde{p}) &:= L_{\\epsilon}(x_i, p) \\\\\n  \\alpha &:= \\min \\left\\{ 1, \\frac{\\bar{\\gamma}(\\tilde{x}, \\tilde{p})}{\\bar{\\gamma}(x_i, p)} \\right\\} \\\\\n  x_{i + 1} &:=\n  \\begin{cases}\n    \\tilde{x} \\quad & \\text{ with prob. } \\alpha \\\\\n    x_i       \\quad & \\text{ with prob. } 1 - \\alpha\n  \\end{cases}\n\\end{split}\n\\end{equation*}\\]\ni.e. we accept the proposal \\(\\tilde{x}\\) with probability \\(\\alpha\\) and reject it, thus sticking with our current iterate, with probability \\(1 - \\alpha\\).",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "Implementing Samplers"
    ]
  },
  {
    "objectID": "tutorials/docs-17-implementing-samplers/index.html#what-we-need-from-a-model-logdensityproblems.jl",
    "href": "tutorials/docs-17-implementing-samplers/index.html#what-we-need-from-a-model-logdensityproblems.jl",
    "title": "Implementing samplers",
    "section": "What we need from a model: LogDensityProblems.jl",
    "text": "What we need from a model: LogDensityProblems.jl\nThere are a few things we need from the “target” / “model” / density that we want to sample from:\n\nWe need access to log-density evaluations \\(\\log \\gamma(x)\\) so we can compute the acceptance ratio involving \\(\\log \\bar{\\gamma}(x, p)\\).\nWe need access to log-density gradients \\(\\nabla \\log \\gamma(x)\\) so we can compute the Leapfrog steps \\(L_{\\epsilon}(x, p)\\).\nWe also need access to the “size” of the model so we can determine the size of \\(M\\).\n\nLuckily for us, there is a package called LogDensityProblems.jl which provides an interface for exactly this!\nTo demonstrate how one can implement the “LogDensityProblems.jl interface”2 we will use a simple Gaussian model as an example:\n\nusing LogDensityProblems: LogDensityProblems;\n\n# Let's define some type that represents the model.\nstruct IsotropicNormalModel{M&lt;:AbstractVector{&lt;:Real}}\n    \"mean of the isotropic Gaussian\"\n    mean::M\nend\n\n# Specifies what input length the model expects.\nLogDensityProblems.dimension(model::IsotropicNormalModel) = length(model.mean)\n# Implementation of the log-density evaluation of the model.\nfunction LogDensityProblems.logdensity(model::IsotropicNormalModel, x::AbstractVector{&lt;:Real})\n    return - sum(abs2, x .- model.mean) / 2\nend\n\nThis gives us all of the properties we want for our MALA sampler with the exception of the computation of the gradient \\(\\nabla \\log \\gamma(x)\\). There is the method LogDensityProblems.logdensity_and_gradient which should return a 2-tuple where the first entry is the evaluation of the logdensity \\(\\log \\gamma(x)\\) and the second entry is the gradient \\(\\nabla \\log \\gamma(x)\\).\nThere are two ways to “implement” this method: 1) we implement it by hand, which is feasible in the case of our IsotropicNormalModel, or b) we defer the implementation of this to a automatic differentiation backend.\nTo implement it by hand we can simply do\n\n# Tell LogDensityProblems.jl that first-order, i.e. gradient information, is available.\nLogDensityProblems.capabilities(model::IsotropicNormalModel) = LogDensityProblems.LogDensityOrder{1}()\n\n# Implement `logdensity_and_gradient`.\nfunction LogDensityProblems.logdensity_and_gradient(model::IsotropicNormalModel, x)\n    logγ_x = LogDensityProblems.logdensity(model, x)\n    ∇logγ_x = -x .* (x - model.mean)\n    return logγ_x, ∇logγ_x\nend\n\nLet’s just try it out:\n\n# Instantiate the problem.\nmodel = IsotropicNormalModel([-5., 0., 5.])\n# Create some example input that we can test on.\nx_example = randn(LogDensityProblems.dimension(model))\n# Evaluate!\nLogDensityProblems.logdensity(model, x_example)\n\n-34.49751246867245\n\n\nTo defer it to an automatic differentiation backend, we can do\n\n# Tell LogDensityProblems.jl we only have access to 0-th order information.\nLogDensityProblems.capabilities(model::IsotropicNormalModel) = LogDensityProblems.LogDensityOrder{0}()\n\n# Use `LogDensityProblemsAD`'s `ADgradient` in combination with some AD backend to implement `logdensity_and_gradient`.\nusing LogDensityProblemsAD, ADTypes, ForwardDiff\nmodel_with_grad = ADgradient(AutoForwardDiff(), model)\nLogDensityProblems.logdensity(model_with_grad, x_example)\n\n-34.49751246867245\n\n\nWe’ll continue with the second approach in this tutorial since this is typically what one does in practice, because there are better hobbies to spend time on than deriving gradients by hand.\nAt this point, one might wonder how we’re going to tie this back to Turing.jl in the end. Effectively, when working with inference methods that only require log-density evaluations and / or higher-order information of the log-density, Turing.jl actually converts the user-provided Model into an object implementing the above methods for LogDensityProblems.jl. As a result, most samplers provided by Turing.jl are actually implemented to work with LogDensityProblems.jl, enabling their use both within Turing.jl and outside of Turing.jl! Morever, there exists similar conversions for Stan through BridgeStan and StanLogDensityProblems.jl, which means that a sampler supporting the LogDensityProblems.jl interface can easily be used on both Turing.jl and Stan models (in addition to user-provided models, as our IsotropicNormalModel above)!\nAnyways, let’s move on to actually implementing the sampler.",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "Implementing Samplers"
    ]
  },
  {
    "objectID": "tutorials/docs-17-implementing-samplers/index.html#implementing-mala-in-abstractmcmc.jl",
    "href": "tutorials/docs-17-implementing-samplers/index.html#implementing-mala-in-abstractmcmc.jl",
    "title": "Implementing samplers",
    "section": "Implementing MALA in AbstractMCMC.jl",
    "text": "Implementing MALA in AbstractMCMC.jl\nNow that we’ve established that a model implementing the LogDensityProblems.jl interface provides us with all the information we need from \\(\\log \\gamma(x)\\), we can address the question: given an object that implements the LogDensityProblems.jl interface, how can we define a sampler for it?\nWe’re going to do this by making our sampler a sub-type of AbstractMCMC.AbstractSampler in addition to implementing a few methods from AbstractMCMC.jl. Why? Because it gets us a lot of functionality for free, as we will see later.\nMoreover, AbstractMCMC.jl provides a very natural interface for MCMC algorithms.\nFirst, we’ll define our MALA type\n\nusing AbstractMCMC\n\nstruct MALA{T,A} &lt;: AbstractMCMC.AbstractSampler\n    \"stepsize used in the leapfrog step\"\n    ϵ_init::T\n    \"covariance matrix used for the momentum\"\n    M_init::A\nend\n\nNotice how we’ve added the suffix _init to both the stepsize and the covariance matrix. We’ve done this because a AbstractMCMC.AbstractSampler should be immutable. Of course there might be many scenarios where we want to allow something like the stepsize and / or the covariance matrix to vary between iterations, e.g. during the burn-in / adaptation phase of the sampling process we might want to adjust the parameters using statistics computed from these initial iterations. But information which can change between iterations should not go in the sampler itself! Instead, this information should go in the sampler state.\nThe sampler state should at the very least contain all the necessary information to perform the next MCMC iteration, but usually contains further information, e.g. quantities and statistics useful for evaluating whether the sampler has converged.\nWe will use the following sampler state for our MALA sampler:\n\nstruct MALAState{A&lt;:AbstractVector{&lt;:Real}}\n    \"current position\"\n    x::A\nend\n\nThis might seem overly redundant: we’re defining a type MALAState and it only contains a simple vector of reals. In this particular case we indeed could have dropped this and simply used a AbstractVector{&lt;:Real} as our sampler state, but typically, as we will see later, one wants to include other quantities in the sampler state. For example, if we also wanted to adapt the parameters of our MALA, e.g. alter the stepsize depending on acceptance rates, in which case we should also put ϵ in the state, but for now we’ll keep things simple.\nMoreover, we also want a sample type, which is a type meant for “public consumption”, i.e. the end-user. This is generally going to contain a subset of the information present in the state. But in such a simple scenario as this, we similarly only have a AbstractVector{&lt;:Real}:\n\nstruct MALASample{A&lt;:AbstractVector{&lt;:Real}}\n    \"current position\"\n    x::A\nend\n\nWe currently have three things:\n\nA AbstractMCMC.AbstractSampler implementation called MALA.\nA state MALAState for our sampler MALA.\nA sample MALASample for our sampler MALA.\n\nThat means that we’re ready to implement the only thing that really matters: AbstractMCMC.step.\nAbstractMCMC.step defines the MCMC iteration of our MALA given the current MALAState. Specifically, the signature of the function is as follows:\n\nfunction AbstractMCMC.step(\n    # The RNG to ensure reproducibility.\n    rng::Random.AbstractRNG,\n    # The model that defines our target.\n    model::AbstractMCMC.AbstractModel,\n    # The sampler for which we're taking a `step`.\n    sampler::AbstractMCMC.AbstractSampler,\n    # The current sampler `state`.\n    state;\n    # Additional keyword arguments that we may or may not need.\n    kwargs...\n)\n\nMoreover, there is a specific AbstractMCMC.AbstractModel which is used to indicate that the model that is provided implements the LogDensityProblems.jl interface: AbstractMCMC.LogDensityModel.\nSince, as we discussed earlier, in our case we’re indeed going to work with types that support the LogDensityProblems.jl interface, we’ll define AbstractMCMC.step for such a AbstractMCMC.LogDensityModel.\nNote that AbstractMCMC.LogDensityModel has no other purpose; it has a single field called logdensity, and it does nothing else. But by wrapping the model in AbstractMCMC.LogDensityModel, it allows samplers that want to work with LogDensityProblems.jl to define their AbstractMCMC.step on this type without running into method ambiguities.\nAll in all, that means that the signature for our AbstractMCMC.step is going to be the following:\n\nfunction AbstractMCMC.step(\n    rng::Random.AbstractRNG,\n    # `LogDensityModel` so we know we're working with LogDensityProblems.jl model.\n    model::AbstractMCMC.LogDensityModel,\n    # Our sampler.\n    sampler::MALA,\n    # Our sampler state.\n    state::MALAState;\n    kwargs...\n)\n\nGreat! Now let’s actually implement the full AbstractMCMC.step for our MALA.\nLet’s remind ourselves what we’re going to do:\n\nSample a new momentum \\(p\\).\nCompute the log-density of the extended target \\(\\log \\bar{\\gamma}(x, p)\\).\nTake a single leapfrog step \\((\\tilde{x}, \\tilde{p}) = L_{\\epsilon}(x, p)\\).\nAccept or reject the proposed \\((\\tilde{x}, \\tilde{p})\\).\n\nAll in all, this results in the following:\n\nusing Random: Random\nusing Distributions  # so we get the `MvNormal`\n\nfunction AbstractMCMC.step(\n    rng::Random.AbstractRNG,\n    model_wrapper::AbstractMCMC.LogDensityModel,\n    sampler::MALA,\n    state::MALAState;\n    kwargs...\n)\n    # Extract the wrapped model which implements LogDensityProblems.jl.\n    model = model_wrapper.logdensity\n    # Let's just extract the sampler parameters to make our lives easier.\n    ϵ = sampler.ϵ_init\n    M = sampler.M_init\n    # Extract the current parameters.\n    x = state.x\n    # Sample the momentum.\n    p_dist = MvNormal(zeros(LogDensityProblems.dimension(model)), M)\n    p = rand(rng, p_dist)\n    # Propose using a single leapfrog step.\n    x̃, p̃ = leapfrog_step(model, x, p, ϵ, M)\n    # Accept or reject proposal.\n    logp = LogDensityProblems.logdensity(model, x) + logpdf(p_dist, p)\n    logp̃ = LogDensityProblems.logdensity(model, x̃) + logpdf(p_dist, p̃)\n    logα = logp̃ - logp\n    state_new = if log(rand(rng)) &lt; logα\n        # Accept.\n        MALAState(x̃)\n    else\n        # Reject.\n        MALAState(x)\n    end\n    # Return the \"sample\" and the sampler state.\n    return MALASample(state_new.x), state_new\nend\n\nFairly straight-forward.\nOf course, we haven’t defined the leapfrog_step method yet, so let’s do that:\n\nfunction leapfrog_step(model, x, p, ϵ, M)\n    # Update momentum `p` using \"position\" `x`.\n    ∇logγ_x = last(LogDensityProblems.logdensity_and_gradient(model, x))\n    p1 = p + (ϵ / 2) .* ∇logγ_x\n    # Update the \"position\" `x` using momentum `p1`.\n    x̃ = x + ϵ .* (M \\ p1)\n    # Update momentum `p1` using position `x̃`\n    ∇logγ_x̃ = last(LogDensityProblems.logdensity_and_gradient(model, x̃))\n    p2 = p1 + (ϵ / 2) .* ∇logγ_x̃\n    # Flip momentum `p2`.\n    p̃ = -p2\n    return x̃, p̃\nend\n\nleapfrog_step (generic function with 1 method)\n\n\nWith all of this, we’re technically ready to sample!\n\nusing Random, LinearAlgebra\n\nrng = Random.default_rng()\nsampler = MALA(1, I)\nstate = MALAState(zeros(LogDensityProblems.dimension(model)))\n\nx_next, state_next = AbstractMCMC.step(\n    rng,\n    AbstractMCMC.LogDensityModel(model),\n    sampler,\n    state\n)\n\n(MALASample{Vector{Float64}}([-1.270621481812781, 0.6699287453025501, 0.1565272822155228]), MALAState{Vector{Float64}}([-1.270621481812781, 0.6699287453025501, 0.1565272822155228]))\n\n\nGreat, it works!\nAnd I promised we would get quite some functionality for free if we implemented AbstractMCMC.step, and so we can now simply call sample to perform standard MCMC sampling:\n\n# Perform 1000 iterations with our `MALA` sampler.\nsamples = sample(model_with_grad, sampler, 10_000; initial_state=state, progress=false)\n# Concatenate into a matrix.\nsamples_matrix = stack(sample -&gt; sample.x, samples)\n\n3×10000 Matrix{Float64}:\n -2.0596    -6.2472   -5.8747   -4.40313  …  -5.04622  -5.0811    -4.72194\n  0.655327  -1.58775  -1.31059  -1.91741      1.66632  -0.920784  -0.814119\n  2.91367    3.82113   3.34893   2.91008      4.98994   5.05034    5.21824\n\n\n\n# Compute the marginal means and standard deviations.\nhcat(mean(samples_matrix; dims=2), std(samples_matrix; dims=2))\n\n3×2 Matrix{Float64}:\n -4.96953    1.00675\n -0.0125145  0.994771\n  4.9968     0.989009\n\n\nLet’s visualize the samples\n\nusing StatsPlots\nplot(transpose(samples_matrix[:, 1:10:end]), alpha=0.5, legend=false)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLook at that! Things are working; amazin’.\nWe can also exploit AbstractMCMC.jl’s parallel sampling capabilities:\n\n# Run separate 4 chains for 10 000 iterations using threads to parallelize.\nnum_chains = 4\nsamples = sample(\n    model_with_grad,\n    sampler,\n    MCMCThreads(),\n    10_000,\n    num_chains;\n    # Note we need to provide an initial state for every chain.\n    initial_state=fill(state, num_chains),\n    progress=false\n)\nsamples_array = stack(map(Base.Fix1(stack, sample -&gt; sample.x), samples))\n\n3×10000×4 Array{Float64, 3}:\n[:, :, 1] =\n -1.51832  -2.7934    -3.83752   …  -4.8896   -4.65255   -4.65255\n -1.2272   -0.963588   0.454172     -1.585    -0.895877  -0.895877\n  3.29242   4.76009    5.70958       2.66503   2.71374    2.71374\n\n[:, :, 2] =\n -1.73986  -3.52168  -3.52168  -4.79942  …  -5.34104   -4.50703   -4.57622\n  1.63128   1.10466   1.10466  -0.48492      0.571391   0.290941   2.25035\n  1.22202   2.88512   2.88512   5.38529      3.73616    4.14858    6.13333\n\n[:, :, 3] =\n -2.69841   -4.11287    -3.55109  …  -5.21374   -3.90058   -4.27903\n  0.599118  -0.0862528  -1.20161     -0.285337  -0.616022   0.825948\n  2.50817    3.85448     4.73486      4.59087    4.76416    6.41979\n\n[:, :, 4] =\n -2.07711   -4.62735  -4.99575   -3.65463  …  -5.69347   -6.06901  -4.83689\n -0.252406   1.43288   0.450218  -1.10308      0.544235   1.29556   1.74143\n  3.13116    3.77752   4.53756    4.34838      3.62714    3.76891   4.61707\n\n\nBut the fact that we have to provide the AbstractMCMC.sample call, etc. with an initial_state to get started is a bit annoying. We can avoid this by also defining a AbstractMCMC.step without the state argument:\n\nfunction AbstractMCMC.step(\n    rng::Random.AbstractRNG,\n    model_wrapper::AbstractMCMC.LogDensityModel,\n    ::MALA;\n    # NOTE: No state provided!\n    kwargs...\n)\n    model = model_wrapper.logdensity\n    # Let's just create the initial state by sampling using  a Gaussian.\n    x = randn(rng, LogDensityProblems.dimension(model))\n\n    return MALASample(x), MALAState(x)\nend\n\nEquipped with this, we no longer need to provide the initial_state everywhere:\n\nsamples = sample(model_with_grad, sampler, 10_000; progress=false)\nsamples_matrix = stack(sample -&gt; sample.x, samples)\nhcat(mean(samples_matrix; dims=2), std(samples_matrix; dims=2))\n\n3×2 Matrix{Float64}:\n -4.97433     0.97882\n  0.00757414  1.01991\n  5.03135     1.01609",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "Implementing Samplers"
    ]
  },
  {
    "objectID": "tutorials/docs-17-implementing-samplers/index.html#using-our-sampler-with-turing.jl",
    "href": "tutorials/docs-17-implementing-samplers/index.html#using-our-sampler-with-turing.jl",
    "title": "Implementing samplers",
    "section": "Using our sampler with Turing.jl",
    "text": "Using our sampler with Turing.jl\nAs we promised, all of this hassle of implementing our MALA sampler in a way that uses LogDensityProblems.jl and AbstractMCMC.jl gets us something more than just an “automatic” implementation of AbstractMCMC.sample.\nIt also enables use with Turing.jl through the externalsampler, but we need to do one final thing first: we need to tell Turing.jl how to extract a vector of parameters from the “sample” returned in our implementation of AbstractMCMC.step. In our case, the “sample” is a MALASample, so we just need the following line:\n\n# Load Turing.jl.\nusing Turing\n\n# Overload the `getparams` method for our \"sample\" type, which is just a vector.\nTuring.Inference.getparams(::Turing.Model, sample::MALASample) = sample.x\n\nAnd with that, we’re good to go!\n\n# Our previous model defined as a Turing.jl model.\n@model mvnormal_model() = x ~ MvNormal([-5., 0., 5.], I)\n# Instantiate our model.\nturing_model = mvnormal_model()\n# Call `sample` but now we're passing in a Turing.jl `model` and wrapping\n# our `MALA` sampler in the `externalsampler` to tell Turing.jl that the sampler\n# expects something that implements LogDensityProblems.jl.\nchain = sample(turing_model, externalsampler(sampler), 10_000; progress=false)\n\nChains MCMC chain (10000×4×1 Array{Float64, 3}):\n\nIterations        = 1:1:10000\nNumber of chains  = 1\nSamples per chain = 10000\nWall duration     = 2.7 seconds\nCompute duration  = 2.7 seconds\nparameters        = x[1], x[2], x[3]\ninternals         = lp\n\nSummary Statistics\n  parameters      mean       std      mcse    ess_bulk    ess_tail      rhat   ⋯\n      Symbol   Float64   Float64   Float64     Float64     Float64   Float64   ⋯\n\n        x[1]   -4.9882    1.0032    0.0175   3275.7305   4858.1246    0.9999   ⋯\n        x[2]   -0.0022    1.0084    0.0183   3019.7740   4581.2508    1.0000   ⋯\n        x[3]    4.9826    1.0176    0.0171   3543.0910   5639.6500    1.0011   ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n        x[1]   -6.9544   -5.6661   -4.9997   -4.2999   -3.0047\n        x[2]   -2.0301   -0.6810    0.0002    0.6744    1.9800\n        x[3]    3.0089    4.2843    4.9876    5.6626    6.9536\n\n\nPretty neat, eh?\n\nModels with constrained parameters\nOne thing we’ve sort of glossed over in all of the above is that MALA, at least how we’ve implemented it, requires \\(x\\) to live in \\(\\mathbb{R}^d\\) for some \\(d &gt; 0\\). If some of the parameters were in fact constrained, e.g. we were working with a Beta distribution which has support on the interval \\((0, 1)\\), not on \\(\\mathbb{R}^d\\), we could easily end up outside of the valid range \\((0, 1)\\).\n\n@model beta_model() = x ~ Beta(3, 3)\nturing_model = beta_model()\nchain = sample(turing_model, externalsampler(sampler), 10_000; progress=false)\n\nChains MCMC chain (10000×2×1 Array{Float64, 3}):\n\nIterations        = 1:1:10000\nNumber of chains  = 1\nSamples per chain = 10000\nWall duration     = 1.56 seconds\nCompute duration  = 1.56 seconds\nparameters        = x\ninternals         = lp\n\nSummary Statistics\n  parameters      mean       std      mcse    ess_bulk    ess_tail      rhat   ⋯\n      Symbol   Float64   Float64   Float64     Float64     Float64   Float64   ⋯\n\n           x    0.5010    0.1888    0.0029   4269.1401   5801.2346    0.9999   ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n           x    0.1456    0.3619    0.5007    0.6422    0.8558\n\n\nYep, that still works, but only because Turing.jl actually transforms the turing_model from constrained to unconstrained, so that the sampler provided to externalsampler is actually always working in unconstrained space! This is not always desirable, so we can turn this off:\n\nchain = sample(turing_model, externalsampler(sampler; unconstrained=false), 10_000; progress=false)\n\nChains MCMC chain (10000×2×1 Array{Float64, 3}):\n\nIterations        = 1:1:10000\nNumber of chains  = 1\nSamples per chain = 10000\nWall duration     = 0.24 seconds\nCompute duration  = 0.24 seconds\nparameters        = x\ninternals         = lp\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n           x    0.5146    0.1666    0.0206    55.0337    28.2364    1.0083     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n           x    0.2260    0.3822    0.5187    0.6442    0.7813\n\n\nThe fun thing is that this still sort of works because\n\nlogpdf(Beta(3, 3), 10.0)\n\n-Inf\n\n\nand so the samples that fall outside of the range are always rejected. But do notice how much worse all the diagnostics are, e.g. ess_tail is very poor compared to when we use unconstrained=true. Moreover, in more complex cases this won’t just result in a “nice” -Inf log-density value, but instead will error:\n\n@model function demo()\n    σ² ~ truncated(Normal(), lower=0)\n    # If we end up with negative values for `σ²`, the `Normal` will error.\n    x ~ Normal(0, σ²)\nend\nsample(demo(), externalsampler(sampler; unconstrained=false), 10_000; progress=false)\n\nDomainError: DomainError(-2.520710520157504, \"Normal: the condition σ &gt;= zero(σ) is not satisfied.\")\nDomainError with -2.520710520157504:\nNormal: the condition σ &gt;= zero(σ) is not satisfied.\nStacktrace:\n  [1] #371\n    @ ~/.julia/packages/Distributions/nmUhn/src/univariate/continuous/normal.jl:37 [inlined]\n  [2] check_args\n    @ ~/.julia/packages/Distributions/nmUhn/src/utils.jl:89 [inlined]\n  [3] #Normal#370\n    @ ~/.julia/packages/Distributions/nmUhn/src/univariate/continuous/normal.jl:37 [inlined]\n  [4] Normal\n    @ ~/.julia/packages/Distributions/nmUhn/src/univariate/continuous/normal.jl:36 [inlined]\n  [5] Normal\n    @ ~/.julia/packages/Distributions/nmUhn/src/univariate/continuous/normal.jl:42 [inlined]\n  [6] macro expansion\n    @ ~/.julia/packages/DynamicPPL/MjWTB/src/compiler.jl:579 [inlined]\n  [7] demo(__model__::DynamicPPL.Model{typeof(demo), (), (), (), Tuple{}, Tuple{}, DynamicPPL.DefaultContext}, __varinfo__::DynamicPPL.ThreadSafeVarInfo{DynamicPPL.TypedVarInfo{@NamedTuple{σ²::DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:σ², typeof(identity)}, Int64}, Vector{Truncated{Normal{Float64}, Continuous, Float64, Float64, Nothing}}, Vector{AbstractPPL.VarName{:σ², typeof(identity)}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, x::DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:x, typeof(identity)}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:x, typeof(identity)}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}, Float64}, Vector{Base.RefValue{Float64}}}, __context__::DynamicPPL.ValuesAsInModelContext{OrderedDict{Any, Any}, DynamicPPL.DefaultContext})\n    @ Main.Notebook ~/work/docs/docs/tutorials/docs-17-implementing-samplers/index.qmd:592\n  [8] _evaluate!!\n    @ ~/.julia/packages/DynamicPPL/MjWTB/src/model.jl:973 [inlined]\n  [9] evaluate_threadsafe!!(model::DynamicPPL.Model{typeof(demo), (), (), (), Tuple{}, Tuple{}, DynamicPPL.DefaultContext}, varinfo::DynamicPPL.TypedVarInfo{@NamedTuple{σ²::DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:σ², typeof(identity)}, Int64}, Vector{Truncated{Normal{Float64}, Continuous, Float64, Float64, Nothing}}, Vector{AbstractPPL.VarName{:σ², typeof(identity)}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, x::DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:x, typeof(identity)}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:x, typeof(identity)}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}, Float64}, context::DynamicPPL.ValuesAsInModelContext{OrderedDict{Any, Any}, DynamicPPL.DefaultContext})\n    @ DynamicPPL ~/.julia/packages/DynamicPPL/MjWTB/src/model.jl:962\n [10] evaluate!!\n    @ ~/.julia/packages/DynamicPPL/MjWTB/src/model.jl:892 [inlined]\n [11] values_as_in_model\n    @ ~/.julia/packages/DynamicPPL/MjWTB/src/values_as_in_model.jl:196 [inlined]\n [12] values_as_in_model\n    @ ~/.julia/packages/DynamicPPL/MjWTB/src/values_as_in_model.jl:195 [inlined]\n [13] getparams(model::DynamicPPL.Model{typeof(demo), (), (), (), Tuple{}, Tuple{}, DynamicPPL.DefaultContext}, vi::DynamicPPL.TypedVarInfo{@NamedTuple{σ²::DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:σ², typeof(identity)}, Int64}, Vector{Truncated{Normal{Float64}, Continuous, Float64, Float64, Nothing}}, Vector{AbstractPPL.VarName{:σ², typeof(identity)}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, x::DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:x, typeof(identity)}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:x, typeof(identity)}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}, Float64})\n    @ Turing.Inference ~/.julia/packages/Turing/Bv30p/src/mcmc/Inference.jl:343\n [14] Turing.Inference.Transition(model::DynamicPPL.Model{typeof(demo), (), (), (), Tuple{}, Tuple{}, DynamicPPL.DefaultContext}, vi::DynamicPPL.TypedVarInfo{@NamedTuple{σ²::DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:σ², typeof(identity)}, Int64}, Vector{Truncated{Normal{Float64}, Continuous, Float64, Float64, Nothing}}, Vector{AbstractPPL.VarName{:σ², typeof(identity)}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, x::DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:x, typeof(identity)}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:x, typeof(identity)}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}, Float64}, t::MALASample{Vector{Float64}})\n    @ Turing.Inference ~/.julia/packages/Turing/Bv30p/src/mcmc/Inference.jl:226\n [15] transition_to_turing\n    @ ~/.julia/packages/Turing/Bv30p/src/mcmc/abstractmcmc.jl:12 [inlined]\n [16] transition_to_turing(f::LogDensityProblemsADForwardDiffExt.ForwardDiffLogDensity{LogDensityFunction{DynamicPPL.TypedVarInfo{@NamedTuple{σ²::DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:σ², typeof(identity)}, Int64}, Vector{Truncated{Normal{Float64}, Continuous, Float64, Float64, Nothing}}, Vector{AbstractPPL.VarName{:σ², typeof(identity)}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}, x::DynamicPPL.Metadata{Dict{AbstractPPL.VarName{:x, typeof(identity)}, Int64}, Vector{Normal{Float64}}, Vector{AbstractPPL.VarName{:x, typeof(identity)}}, Vector{Float64}, Vector{Set{DynamicPPL.Selector}}}}, Float64}, DynamicPPL.Model{typeof(demo), (), (), (), Tuple{}, Tuple{}, DynamicPPL.DefaultContext}, Nothing}, ForwardDiff.Chunk{2}, ForwardDiff.Tag{DynamicPPL.DynamicPPLTag, Float64}, ForwardDiff.GradientConfig{ForwardDiff.Tag{DynamicPPL.DynamicPPLTag, Float64}, Float64, 2, Vector{ForwardDiff.Dual{ForwardDiff.Tag{DynamicPPL.DynamicPPLTag, Float64}, Float64, 2}}}}, transition::MALASample{Vector{Float64}})\n    @ Turing.Inference ~/.julia/packages/Turing/Bv30p/src/mcmc/abstractmcmc.jl:17\n [17] step(rng::TaskLocalRNG, model::DynamicPPL.Model{typeof(demo), (), (), (), Tuple{}, Tuple{}, DynamicPPL.DefaultContext}, sampler_wrapper::DynamicPPL.Sampler{Turing.Inference.ExternalSampler{MALA{Int64, UniformScaling{Bool}}, AutoForwardDiff{nothing, Nothing}, false}}; initial_state::Nothing, initial_params::Nothing, kwargs::@Kwargs{})\n    @ Turing.Inference ~/.julia/packages/Turing/Bv30p/src/mcmc/abstractmcmc.jl:141\n [18] step\n    @ ~/.julia/packages/Turing/Bv30p/src/mcmc/abstractmcmc.jl:96 [inlined]\n [19] macro expansion\n    @ ~/.julia/packages/AbstractMCMC/YrmkI/src/sample.jl:130 [inlined]\n [20] macro expansion\n    @ ~/.julia/packages/AbstractMCMC/YrmkI/src/logging.jl:16 [inlined]\n [21] mcmcsample(rng::TaskLocalRNG, model::DynamicPPL.Model{typeof(demo), (), (), (), Tuple{}, Tuple{}, DynamicPPL.DefaultContext}, sampler::DynamicPPL.Sampler{Turing.Inference.ExternalSampler{MALA{Int64, UniformScaling{Bool}}, AutoForwardDiff{nothing, Nothing}, false}}, N::Int64; progress::Bool, progressname::String, callback::Nothing, discard_initial::Int64, thinning::Int64, chain_type::Type, initial_state::Nothing, kwargs::@Kwargs{})\n    @ AbstractMCMC ~/.julia/packages/AbstractMCMC/YrmkI/src/sample.jl:120\n [22] sample(rng::TaskLocalRNG, model::DynamicPPL.Model{typeof(demo), (), (), (), Tuple{}, Tuple{}, DynamicPPL.DefaultContext}, sampler::DynamicPPL.Sampler{Turing.Inference.ExternalSampler{MALA{Int64, UniformScaling{Bool}}, AutoForwardDiff{nothing, Nothing}, false}}, N::Int64; chain_type::Type, resume_from::Nothing, initial_state::Nothing, kwargs::@Kwargs{progress::Bool})\n    @ DynamicPPL ~/.julia/packages/DynamicPPL/MjWTB/src/sampler.jl:93\n [23] sample\n    @ ~/.julia/packages/DynamicPPL/MjWTB/src/sampler.jl:83 [inlined]\n [24] #sample#4\n    @ ~/.julia/packages/Turing/Bv30p/src/mcmc/Inference.jl:276 [inlined]\n [25] sample\n    @ ~/.julia/packages/Turing/Bv30p/src/mcmc/Inference.jl:267 [inlined]\n [26] #sample#3\n    @ ~/.julia/packages/Turing/Bv30p/src/mcmc/Inference.jl:264 [inlined]\n [27] top-level scope\n    @ ~/work/docs/docs/tutorials/docs-17-implementing-samplers/index.qmd:594\n\n\nAs expected, we run into a DomainError at some point, while if we set unconstrained=true, letting Turing.jl transform the model to a unconstrained form behind the scenes, everything works as expected:\n\nsample(demo(), externalsampler(sampler; unconstrained=true), 10_000; progress=false)\n\nChains MCMC chain (10000×3×1 Array{Float64, 3}):\n\nIterations        = 1:1:10000\nNumber of chains  = 1\nSamples per chain = 10000\nWall duration     = 1.7 seconds\nCompute duration  = 1.7 seconds\nparameters        = σ², x\ninternals         = lp\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n          σ²    0.8390    0.5452    0.0252   328.0919   123.6615    1.0002     ⋯\n           x   -0.0492    0.9701    0.0539   481.7051   287.1264    1.0000     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n          σ²    0.1190    0.3983    0.7316    1.1717    2.1026\n           x   -2.4037   -0.4286    0.0070    0.4260    1.8049\n\n\nNeat!\nSimilarly, which automatic differentiation backend one should use can be specified through the adtype keyword argument too. For example, if we want to use ReverseDiff.jl instead of the default ForwardDiff.jl:\n\nusing ReverseDiff: ReverseDiff\n# Specify that we want to use `AutoReverseDiff`.\nsample(\n    demo(),\n    externalsampler(sampler; unconstrained=true, adtype=AutoReverseDiff()),\n    10_000;\n    progress=false\n)\n\nChains MCMC chain (10000×3×1 Array{Float64, 3}):\n\nIterations        = 1:1:10000\nNumber of chains  = 1\nSamples per chain = 10000\nWall duration     = 3.14 seconds\nCompute duration  = 3.14 seconds\nparameters        = σ², x\ninternals         = lp\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   e ⋯\n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64     ⋯\n\n          σ²    0.8407    0.5792    0.0294   252.0957    59.0366    1.0094     ⋯\n           x    0.0564    1.0841    0.0710   356.2762   174.7654    1.0063     ⋯\n                                                                1 column omitted\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5%\n      Symbol   Float64   Float64   Float64   Float64   Float64\n\n          σ²    0.1173    0.3746    0.7319    1.1818    2.1846\n           x   -2.1361   -0.4329    0.0350    0.4349    2.8435\n\n\nDouble-neat.",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "Implementing Samplers"
    ]
  },
  {
    "objectID": "tutorials/docs-17-implementing-samplers/index.html#summary",
    "href": "tutorials/docs-17-implementing-samplers/index.html#summary",
    "title": "Implementing samplers",
    "section": "Summary",
    "text": "Summary\nAt this point it’s worth maybe reminding ourselves what we did and also why we did it:\n\nWe define our models in the LogDensityProblems.jl interface because it makes the sampler agnostic to how the underlying model is implemented.\nWe implement our sampler in the AbstractMCMC.jl interface, which just means that our sampler is a subtype of AbstractMCMC.AbstractSampler and we implement the MCMC transition in AbstractMCMC.step.\nPoints 1 and 2 makes it so our sampler can be used with a wide range of model implementations, amongst them being models implemented in both Turing.jl and Stan. This gives you, the inference implementer, a large collection of models to test your inference method on, in addition to allowing users of Turing.jl and Stan to try out your inference method with minimal effort.",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "Implementing Samplers"
    ]
  },
  {
    "objectID": "tutorials/docs-17-implementing-samplers/index.html#footnotes",
    "href": "tutorials/docs-17-implementing-samplers/index.html#footnotes",
    "title": "Implementing samplers",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWe’re going with the leapfrog formulation because in a future version of this tutorial we’ll add a section extending this simple “baseline” MALA sampler to more complex versions. See issue #479 for progress on this.↩︎\nThere is no such thing as a proper interface in Julia (at least not officially), and so we use the word “interface” here to mean a few minimal methods that needs to be implemented by any type that we treat as a target model.↩︎",
    "crumbs": [
      "Get Started",
      "Developers",
      "Inference (note: outdated)",
      "Implementing Samplers"
    ]
  },
  {
    "objectID": "../library/index.html",
    "href": "../library/index.html",
    "title": "Turing Libraries",
    "section": "",
    "text": "This page lists all the packages that are part of the The Turing Organization."
  },
  {
    "objectID": "../library/index.html#modelling-languages",
    "href": "../library/index.html#modelling-languages",
    "title": "Turing Libraries",
    "section": "Modelling Languages",
    "text": "Modelling Languages\n\nDynamicPPL.jl: A domain-specific language and backend for probabilistic programming languages used by Turing.jl.\nJuliaBUGS.jl: JuliaBUGS is a graph-based probabilistic programming language and a component of the Turing ecosystem.\nTuringGLM.jl: A Julia package for Bayesian generalised linear models used for returning an instantiated Turing model using the formula syntax"
  },
  {
    "objectID": "../library/index.html#markov-chain-monte-carlo-mcmc",
    "href": "../library/index.html#markov-chain-monte-carlo-mcmc",
    "title": "Turing Libraries",
    "section": "Markov chain Monte Carlo (MCMC)",
    "text": "Markov chain Monte Carlo (MCMC)\n\nAdvancedHMC.jl: It provides a robust, modular, and efficient implementation of advanced Hamiltonian Monte Carlo (HMC) algorithms.\nAbstractMCMC.jl: Abstract types and interfaces for Markov chain Monte Carlo methods. This defines an interface for sampling and combining Markov chains.\nThermodynamicIntegration.jl: A simple package to compute Thermodynamic Integration for computing the evidence in a Bayesian setting.\nAdvancedPS.jl: This is a lightweight package that implements particle-based Monte Carlo algorithms for the Turing ecosystem.\nSliceSampling.jl: This package is a collection of slice sampling algorithms including the univariate slice samplers by Neal (2003).\nEllipticalSliceSampling.jl: This package implements elliptical slice sampling in the Julia language, as described in Murray, Adams & MacKay (2010).\nNestedSamplers.jl: A Julian implementation of single- and multi-ellipsoidal nested sampling algorithms using the AbstractMCMC interface."
  },
  {
    "objectID": "../library/index.html#diagnostics",
    "href": "../library/index.html#diagnostics",
    "title": "Turing Libraries",
    "section": "Diagnostics",
    "text": "Diagnostics\n\nMCMCChains.jl: Implementation of Julia types for summarising MCMC simulations and utility functions for diagnostics and visualisations.\nMCMCDiagnosticTools.jl: This package provides functionality for diagnosing samples generated using Markov Chain Monte Carlo.\nParetoSmooth.jl: An implementation of Pareto smoothed importance sampling(PSIS) algorithms in Julia."
  },
  {
    "objectID": "../library/index.html#bijectors.jl",
    "href": "../library/index.html#bijectors.jl",
    "title": "Turing Libraries",
    "section": "Bijectors.jl",
    "text": "Bijectors.jl\n\nBijectors.jl: A package for transforming distributions, used by Turing.jl."
  },
  {
    "objectID": "../library/index.html#turingcallbacks.jl",
    "href": "../library/index.html#turingcallbacks.jl",
    "title": "Turing Libraries",
    "section": "TuringCallbacks.jl",
    "text": "TuringCallbacks.jl\n\nTuringCallbacks.jl: A package containing some convenient callbacks to use when you sample in Turing.jl."
  },
  {
    "objectID": "../library/index.html#turingbenchmarking.jl",
    "href": "../library/index.html#turingbenchmarking.jl",
    "title": "Turing Libraries",
    "section": "TuringBenchmarking.jl",
    "text": "TuringBenchmarking.jl\n\nTuringBenchmarking.jl: A package for benchmarking and checking Turing.jl models."
  },
  {
    "objectID": "../library/index.html#gaussian-processes",
    "href": "../library/index.html#gaussian-processes",
    "title": "Turing Libraries",
    "section": "Gaussian Processes",
    "text": "Gaussian Processes\n\nAbstractGPs.jl: AbstractGPs.jl is a package that defines a low-level API for working with Gaussian processes (GPs), and basic functionality for working with them in the simplest cases.\nKernelFunctions.jl: Julia package for kernel functions for machine learning.\nApproximateGPs.jl: This is a package that provides some approximate inference algorithms for Gaussian process models, built on top of AbstractGPs.jl."
  },
  {
    "objectID": "../news/posts/2019-12-14-initial-post/index.html",
    "href": "../news/posts/2019-12-14-initial-post/index.html",
    "title": "Turing’s Blog",
    "section": "",
    "text": "All good open source projects should have a blog, and Turing is one such project. Later on, members of the Turing team may be populating this feed with posts on topics like\n\nInteresting things you can do with Turing, or interesting things we have seen others do.\nDevelopment updates and major release announcements.\nResearch updates.\nExplorations of Turing’s internals.\nUpdates to Turing’s satellite projects AdvancedHMC.jl or Bijectors.jl.\n\nStay tuned!\n\n\n\n Back to top"
  },
  {
    "objectID": "../news/posts/2022-02-17-gsoc/index.html",
    "href": "../news/posts/2022-02-17-gsoc/index.html",
    "title": "Google Summer of Code 2022",
    "section": "",
    "text": "It is another year of the Google Summer of Code time, and we have compiled an updated list of exciting Turing projects! Projects that the Turing team would be interested in working with students on over the summer are listed below. This information is also cross-posted at Julia’s Turing project page.\nIf you are interested in exploring any of these projects or have any questions, please reach out to the listed project mentors. You can find their contact information at turinglang.org/team."
  },
  {
    "objectID": "../news/posts/2022-02-17-gsoc/index.html#more-real-world-bayesian-models-in-turing-julia",
    "href": "../news/posts/2022-02-17-gsoc/index.html#more-real-world-bayesian-models-in-turing-julia",
    "title": "Google Summer of Code 2022",
    "section": "More real-world Bayesian models in Turing / Julia",
    "text": "More real-world Bayesian models in Turing / Julia\nMentors: Kai Xu, Tor E. Fjelde, Hong Ge\nProject difficulty: Medium\nProject length: 175 hrs or 350 hrs\nDescription: There are many real-world Bayesian models out there, and they deserve a Turing / Julia implementation.\nExamples include but not limited to - Forecasting (Prophet, datasets) - Recommender system (probabilistic matrix factorisation, dataset) - Ranking (TrueSkill, dataset) - Bayesian revenue estimation (example) - Political forecasting model (example) - Topic mining (latent Dirichlet allocation and new variants) - Multiple Annotators/Combining Unreliable Observations (Dawid and Skene, 1979)\nFor each model, we would consider the following tasks as part of a GSoC project: - Correctness test: correctness of the implementation can be tested by doing inference for prior samples, for which we know the ground truth latent variables. - Performance benchmark: this includes (i) time per MCMC step and (ii) time per effective sample; if the model is differentiable, a further break-down of (i) into (i.1) time per forward pass and (i.2) time per gradient pass are needed. - Real-world results: if available, the final step is to apply the model to a real-world dataset; if such an experiment has been done in the literature, consistency of inference results needs to be checked"
  },
  {
    "objectID": "../news/posts/2022-02-17-gsoc/index.html#improving-the-integration-between-turing-and-turings-mcmc-inference-packages",
    "href": "../news/posts/2022-02-17-gsoc/index.html#improving-the-integration-between-turing-and-turings-mcmc-inference-packages",
    "title": "Google Summer of Code 2022",
    "section": "Improving the integration between Turing and Turing’s MCMC inference packages",
    "text": "Improving the integration between Turing and Turing’s MCMC inference packages\nMentors: Cameron Pfiffer, Mohamed Tarek, David Widmann\nProject difficulty: Easy\nProject length: 175 hrs\nDescription: Turing.jl is based on a set of inference packages maintained by the TuringLang group. This project is about making use of improvements in DynamicPPL to create a generic integration between Turing.jl and the AbstractMCMC.jl sampling API. The ultimate goal is to remove or substantially reduce algorithm-specific glue code inside Turing.jl. The project would also involve improving data structures for storing model parameters in DynamicPPL."
  },
  {
    "objectID": "../news/posts/2022-02-17-gsoc/index.html#directed-graphical-model-support-for-the-abstract-probabilistic-programming-library",
    "href": "../news/posts/2022-02-17-gsoc/index.html#directed-graphical-model-support-for-the-abstract-probabilistic-programming-library",
    "title": "Google Summer of Code 2022",
    "section": "Directed-graphical model support for the abstract probabilistic programming library",
    "text": "Directed-graphical model support for the abstract probabilistic programming library\nMentors: Philipp Gabler, Hong Ge\nProject difficulty: Hard\nProject length: 350 hrs\nDescription: We want to have a very light-weight representation of probabilistic models of static graphs (similar to BUGS), which can serve as a representation target of other front-end DSLs or be dynamically built. The representation should consist of the model and node representations (stochastic and deterministic, perhaps hyperparameters) and conform to the AbstractPPL model interface, with basic functions (evaluation of density, sampling, conditioning; at later stages some static analysis like extraction of Markov blankets). The model should also contain the state of the variables and implement the AbstractPPL trace interface (dictionary functions, querying of variable names). The result should be able to work with existing sampling packages through the abstract interfaces."
  },
  {
    "objectID": "../news/posts/2022-02-17-gsoc/index.html#a-modular-tape-caching-mechanism-for-reversediff",
    "href": "../news/posts/2022-02-17-gsoc/index.html#a-modular-tape-caching-mechanism-for-reversediff",
    "title": "Google Summer of Code 2022",
    "section": "A modular tape caching mechanism for ReverseDiff",
    "text": "A modular tape caching mechanism for ReverseDiff\nMentors: Qingliang Zhuo, Mohamed Tarek\nProject difficulty: Medium\nProject length: 175 hrs\nDescription: Tape caching often leads to significant performance improvements for gradient-based sampling algorithms (e.g. HMC/NUTS). Tape caching is only possible at the complete computational level for ReverseDiff at the moment. This project is about implementing a more modular, i.e. function-as-a-caching-barrier, tape caching mechanism for ReverseDiff.jl."
  },
  {
    "objectID": "../news/posts/2022-02-17-gsoc/index.html#benchmarking-improving-performance-of-the-juliagaussianprocesses-libraries",
    "href": "../news/posts/2022-02-17-gsoc/index.html#benchmarking-improving-performance-of-the-juliagaussianprocesses-libraries",
    "title": "Google Summer of Code 2022",
    "section": "Benchmarking & improving performance of the JuliaGaussianProcesses libraries",
    "text": "Benchmarking & improving performance of the JuliaGaussianProcesses libraries\nMentors: Theo Galy-Fajou, Will Tebbutt, ST John\nProject difficulty: Medium\nProject length: 350 hrs\nDescription: Although KernelFunctions.jl has extensive correctness testing, our performance testing is lacking. This project aims to resolve this, and resolve performance issues wherever they are found. The student would first need to extend our existing benchmarking coverage, and debug any obvious performance problems. The next phase of the work would be to construct end-to-end examples of KernelFunctions being used in practice, profile them to determine where performance problems lie, and fix them."
  },
  {
    "objectID": "../news/posts/2022-02-17-gsoc/index.html#iterative-methods-for-inference-in-gaussian-processes",
    "href": "../news/posts/2022-02-17-gsoc/index.html#iterative-methods-for-inference-in-gaussian-processes",
    "title": "Google Summer of Code 2022",
    "section": "Iterative methods for inference in Gaussian Processes",
    "text": "Iterative methods for inference in Gaussian Processes\nMentors: Will Tebbutt, S. T. John, Ross Viljoen\nProject difficulty: Medium\nProject length: 175 hrs\nDescription: There has recently been quite a bit of work on inference methods for GPs that use iterative methods rather than the Cholesky factorisation. They look quite promising, but no one has implemented any of these within the Julia GP ecosystem yet, but they should fit nicely within the AbstractGPs framework. If you’re interested in improving the GP ecosystem in Julia, this project might be for you!"
  },
  {
    "objectID": "../news/posts/2022-02-17-gsoc/index.html#approximate-inference-methods-for-non-gaussian-likelihoods-in-gaussian-processes",
    "href": "../news/posts/2022-02-17-gsoc/index.html#approximate-inference-methods-for-non-gaussian-likelihoods-in-gaussian-processes",
    "title": "Google Summer of Code 2022",
    "section": "Approximate inference methods for non-Gaussian likelihoods in Gaussian Processes",
    "text": "Approximate inference methods for non-Gaussian likelihoods in Gaussian Processes\nMentors: S. T. John, Ross Viljoen, Theo Galy-Fajou\nProject difficulty: Hard\nProject length: 350 hrs\nDescription: Adding approximate inference methods for non-Gaussian likelihoods which are available in other GP packages but not yet within JuliaGPs. The project would start by determining which approximate inference method(s) to implement—there’s lots to do, and we’re happy to work with a student on whichever method they are most interested in, or to suggest one if they have no strong preference."
  },
  {
    "objectID": "../news/posts/2022-02-17-gsoc/index.html#gpu-integration-in-the-juliagps-ecosystem",
    "href": "../news/posts/2022-02-17-gsoc/index.html#gpu-integration-in-the-juliagps-ecosystem",
    "title": "Google Summer of Code 2022",
    "section": "GPU integration in the JuliaGPs ecosystem",
    "text": "GPU integration in the JuliaGPs ecosystem\nMentors: Ross Viljoen, Theo Galy-Fajou, Will Tebbutt\nProject difficulty: Medium\nProject length: 350 hrs\nDescription: This would involve first ensuring that common models are able to run fully on the GPU, then identifying and improving GPU-specific performance bottlenecks. This would begin by implementing a limited end-to-end example involving a GP with a standard kernel, and profiling it to debug any substantial performance bottlenecks. From there, support for a wider range of the functionality available in KernelFunctions.jl and AbstractGPs.jl can be added. Stretch goal: extension of GPU support to some functionality in ApproximateGPs.jl."
  },
  {
    "objectID": "../news/posts/2020-05-04-Imperial-Report13-analysis/index.html",
    "href": "../news/posts/2020-05-04-Imperial-Report13-analysis/index.html",
    "title": "Replication study: Estimating number of infections and impact of NPIs on COVID-19 in European countries (Imperial Report 13)",
    "section": "",
    "text": "The Turing.jl team is currently exploring possibilities in an attempt to help with the ongoing SARS-CoV-2 crisis. As preparation for this and to get our feet wet, we decided to perform a replication study of the Imperial Report 13, which attempts to estimate the real number of infections and impact of non-pharmaceutical interventions on COVID-19. In the report, the inference was performed using the probabilistic programming language (PPL) Stan. We have explicated their model and inference in Turing.jl, a Julia-based PPL. We believe the results and analysis of our study are relevant for the public, and for other researchers who are actively working on epidemiological models. To that end, our implementation and results are available here.\nIn summary, we replicated the Imperial COVID-19 model using Turing.jl. Subsequently, we compared the inference results between Turing and Stan, and our comparison indicates that results are reproducible with two different implementations. In particular, we performed 4 sets of simulations using the Imperial COVID-19 model. The resulting estimates of the expected real number of cases, in contrast to the recorded number of cases, the reproduction number \\(R_t\\), and the expected number of deaths as a function of time and non-pharmaceutical interventions (NPIs) for each Simulation are shown below.\n\n\n\n\n\nSimulation (a): hypothetical Simulation from the model without data (prior predictive) or non-pharmaceutical interventions. Under the prior assumptions of the Imperial Covid-19 model, there is a very wide range of epidemic progressions with expected cases from almost 0 to 100% of the population over time. The black bar corresponds to the date of the last observation. Note that \\(R_t\\) has a different time-range than the other plots; following the original report, this shows the 100 days following the country-specific epidemic_start which is defined to be 31 days prior to the first date of 10 cumulative deaths, while the other plots show the last 60 days.\n\n\n\n\nSimulation (b): future Simulation with non-pharmaceutical interventions kept in place (posterior predictive). After incorporating the observed infection data, we can see a substantially more refined range of epidemic progression. The reproduction rate estimate lies in the range of 3.5-5.6 before any intervention is introduced. The dotted lines correspond to observations, and the black bar corresponds to the date of the last observation.\n\n\n\n\nSimulation (c): future Simulation with non-pharmaceutical interventions removed. Now we see the hypothetical scenarios after incorporating infection data, but with non-pharmaceutical interventions removed. This plot looks similar to Simulation (a), but with a more rapid progression of the pandemic since the estimated reproduction rate is bigger than the prior assumptions. The dotted lines correspond to observations, and the black bar corresponds to the date of the last observation.\n\n\n\n\nSimulation (d): future Simulation with when lockdown is lifted two weeks before the last observation (predictive posterior). As a result there is a clear, rapid rebound of the reproduction rate. Comparing with Simulation (b) we do not observe an immediate increase in the number of expected cases and deaths upon lifting lockdown, but there is a significant difference in the number of cases and deaths in the last few days in the plot: Simulation (d) results in both greater number of cases and deaths, as expected. This demonstrates how the effects of lifting an intervention might not become apparent in the measurable variables, e.g. deaths, until several weeks later. The dotted lines correspond to observations, the black bar corresponds to the date of the last observation, and the red bar indicates when lockdown was lifted.\nOverall, Simulation (a) shows the prior modelling assumptions, and how these prior assumptions determine the predicted number of cases, etc. before seeing any data. Simulation (b) predicts the trend of the number of cases, etc. using estimated parameters and by keeping all the non-pharmaceutical interventions in place. Simulation (c) shows the estimate in the case where none of the intervention measures are ever put in place. Simulation (d) shows the estimates in the case when the lockdown was lifted two weeks prior to the last observation while keeping all the other non-pharmaceutical interventions in place.\nWe want to emphasise that we do not provide additional analysis of the Imperial model yet, nor are we aiming to make any claims about the validity or the implications of the model. Instead we refer to Imperial Report 13 for more details and analysis. The purpose of this post is solely to add validation to the inference performed in the paper by obtaining the same results using a different probabilistic programming language (PPL) and by exploring whether or not Turing.jl can be useful for researchers working on these problems.\nFor our next steps, we’re looking at collaboration with other researchers and further developments of this and similar models. There are some immediate directions to explore:\n\nIncorporation of more sources of data, e.g. national mobility, seasonal changes and behavior changes in individuals.\nHow the assumptions incorporated into the priors and their parameters change resulting posterior.\nThe current model does not directly include recovery as a possibility and assumes that if a person has been infected once then he/she will be infectious until death. Number of recovered cases suffers from the same issues as the number of cases: it cannot be directly observed. But we can also deal with it in a similar manner as is done with number of cases and incorporate this into the model for a potential improvement. This will result in a plethora of different models from which we can select the most realistic one using different model comparison techniques, e.g. leave-one-out cross-validation (loo-cv).\n\nSuch model refinement can be potentially valuable given the high impact of this pandemic and the uncertainty and debates in the potential outcomes.\nAcknowledgement We would like to thank the Julia community for creating such an excellent platform for scientific computing, and for the continuous feedback that we have received. We also thank researchers from Computational and Biological Laboratory at Cambridge University for their feedback on an early version of the post. \n\n\n\n Back to top"
  },
  {
    "objectID": "../news/posts/2021-02-04-gsoc/index.html",
    "href": "../news/posts/2021-02-04-gsoc/index.html",
    "title": "Google Summer of Code 2021",
    "section": "",
    "text": "It’s about time for us to start thinking about projects we’d like to see at Turing.jl for the Google Summer of Code 2021! Below is a list of projects the Turing team would be interested in working with students on for the summer.\nIf you are interested in exploring any of these projects, please reach out to the listed project mentors. You can find their contact information at turinglang.org/team.\n\nMCMCChains improvements\nMentors: Cameron Pfiffer, Hong Ge\nProject difficulty: Easy\nDescription: MCMCChains is a key component of the Turing.jl ecosystem. It is the package that determines how to analyze and store MCMC samples provided by packages like Turing. It’s also used outside of Turing.\nFor this project, a student might improve the performance of the various statistical functions provided by MCMCChains, changing the back end to use a data storage format that maintains the shape of parameter samples, or improve the general plotting functionality of the package.\nThere’s lots of fun little things to do for MCMCChains. Check out this meta-issue for more details and discussions.\n\n\nParticle filtering methods\nMentors: Hong Ge, Cameron Pfiffer\nProject difficulty: Medium\nDescription: Turing’s support for particle sampling methods is slowing being improved with the addition of AdvancedPS.jl. If you’re interested in implementing or improving particle sampling methods, this is a great project for you!\n\n\nNested Sampling\nMentors: Miles Lucas, Cameron Pfiffer, Hong Ge\nProject difficulty: Hard\nDescription: NestedSamplers.jl is an excellent package which implements nested sampling methods. As of yet, it is not connected to Turing.jl. For this project, a student would connect the NestedSamplers.jl library to Turing.jl.\n\n\nGPU acceleration\nMentors: Mohamed Tarek, Hong Ge, Kai Xu, Tor Fjelde\nProject difficulty: Medium\nDescription: Turing’s native GPU support is limited in that the Metropolis-Hastings and HMC samplers do not implement GPU sampling methods. This can and should be done – GPU methods are awesome! If you are interested with working on parallelism and GPUs, this project is for you.\nStudents will work with the code at AdvancedMH or AdvancedHMC, depending on their interests.\n\n\nDocumentation and tutorial improvements\nMentors: Cameron Pfiffer, Martin Trapp\nProject difficulty: Easy\nDescription: Turing’s documentation and tutorials need a bit of an overhaul. Turing has changed significantly since the last time the documentation was written, and it’s beginning to show. Students would use their knowledge of probabilistic programming languages and Turing to shore-up or rewrite documentation and tutorials.\n\n\nIterative Methods for Inference in Gaussian Processes\nMentors: Will Tebbutt, S. T. John, Theo Galy-Fajou\nProject difficulty: Medium\nDescription: There has recently been quite a bit of work on inference methods for GPs that use iterative methods rather than the Cholesky factorisation. They look quite promising, but no one has implemented any of these within the Julia GP ecosystem yet, but they should fit nicely within the AbstractGPs framework. If you’re interested in improving the GP ecosystem in Julia, this project might be for you!\n\n\nImplement advanced variational Gaussian process models\nMentors: ST John, Will Tebbutt, Theo Galy-Fajou\nProject difficulty: Easy to Medium\nDescription: Sparse variational Gaussian process models provide the flexibility to scale to large datasets, handle arbitrary (non-conjugate) likelihoods, and to be used as building blocks for composite models such as deep GPs. This project is about making such models more readily available within the Julia GP ecosystem - depending on your interests you can focus on making it easier for end users and providing good tutorials, or on the implementations of these models to give us the same or better performance as with established Python packages such as GPflow, integrating with Flux.jl, etc.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "../news/posts/2020-02-12-jsoc/index.html",
    "href": "../news/posts/2020-02-12-jsoc/index.html",
    "title": "Google Summer of Code/Julia Summer of Code",
    "section": "",
    "text": "Last year, Turing participated in the Google Summer of Code (GSoC) through the Julia language organization. It was a fun time, and the project was better for it. Turing plans to participate in the upcoming GSoC, and we wanted to outline some potential projects and expectations we have for applicants.\nIf you are not aware, Google provides funds to students around the world to develop a project of their choice over the summer. Students receive funds from Google and spend three months on any open source project.\nThe Turing development team has prepared a list of possible projects that we have deemed valuable to the project and easy enough that it could feasibly be created in the three-month limit. This list is not exclusive – if you have a good idea, you can write it up in your proposal, though it is recommend that you reach out to any of the Turing team on Julia’s Slack (you can get an invite here) or Discourse. Messages on Discourse should be posted to the “Probabilistic programming” category – we’ll find you!\nPossible project ideas:\n\nBenchmarking. Turing’s performance has been sporadically benchmarked against various other probabilistic programming languages (e.g. Turing, Stan, PyMC3, TensorFlow Prob), but a systemic approach to studying where Turing excels and where it falls short would be useful. A GSoC student would implement identical models in many PPLs and build tools to benchmark all PPLs against one another.\nNested sampling integration. Turing focuses on modularity in inference methods, and the development team would like to see more inference methods, particularly the popular nested sampling method. A Julia package (NestedSamplers.jl) but it is not hooked up to Turing and does not currently have a stable API. A GSoC student would either integrate that package or construct their own nested sampling method and build it into Turing.\nAutomated function memoization by model annotation. Function memoization is a way to reduce costly function evaluation by caching the output when the same inputs are given. Turing’s Gibbs sampler often ends up rerunning expensive functions multiple times, and it would be a significant performance improvement to allow Turing’s model compiler to automatically memoize functions where appropriate. A student working on this project would become intimately familiar with Turing’s model compiler and build in various automated improvements.\nMaking Distributions GPU compatible. Julia’s GPU tooling is generally quite good, but currently Turing is not able to reliably use GPUs while sampling because Distributions.jl is not GPU compatible. A student on this project would work with the Turing developers and the Distributions developers to allow the use of GPU parallelism where possible in Turing.\nStatic distributions. Small, fixed-size vectors and matrices are fairly common in Turing models. This means that sampling in Turing can probably benefit from using statically sized vectors and matrices from StaticArrays.jl instead of the dynamic normal Julia arrays. Beside the often superior performance of small static vectors and matrices, static arrays are also automatically compatible with the GPU stack in Julia. Currently, the main obstacle to using StaticArrays.jl is that distributions in Distributions.jl are not compatible with StaticArrays. A GSoC student would adapt the multivariate and matrix-variate distributions as well as the univariate distribution with vector parameters in Distributions.jl to make a spin-off package called StaticDistributions.jl. The student would then benchmark StaticDistributions.jl against Distributions.jl and showcase an example of using StaticDistributions.jl together with CuArrays.jl and/or CUDAnative.jl for GPU-acceleration.\nGPnet extensions. One of Turing’s satellite packages, GPnet, is designed to provide a comprehensive suite of Gaussian process tools. See this issue for potential tasks – there’s a lot of interesting stuff going on with GPs, and this task in particular may have some creative freedom to it.\nBetter chains and model diagnostics. One package that Turing (and many others) rely on heavily is MCMCChains.jl, a package designed to format, store, and analyze parameter samples generated during MCMC inference. MCMCChains is currently showing its age a little and has many bad design choices that need to be fixed. Alternatively, a student could construct a far more lightweight chain system.\nModel comparison tools. Turing and its satellite packages do not currently provide a comprehensive suite of model comparison tools, a critical tool for the applied statistician. A student who worked on this project would implement various model comparison tools like LOO and WAIC, among others.\nMLE/MAP tools. Maximum likelihood estimates (MLE) and maximum a posteriori (MAP) estimates can currently only be done by users through a clunky set of workarounds. A streamlined function like mle(model) or map(model) would be very useful for many of Turing’s users who want to see what the MLE or MAP estimates look like, and it may be valuable to allow for functionality that allows MCMC sampling to begin from the MLE or MAP estimates. Students working on this project will work with optimization packages such as Optim.jl to make MLE and MAP estimation straightforward for Turing models.\nParticle sampler improvements. Turing’s development team has spent a lot of time and energy to make inference methods more modular, but Turing’s particle samplers have not yet been modernized and spun off into a separate package. Two packages that resulted from this were AdvancedHMC for Hamiltonian MCMC methods, and AdvancedMH for Metropolis-Hastings style inference methods. A student who worked on this project would become very familiar with Turing’s inference backend and with particle sampling methods. This is a good project for people who love making things efficient and easily extendable.\n\nOther projects are welcome, but we do strongly recommend discussing any potential projects with members of the Turing team, as they will end up mentoring GSoC students for the duration of the project.\nWe’re looking forward to what people are interested in!\n\n\n\n Back to top"
  },
  {
    "objectID": "../news/posts/2020-09-11-gsoc/index.html",
    "href": "../news/posts/2020-09-11-gsoc/index.html",
    "title": "Google Summer of Code 2020",
    "section": "",
    "text": "As the 2020 Google Summer of Code comes to a close, the Turing team thought it would be a good opportunity to reflect on the work that was done by our superb students this summer.\nSaranjeet Kaur’s project focused primarily on expanding NestedSamplers.jl. NestedSamplers.jl now supports PolyChord-style nested sampling natively, which is an absolute delight. Saranjeet wrote about this here. She also provided a good tutorial on how to use NestedSamplers.jl here. The NestedSamplers.jl integration with Turing is still on-going – integrating new samplers with Turing is one of the more difficult tasks. If you are interested to see the progress on this, check out the relevant pull request.\nArthur Lui’s project was to provide a much-needed set of benchmarks of Bayesian nonparametric models between Turing and other PPLs. Arthur’s work spawned a GitHub repository with good practices for benchmarking, as well as three blog posts with some (very cool!) statistics on Turing’s performance:\n\nDirichlet Process Gaussian mixture model via the stick-breaking construction in various PPLs\nGaussian Process Regression Model in various PPLs\nGaussian Process Classification Model in various PPLs\n\nFinally, Sharan Yalburgi (a returning GSoC student) completed an epic amount of work Turing’s growing suite of Gaussian process tools. In particular, the GitHub organization JuliaGaussianProcesses was founded, and serves as an effort to build a robust Gaussian process framework for the Julia ecosystem. The framework consists of multiple GP related Julia packages:\n\nKernelFunctions.jl provides kernel functions for GPs as well as efficient AD for these kernels. KernelFunctions.jl also supports multi-output GPs by providing necessary data abstractions and multi-output kernels.\nAbstractGPs.jl defines GP abstractions and provides exact posteriors. It provides support for induced points based GP posteriors and for efficient sequential/online (sparse) GP updates.\nGPLikelihoods.jl defines alternate likelihoods for Non-Gaussian GPs.\nGPMLj.jl provides a Julia interface for GPFlow, a GP library written in Python using TensorFlow.\n\nSpecial thanks to our three GSoC students for this summer, who all did excellent work. Additional thanks to Google for supporting open source software development and the Julia language!\n\n\n\n Back to top"
  }
]
