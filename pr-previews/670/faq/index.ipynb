{
  "cells": [
    {
      "outputs": [],
      "cell_type": "code",
      "source": "# Install necessary dependencies.\nusing Pkg\nPkg.activate(; temp=true)\nPkg.add([])",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Why is this variable being treated as random instead of observed?\n\nThis is a common source of confusion. In Turing.jl, you can only condition or fix expressions that explicitly appear on the left-hand side (LHS) of a `~` statement. \n\nFor example, if your model contains:\n```julia\nx ~ filldist(Normal(), 2)\n```\n\nYou cannot directly condition on `x[2]` using `condition(model, @varname(x[2]) => 1.0)` because `x[2]` never appears on the LHS of a `~` statement. Only `x` as a whole appears there.\n\nHowever, there is an important exception: when you use the broadcasting operator `.~` with a univariate distribution, each element is treated as being separately drawn from that distribution, allowing you to condition on individual elements:\n\n```julia\n@model function f1()\n    x = Vector{Float64}(undef, 3)\n    x .~ Normal()  # Each element is a separate draw\nend\n\nm1 = f1() | (@varname(x[1]) => 1.0)\nsample(m1, NUTS(), 100) # This works!\n```\n\nIn contrast, you cannot condition on parts of a multivariate distribution because it represents a single distribution over the entire vector:\n\n```julia\n@model function f2()\n    x = Vector{Float64}(undef, 3)\n    x ~ MvNormal(zeros(3), I)  # Single multivariate distribution\nend\n\nm2 = f2() | (@varname(x[1]) => 1.0)\nsample(m2, NUTS(), 100) # This doesn't work!\n```\n\nThe key insight is that `filldist` creates a single distribution (not N independent distributions), which is why you cannot condition on individual elements. The distinction is not just about what appears on the LHS of `~`, but whether you're dealing with separate distributions (`.~` with univariate) or a single distribution over multiple values (`~` with multivariate or `filldist`).\n\nTo understand more about how Turing determines whether a variable is treated as random or observed, see:\n\n- [Core Functionality]({{< meta core-functionality >}}) - basic explanation of the `~` notation and conditioning\n\n\n## Can I use parallelism / threads in my model?\n\nYes, but with important caveats! There are two types of parallelism to consider:\n\n### 1. Parallel Sampling (Multiple Chains)\nTuring.jl fully supports sampling multiple chains in parallel:\n\n- **Multithreaded sampling**: Use `MCMCThreads()` to run one chain per thread\n- **Distributed sampling**: Use `MCMCDistributed()` for distributed computing\n\nSee the [Core Functionality guide]({{<meta core-functionality>}}#sampling-multiple-chains) for examples.\n\n### 2. Threading Within Models\nUsing threads inside your model (e.g., `Threads.@threads`) requires more care:\n\n```julia\n@model function f(y)\n    x = Vector{Float64}(undef, length(y))\n    Threads.@threads for i in eachindex(y)\n        x[i] ~ Normal()  # UNSAFE: `assume` statements in @threads can crash!\n        y[i] ~ Normal(x[i])  # `observe` statements are okay\n    end\nend\n```\n\n**Important limitations:**\n\n- **Observe statements**: Generally safe to use in threaded loops\n- **Assume statements** (sampling statements): Often crash unpredictably or produce incorrect results\n- **AD backend compatibility**: Many AD backends don't support threading. Check the [multithreaded column in ADTests](https://turinglang.org/ADTests/) for compatibility\n\nFor safe parallelism within models, consider vectorised operations instead of explicit threading.\n\n## How do I check the type stability of my Turing model?\n\nType stability is crucial for performance. Check out:\n\n- [Performance Tips]({{< meta usage-performance-tips >}}) - includes specific advice on type stability\n- Use `DynamicPPL.DebugUtils.model_warntype` to check type stability of your model\n\n## How do I debug my Turing model?\n\nFor debugging both statistical and syntactical issues:\n\n- [Troubleshooting Guide]({{< meta usage-troubleshooting >}}) - common errors and their solutions\n- For more advanced debugging, DynamicPPL provides [the `DynamicPPL.DebugUtils` module](https://turinglang.org/DynamicPPL.jl/stable/api/#Debugging-Utilities) for inspecting model internals\n\n## What are the main differences between Turing, BUGS, and Stan syntax?\n\nKey syntactic differences include:\n\n- **Parameter blocks**: Stan requires explicit `data`, `parameters`, and `model` blocks. In Turing, everything is defined within the `@model` macro\n- **Variable declarations**: Stan requires upfront type declarations in parameter blocks. Turing infers types from the sampling statements\n- **Transformed data**: Stan has a `transformed data` block for preprocessing. In Turing, data transformations should be done before defining the model\n- **Generated quantities**: Stan has a `generated quantities` block. In Turing, use the approach described in [Tracking Extra Quantities]({{< meta usage-tracking-extra-quantities >}})\n\nExample comparison:\n```stan\n// Stan\ndata {\n  real y;\n}\nparameters {\n  real mu;\n  real<lower=0> sigma;\n}\nmodel {\n  mu ~ normal(0, 1);\n  sigma ~ normal(0, 1);\n  y ~ normal(mu, sigma);\n}\n```\n\n```julia\n# Turing\n@model function my_model(y)\n    mu ~ Normal(0, 1)\n    sigma ~ truncated(Normal(0, 1); lower=0)\n    y ~ Normal(mu, sigma)\nend\n```\n\n## Which automatic differentiation backend should I use?\n\nThe choice of AD backend can significantly impact performance. See:\n\n- [Automatic Differentiation Guide]({{< meta usage-automatic-differentiation >}}) - comprehensive comparison of ForwardDiff, Mooncake, ReverseDiff, and other backends\n- [Performance Tips]({{< meta usage-performance-tips >}}#choose-your-ad-backend) - quick guide on choosing backends\n- [AD Backend Benchmarks](https://turinglang.org/ADTests/) - performance comparisons across various models\n\n## I changed one line of my model and now it's so much slower; why?\n\nSmall changes can have big performance impacts. Common culprits include:\n\n- Type instability introduced by the change\n- Switching from vectorised to scalar operations (or vice versa)\n- Inadvertently causing AD backend incompatibilities\n- Breaking assumptions that allowed compiler optimizations\n\nSee our [Performance Tips]({{< meta usage-performance-tips >}}) and [Troubleshooting Guide]({{< meta usage-troubleshooting >}}) for debugging performance regressions.",
      "metadata": {}
    }
  ],
  "nbformat_minor": 5,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia"
    },
    "kernelspec": {
      "name": "julia",
      "display_name": "Julia",
      "language": "julia"
    }
  },
  "nbformat": 4
}