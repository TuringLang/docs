{
  "cells": [
    {
      "outputs": [],
      "cell_type": "code",
      "source": "# Install necessary dependencies.\nusing Pkg\nPkg.activate(; temp=true)\nPkg.add([\"Turing\", \"StatsPlots\"])",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "```julia\n#| echo: false\n#| output: false\nusing Pkg;\nPkg.instantiate();\n```",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Standard MCMC sampling methods return values of the parameters of the model.\nHowever, it is often also useful to generate new data points using the model, given a distribution of the parameters.\nTuring.jl allows you to do this using the `predict` function, along with conditioning syntax.\n\nConsider the following simple model, where we observe some normally-distributed data `X` and want to learn about its mean `m`.",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "using Turing\n@model function f(N)\n    m ~ Normal()\n    X ~ filldist(Normal(m), N)\nend",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Notice first how we have not specified `X` as an argument to the model.\nThis allows us to use Turing's conditioning syntax to specify whether we want to provide observed data or not.\n\n> If you want to specify `X` as an argument to the model, then to mark it as being unobserved, you have to instantiate the model again with `X = missing` or `X = fill(missing, N)`.\n> Whether you use `missing` or `fill(missing, N)` depends on whether `X` is treated as a single distribution (e.g. with `filldist` or `product_distribution`), or as multiple independent distributions (e.g. with `.~` or a for loop over `eachindex(X)`).\n> This is rather finicky, so we recommend using the current approach: conditioning and deconditioning `X` as a whole should work regardless of how `X` is defined in the model.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "```julia\n# Generate some synthetic data\nN = 5\ntrue_m = 3.0\nX = rand(Normal(true_m), N)\n\n# Instantiate the model with observed data\nmodel = f(N) | (; X = X)\n\n# Sample from the posterior\nchain = sample(model, NUTS(), 1_000; progress=false)\nmean(chain[:m])\n```",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Posterior predictive distribution\n\n`chain[:m]` now contains samples from the posterior distribution of `m`.\nIf we use these samples of the parameters to generate new data points, we obtain the *posterior predictive distribution*.\nStatistically, this is defined as\n\n$$\np(\\tilde{x} | \\mathbf{X}) = \\int p(\\tilde{x} | \\theta) p(\\theta | \\mathbf{X}) d\\theta,\n$$\n\nwhere $\\tilde{x}$ are the new data which you wish to draw, $\\theta$ are the model parameters, and $\\mathbf{X}$ are the observed data.\n$p(\\tilde{x} | \\theta)$ is the distribution of the new data given the parameters, which is specified in the Turing.jl model (the `X ~ ...` line); and $p(\\theta | \\mathbf{X})$ is the posterior distribution, as given by the Markov chain.\n\nTo obtain samples of $\\tilde{x}$, we need to first remove the observed data from the model (or 'decondition' the model).\nThis means that when the model is evaluated, it will sample a new value for `X`.\nIf you don't decondition the model, then `X` will remain fixed to the observed data, and no new samples will be generated.",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "predictive_model = decondition(model)",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "> ## Selective deconditioning\n> \n> If you only want to decondition a single variable `X`, you can use `decondition(model, @varname(X))`.\n\nTo demonstrate how this deconditioned model can generate new data, we can fix the value of `m` to be its mean and evaluate the model:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "predictive_model_with_mean_m = predictive_model | (; m = mean(chain[:m]))\nrand(predictive_model_with_mean_m)",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "This has given us a single sample of `X` given the mean value of `m`.\nOf course, to take our Bayesian uncertainty into account, we want to use the full posterior distribution of `m`, not just its mean.\nTo do so, we use `predict`, which _effectively_ does the same as above but for every sample in the chain:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "predictive_samples = predict(predictive_model, chain)",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "> ## Reproducibility\n> \n> `predict`, like many other Julia functions that involve randomness, takes an optional `rng` as its first argument.\n> This controls the generation of new `X` samples, and makes your results reproducible.\n\n> `predict` returns a Chains object itself, which will only contain the newly predicted variables.\n> If you want to also retain the original parameters, you can use `predict(rng, predictive_model, chain; include_all=true)`.\n\nWe can visualise the predictive distribution by combining all the samples and making a density plot:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "using StatsPlots: density, density!, vline!\n\npredicted_X = vcat([predictive_samples[Symbol(\"X[$i]\")] for i in 1:N]...)\ndensity(predicted_X, label=\"Posterior predictive\")",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Depending on your data, you may naturally want to create different visualisations.\nFor example, perhaps `X` contains some time-series data, in which case you can plot each prediction individually as a line against time.\n\n## Prior predictive distribution\n\nAlternatively, if we use the prior distribution of the parameters $p(\\theta)$, we obtain the *prior predictive distribution*:\n\n$$\np(\\tilde{x}) = \\int p(\\tilde{x} | \\theta) p(\\theta) d\\theta,\n$$\n\nIn an exactly analogous fashion to above, you could sample from the prior distribution of the conditioned model, and _then_ pass that to `predict`:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "prior_params = sample(model, Prior(), 1_000; progress=false)\nprior_predictive_samples = predict(predictive_model, prior_params)",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "In fact there is a simpler way: you can directly sample from the deconditioned model, using Turing's `Prior` sampler.\nThis will, in a single call, generate prior samples for both the parameters as well as the new data.",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "prior_predictive_samples = sample(predictive_model, Prior(), 1_000; progress=false)",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can visualise the prior predictive distribution in the same way as before.\nLet's compare the two predictive distributions:",
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": "prior_predicted_X = vcat([prior_predictive_samples[Symbol(\"X[$i]\")] for i in 1:N]...)\ndensity(prior_predicted_X, label=\"Prior predictive\")\ndensity!(predicted_X, label=\"Posterior predictive\")\nvline!([true_m], label=\"True mean\", linestyle=:dash, color=:black)",
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can see here that the prior predictive distribution is:\n\n1. Wider than the posterior predictive distribution;\n2. Centred on the prior mean of `m` (which is 0), rather than the posterior mean (which is close to the true mean of `3`).\n\nBoth of these are because the posterior predictive distribution has been informed by the observed data.",
      "metadata": {}
    }
  ],
  "nbformat_minor": 5,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia"
    },
    "kernelspec": {
      "name": "julia",
      "display_name": "Julia",
      "language": "julia"
    }
  },
  "nbformat": 4
}